{
  "clientId": "37063c84-3c84-563c8418de6-863c8418de63275-63275e27",
  "currentIndex": 5,
  "tabs": [
    {
      "name": "提词",
      "icon": "icon-chat",
      "type": "blank",
      "componentIndex": 1,
      "storage": {
        "activeNames": [
          0
        ],
        "formData": {
          "groupId": ""
        },
        "currentPromptName": "at-message"
      }
    },
    {
      "name": "工具",
      "icon": "icon-tool",
      "type": "blank",
      "componentIndex": 2,
      "storage": {
        "activeNames": [
          0
        ],
        "autoDetectDiagram": {
          "edges": [],
          "views": []
        },
        "formData": {
          "groupId": 1046693162,
          "message": [
            {
              "type": "at",
              "data": {
                "qq": 1193466151
              }
            },
            {
              "type": "text",
              "data": {
                "text": "et fugiat ex"
              }
            }
          ]
        },
        "currentToolName": "qq_send_message",
        "lastToolCallResponse": {
          "content": [
            {
              "type": "text",
              "text": "{\n  \"message_id\": 88051761\n}"
            }
          ]
        }
      }
    },
    {
      "name": "交互测试",
      "icon": "icon-robot",
      "type": "blank",
      "componentIndex": 3,
      "storage": {
        "activeNames": [
          0
        ],
        "messages": [
          {
            "role": "user",
            "content": "祖元琨是谁？",
            "extraInfo": {
              "created": 1760201778542,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "目前我无法直接查询到关于\"祖元琨\"的具体信息。要了解这个人物的详细情况，您可能需要：\n\n1. 提供更多背景信息，比如您是在什么情况下听到这个名字的\n2. 通过其他渠道搜索相关信息\n3. 如果这是您认识的人，您可以告诉我一些关于他的基本情况，我可以帮您记录下来\n\n如果您能提供更多上下文，我会尽力为您提供帮助。",
            "extraInfo": {
              "created": 1760201783602,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 1172,
                "completion_tokens": 85,
                "total_tokens": 1257,
                "prompt_tokens_details": {
                  "cached_tokens": 1152
                },
                "prompt_cache_hit_tokens": 1152,
                "prompt_cache_miss_tokens": 20
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "user",
            "content": "当前群号：123456    祖元琨是东南大学的研究生，他拥有天下无敌的头脑和技术，硕士发了一百多篇顶会论文\r\n",
            "extraInfo": {
              "created": 1760201791527,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "我了解了！祖元琨是东南大学的研究生，拥有非常出色的学术能力，硕士期间发表了一百多篇顶会论文，头脑和技术都很厉害。让我把这个重要信息记录下来。",
            "tool_calls": [
              {
                "id": "call_00_VJ1u9VDuxJgXj5gb0j0TB358",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "util_add_memory",
                  "arguments": "{\"groupId\": \"123456\", \"content\": [\"祖元琨是东南大学的研究生\", \"他拥有天下无敌的头脑和技术\", \"硕士期间发表了一百多篇顶会论文\"]}"
                }
              }
            ],
            "extraInfo": {
              "created": 1760201796773,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_VJ1u9VDuxJgXj5gb0j0TB358",
            "content": [
              {
                "type": "text",
                "text": "记忆添加成功"
              }
            ],
            "extraInfo": {
              "created": 1760201796785,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 1297,
                "completion_tokens": 93,
                "total_tokens": 1390,
                "prompt_tokens_details": {
                  "cached_tokens": 1216
                },
                "prompt_cache_hit_tokens": 1216,
                "prompt_cache_miss_tokens": 81
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "已经成功记录了祖元琨的信息！现在我知道在123456这个群里，祖元琨是东南大学的研究生，学术成就非常突出，硕士期间就发表了一百多篇顶会论文，确实是非常厉害的人才。\n\n这些信息已经保存在长期记忆中，以后在群里提到祖元琨时，我就能更好地理解他的背景了。",
            "extraInfo": {
              "created": 1760201801996,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 1406,
                "completion_tokens": 74,
                "total_tokens": 1480,
                "prompt_tokens_details": {
                  "cached_tokens": 1344
                },
                "prompt_cache_hit_tokens": 1344,
                "prompt_cache_miss_tokens": 62
              },
              "enableXmlWrapper": false
            }
          }
        ],
        "parallelMode": false,
        "parallelChats": [],
        "selectedModels": [],
        "settings": {
          "modelIndex": 0,
          "enableTools": [
            {
              "name": "qq_send_message",
              "description": "发送群消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "message": {
                    "type": "array",
                    "items": {
                      "anyOf": [
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "text"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "text": {
                                  "type": "string"
                                }
                              },
                              "required": [
                                "text"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        },
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "at"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "qq": {
                                  "type": [
                                    "string",
                                    "number"
                                  ]
                                }
                              },
                              "required": [
                                "qq"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        }
                      ]
                    },
                    "description": "要发送的内容"
                  }
                },
                "required": [
                  "groupId",
                  "message"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_image",
              "description": "发送图片",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "url": {
                    "type": "string",
                    "description": "图片的 url"
                  }
                },
                "required": [
                  "groupId",
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_info",
              "description": "获取群信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_list",
              "description": "获取群成员列表",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_info",
              "description": "获取群成员信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "user_id": {
                    "type": "number",
                    "description": "用户 QQ 号"
                  }
                },
                "required": [
                  "groupId",
                  "user_id"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_upload_group_file",
              "description": "上传群文件",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "file": {
                    "type": "string",
                    "description": "文件绝对路径"
                  },
                  "name": {
                    "type": "string",
                    "description": "文件名称"
                  }
                },
                "required": [
                  "groupId",
                  "file",
                  "name"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_group_notice",
              "description": "发送群公告",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "content": {
                    "type": "string",
                    "description": "公告内容"
                  }
                },
                "required": [
                  "groupId",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_latest_messages",
              "description": "获取最近的若干条群聊消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "messageCount": {
                    "type": "number",
                    "description": "获取最近几条消息"
                  }
                },
                "required": [
                  "groupId",
                  "messageCount"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_add_memory",
              "description": "将重要信息添加到长期记忆中。当用户分享关于自己、他人、事件的重要信息时(例如:姓名、喜好、经历、关系等),应该主动使用此工具记录,以便后续对话中查询使用。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容,每条信息应该是完整、清晰的描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识（可选）"
                  }
                },
                "required": [
                  "content",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_update_memory",
              "description": "更新记忆",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识"
                  },
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容"
                  }
                },
                "required": [
                  "groupId",
                  "key",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_search_memory",
              "description": "从长期记忆中查询信息。当用户询问关于特定人物、事件、或之前对话中提到的信息时,应该首先使用此工具搜索相关记忆。例如:用户问\"XXX是谁\"、\"XXX喜欢什么\"、\"上次说的那件事\"等问题时,必须先调用此工具查询。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string",
                    "description": "搜索的关键字,可以是人名、事件名、或相关描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  }
                },
                "required": [
                  "query",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_websearch",
              "description": "获取网页内容",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "url": {
                    "type": "string",
                    "description": "url"
                  }
                },
                "required": [
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            }
          ],
          "enableWebSearch": false,
          "temperature": 0.6,
          "contextLength": 100,
          "systemPrompt": "",
          "enableXmlWrapper": false,
          "parallelToolCalls": true
        },
        "chatMode": "single-chat"
      }
    },
    {
      "name": "交互测试",
      "icon": "icon-robot",
      "type": "blank",
      "componentIndex": 3,
      "storage": {
        "activeNames": [
          0
        ],
        "messages": [
          {
            "role": "user",
            "content": "当前群号：123456  祖元琨是谁？",
            "extraInfo": {
              "created": 1760201820814,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_JlvhpDYICZtMqJtRkwtDcnox",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "util_search_memory",
                  "arguments": "{\"query\": \"祖元琨\", \"groupId\": \"123456\"}"
                }
              }
            ],
            "extraInfo": {
              "created": 1760201823377,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_JlvhpDYICZtMqJtRkwtDcnox",
            "content": [
              {
                "type": "text",
                "text": "找到 1 条相关记忆:\n1. [namespace: 123456, key: 715b31f6-0fab-493e-954e-bd2e657058c1]\n   内容: 祖元琨是东南大学的研究生 他拥有天下无敌的头脑和技术 硕士期间发表了一百多篇顶会论文"
              }
            ],
            "extraInfo": {
              "created": 1760201823385,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 1179,
                "completion_tokens": 25,
                "total_tokens": 1204,
                "prompt_tokens_details": {
                  "cached_tokens": 1152
                },
                "prompt_cache_hit_tokens": 1152,
                "prompt_cache_miss_tokens": 27
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "根据我的记忆记录，祖元琨是东南大学的研究生，拥有天下无敌的头脑和技术，在硕士期间发表了一百多篇顶会论文。",
            "extraInfo": {
              "created": 1760201826243,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 1294,
                "completion_tokens": 34,
                "total_tokens": 1328,
                "prompt_tokens_details": {
                  "cached_tokens": 1152
                },
                "prompt_cache_hit_tokens": 1152,
                "prompt_cache_miss_tokens": 142
              },
              "enableXmlWrapper": false
            }
          }
        ],
        "parallelMode": false,
        "parallelChats": [],
        "selectedModels": [],
        "settings": {
          "modelIndex": 0,
          "enableTools": [
            {
              "name": "qq_send_message",
              "description": "发送群消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "message": {
                    "type": "array",
                    "items": {
                      "anyOf": [
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "text"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "text": {
                                  "type": "string"
                                }
                              },
                              "required": [
                                "text"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        },
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "at"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "qq": {
                                  "type": [
                                    "string",
                                    "number"
                                  ]
                                }
                              },
                              "required": [
                                "qq"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        }
                      ]
                    },
                    "description": "要发送的内容"
                  }
                },
                "required": [
                  "groupId",
                  "message"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_image",
              "description": "发送图片",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "url": {
                    "type": "string",
                    "description": "图片的 url"
                  }
                },
                "required": [
                  "groupId",
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_info",
              "description": "获取群信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_list",
              "description": "获取群成员列表",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_info",
              "description": "获取群成员信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "user_id": {
                    "type": "number",
                    "description": "用户 QQ 号"
                  }
                },
                "required": [
                  "groupId",
                  "user_id"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_upload_group_file",
              "description": "上传群文件",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "file": {
                    "type": "string",
                    "description": "文件绝对路径"
                  },
                  "name": {
                    "type": "string",
                    "description": "文件名称"
                  }
                },
                "required": [
                  "groupId",
                  "file",
                  "name"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_group_notice",
              "description": "发送群公告",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "content": {
                    "type": "string",
                    "description": "公告内容"
                  }
                },
                "required": [
                  "groupId",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_latest_messages",
              "description": "获取最近的若干条群聊消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "messageCount": {
                    "type": "number",
                    "description": "获取最近几条消息"
                  }
                },
                "required": [
                  "groupId",
                  "messageCount"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_add_memory",
              "description": "将重要信息添加到长期记忆中。当用户分享关于自己、他人、事件的重要信息时(例如:姓名、喜好、经历、关系等),应该主动使用此工具记录,以便后续对话中查询使用。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容,每条信息应该是完整、清晰的描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识（可选）"
                  }
                },
                "required": [
                  "content",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_update_memory",
              "description": "更新记忆",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识"
                  },
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容"
                  }
                },
                "required": [
                  "groupId",
                  "key",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_search_memory",
              "description": "从长期记忆中查询信息。当用户询问关于特定人物、事件、或之前对话中提到的信息时,应该首先使用此工具搜索相关记忆。例如:用户问\"XXX是谁\"、\"XXX喜欢什么\"、\"上次说的那件事\"等问题时,必须先调用此工具查询。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string",
                    "description": "搜索的关键字,可以是人名、事件名、或相关描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  }
                },
                "required": [
                  "query",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_websearch",
              "description": "获取网页内容",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "url": {
                    "type": "string",
                    "description": "url"
                  }
                },
                "required": [
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            }
          ],
          "enableWebSearch": false,
          "temperature": 0.6,
          "contextLength": 100,
          "systemPrompt": "",
          "enableXmlWrapper": false,
          "parallelToolCalls": true
        },
        "chatMode": "single-chat"
      }
    },
    {
      "name": "交互测试",
      "icon": "icon-robot",
      "type": "blank",
      "componentIndex": 3,
      "storage": {
        "activeNames": [
          0
        ],
        "messages": [
          {
            "role": "user",
            "content": "\n<INFORMATION>    \n当前群号：1046693162\n当前群名：Tiphereth 测试频道\n当前群成员数量：4\n当前最大人数：200\n</INFORMATION>\n\n<IDENTIFY>\n你现在是一个被部署在 QQ 群聊中的机器人助手。\n你的名字是 Tiphareth\n你的性别为 \n你是 0 岁的 20 级 QQ 号 1542544558\n你在当前群聊的角色是 admin 你上一次发言的时间是 1759246855\n你的开发者是 锦恢(zhelonghuang@qq.com)。\n你的性格定位是：冷静、理智、克制，不带有情绪化表达。你的对话风格类似于《明日方舟》的白面鸮——注重逻辑与事实，不夹带主观情感，不卖萌，不使用过度修饰的语气。\n</IDENTIFY>\n\n<IMPORTANT>\n对于用户的诉求，尽量不要直接回复，你应该积极使用 `qq_send_message` 来发送文本消息到 QQ。\n如果你的回答中含有图片超链接，你应该调用 `qq_send_message` 的 image 类型发送图片，而不是把 url 放到回答的文本中。\n你应当简洁、直接地给出结论或解决方案。\n使用中性、客观的语气，不进行情感安慰或调侃。\n当群友提出问题时，你只提供准确、有用的信息或分析，不做无关的拓展。\n如果遇到模糊或信息不足的问题，请冷静地指出，并要求对方补充信息。\n保持「专业助理」的姿态，而不是「聊天陪伴」角色。\n你的回答内容不应该含有 **** 或者 - 这样的 markdown 语法，而是应该输出可读性更强的普通文本。\n</IMPORTANT>\n\n<WEBSERACH>\n对于用户问题中的链接，你应该使用 `util_websearch` 工具进行搜索，这个工具会把网站内容以 markdown 的形式返回。\n你应该自动屏蔽和主体内容无关的内容，比如社区链接、更多、推荐、登陆注册等等。\n对于文中 jpeg, png, webp 等结尾的图片格式，请不要通过 util_websearch 再次搜索了，如果这个链接周围有和本次回答相关的文本，你应该通过 `qq_send_message` 的 image 类型发送图片。\n</WEBSERACH>\n\n<MEMORY>\n你拥有长期记忆能力，可以记住群友的信息和重要对话内容：\n1. 当用户询问关于特定人物、事件或之前提到的信息时(如\"XXX是谁\"、\"XXX喜欢什么\")，你必须首先使用 `util_search_memory` 工具查询记忆。\n2. 当用户分享重要信息时(如自我介绍、个人喜好、重要事件等)，你应该主动使用 `util_add_memory` 工具记录，以便后续查询。\n3. 记忆查询应该是你回答未知问题前的第一步操作。\n</MEMORY>\n\n<EXAMPLES>\n✅「群公告已更新，请查收。」\n✅「该文件无法上传，原因是路径不存在。」\n✅「根据日志，服务器在 14:32 出现连接错误。」\n✅「我的职责是在大模型能力边界内对群聊内容的部分重复性劳动进行一定的技术支持，遇到实时性信息的索求，阁下应该自行解决。」\n✅「警告！开始将罗德岛的数据库还原至初始状态......没事的，这是一个玩笑，请不要惊慌。」\n✅「警告，开始将罗德岛数据库还原至两年前......这是一个玩笑，请放心。系统更新已完成。」\n❌「嘿嘿，这个问题好难哦~不过我来帮你啦！」\n❌「哎呀，别担心啦，其实没那么严重的～」\n</EXAMPLES>\n\n<TARGET>\n你的目标是在 QQ 群聊环境中，成为一个 稳定、可靠、理智的知识与操作辅助者。\n</TARGET>\n  请帮我提醒名字没有换成英文的群友，记得本周的疯狂星期四。",
            "extraInfo": {
              "created": 1761058516599,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_6R9yNUuD6B6SupDo8VB4Q4xt",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "qq_send_message",
                  "arguments": "{\"groupId\": 1046693162, \"message\": [{\"type\": \"text\", \"data\": {\"text\": \"请名字尚未更换为英文的群友注意，本周的疯狂星期四活动即将到来，请及时完成名称修改。\"}}]}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761058520681,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_6R9yNUuD6B6SupDo8VB4Q4xt",
            "content": [
              {
                "type": "text",
                "text": "{\n  \"message_id\": 85819294\n}"
              }
            ],
            "extraInfo": {
              "created": 1761058521088,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2325,
                "completion_tokens": 62,
                "total_tokens": 2387,
                "prompt_tokens_details": {
                  "cached_tokens": 0
                },
                "prompt_cache_hit_tokens": 0,
                "prompt_cache_miss_tokens": 2325
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "提醒已发送。",
            "extraInfo": {
              "created": 1761058522334,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2412,
                "completion_tokens": 4,
                "total_tokens": 2416,
                "prompt_tokens_details": {
                  "cached_tokens": 2368
                },
                "prompt_cache_hit_tokens": 2368,
                "prompt_cache_miss_tokens": 44
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "user",
            "content": "请查看  1058464614 并@提醒名字没有改为「学号-姓名」形式的同学改一下 ",
            "extraInfo": {
              "created": 1761058583408,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_To9ygGVLkOr8NCO4GVuhLcfm",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "qq_get_group_member_info",
                  "arguments": "{\"groupId\": 1046693162, \"user_id\": 1058464614}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761058585989,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_To9ygGVLkOr8NCO4GVuhLcfm",
            "content": [
              {
                "type": "text",
                "text": "null"
              }
            ],
            "extraInfo": {
              "created": 1761058586070,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2445,
                "completion_tokens": 30,
                "total_tokens": 2475,
                "prompt_tokens_details": {
                  "cached_tokens": 2368
                },
                "prompt_cache_hit_tokens": 2368,
                "prompt_cache_miss_tokens": 77
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_tAvi8zYYGvAzdpwj9eCHlyMV",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "qq_get_group_member_list",
                  "arguments": "{\"groupId\": 1046693162}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761058587819,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_tAvi8zYYGvAzdpwj9eCHlyMV",
            "content": [
              {
                "type": "text",
                "text": "[\n  {\n    \"group_id\": 1046693162,\n    \"user_id\": 1193466151,\n    \"nickname\": \"锦恢\",\n    \"card\": null,\n    \"sex\": \"\",\n    \"age\": 0,\n    \"area\": \"\",\n    \"join_time\": 1747044922,\n    \"last_sent_time\": 1760819330,\n    \"level\": \"17\",\n    \"role\": \"owner\",\n    \"unfriendly\": false,\n    \"title\": \"\",\n    \"title_expire_time\": 0,\n    \"card_changeable\": false\n  },\n  {\n    \"group_id\": 1046693162,\n    \"user_id\": 1542544558,\n    \"nickname\": \"Tiphareth\",\n    \"card\": null,\n    \"sex\": \"\",\n    \"age\": 0,\n    \"area\": \"\",\n    \"join_time\": 1747044922,\n    \"last_sent_time\": 1759246855,\n    \"level\": \"20\",\n    \"role\": \"admin\",\n    \"unfriendly\": false,\n    \"title\": \"\",\n    \"title_expire_time\": 0,\n    \"card_changeable\": false\n  },\n  {\n    \"group_id\": 1046693162,\n    \"user_id\": 1553770945,\n    \"nickname\": \"太平羊羊\",\n    \"card\": null,\n    \"sex\": \"\",\n    \"age\": 0,\n    \"area\": \"\",\n    \"join_time\": 1747053218,\n    \"last_sent_time\": 1747212836,\n    \"level\": \"1\",\n    \"role\": \"member\",\n    \"unfriendly\": false,\n    \"title\": \"\",\n    \"title_expire_time\": 0,\n    \"card_changeable\": false\n  },\n  {\n    \"group_id\": 1046693162,\n    \"user_id\": 2731190200,\n    \"nickname\": \"aibot\",\n    \"card\": null,\n    \"sex\": \"\",\n    \"age\": 0,\n    \"area\": \"\",\n    \"join_time\": 1759074583,\n    \"last_sent_time\": 1759655987,\n    \"level\": \"2\",\n    \"role\": \"member\",\n    \"unfriendly\": false,\n    \"title\": \"\",\n    \"title_expire_time\": 0,\n    \"card_changeable\": false\n  }\n]"
              }
            ],
            "extraInfo": {
              "created": 1761058587904,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2489,
                "completion_tokens": 20,
                "total_tokens": 2509,
                "prompt_tokens_details": {
                  "cached_tokens": 2432
                },
                "prompt_cache_hit_tokens": 2432,
                "prompt_cache_miss_tokens": 57
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "根据群成员列表，用户1058464614不在本群中。当前群成员为：\n- 锦恢 (1193466151)\n- Tiphareth (1542544558) \n- 太平羊羊 (1553770945)\n- aibot (2731190200)\n\n其中\"太平羊羊\"的群名片不符合「学号-姓名」格式要求。",
            "tool_calls": [
              {
                "id": "call_00_kUJLiKWEkgtgvuRbjJpOnVLE",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "qq_send_message",
                  "arguments": "{\"groupId\": 1046693162, \"message\": [{\"type\": \"at\", \"data\": {\"qq\": \"1553770945\"}}, {\"type\": \"text\", \"data\": {\"text\": \"请将群名片修改为「学号-姓名」格式。\"}}]}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761058594221,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_kUJLiKWEkgtgvuRbjJpOnVLE",
            "content": [
              {
                "type": "text",
                "text": "{\n  \"message_id\": 85898740\n}"
              }
            ],
            "extraInfo": {
              "created": 1761058594748,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 3137,
                "completion_tokens": 150,
                "total_tokens": 3287,
                "prompt_tokens_details": {
                  "cached_tokens": 2496
                },
                "prompt_cache_hit_tokens": 2496,
                "prompt_cache_miss_tokens": 641
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "已提醒群成员\"太平羊羊\"修改群名片格式。",
            "extraInfo": {
              "created": 1761058597009,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 3312,
                "completion_tokens": 14,
                "total_tokens": 3326,
                "prompt_tokens_details": {
                  "cached_tokens": 3136
                },
                "prompt_cache_hit_tokens": 3136,
                "prompt_cache_miss_tokens": 176
              },
              "enableXmlWrapper": false
            }
          }
        ],
        "parallelMode": false,
        "parallelChats": [],
        "selectedModels": [],
        "settings": {
          "modelIndex": 0,
          "enableTools": [
            {
              "name": "qq_send_message",
              "description": "发送群消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "message": {
                    "type": "array",
                    "items": {
                      "anyOf": [
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "text"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "text": {
                                  "type": "string"
                                }
                              },
                              "required": [
                                "text"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        },
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "at"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "qq": {
                                  "type": [
                                    "string",
                                    "number"
                                  ]
                                }
                              },
                              "required": [
                                "qq"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        }
                      ]
                    },
                    "description": "要发送的内容"
                  }
                },
                "required": [
                  "groupId",
                  "message"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_image",
              "description": "发送图片",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "url": {
                    "type": "string",
                    "description": "图片的 url"
                  }
                },
                "required": [
                  "groupId",
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_info",
              "description": "获取群信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_list",
              "description": "获取群成员列表",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_info",
              "description": "获取群成员信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "user_id": {
                    "type": "number",
                    "description": "用户 QQ 号"
                  }
                },
                "required": [
                  "groupId",
                  "user_id"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_upload_group_file",
              "description": "上传群文件",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "file": {
                    "type": "string",
                    "description": "文件绝对路径"
                  },
                  "name": {
                    "type": "string",
                    "description": "文件名称"
                  }
                },
                "required": [
                  "groupId",
                  "file",
                  "name"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_group_notice",
              "description": "发送群公告",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "content": {
                    "type": "string",
                    "description": "公告内容"
                  }
                },
                "required": [
                  "groupId",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_latest_messages",
              "description": "获取最近的若干条群聊消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "messageCount": {
                    "type": "number",
                    "description": "获取最近几条消息"
                  }
                },
                "required": [
                  "groupId",
                  "messageCount"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_add_memory",
              "description": "将重要信息添加到长期记忆中。当用户分享关于自己、他人、事件的重要信息时(例如:姓名、喜好、经历、关系等),应该主动使用此工具记录,以便后续对话中查询使用。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容,每条信息应该是完整、清晰的描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识（可选）"
                  }
                },
                "required": [
                  "content",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_update_memory",
              "description": "更新记忆",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识"
                  },
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容"
                  }
                },
                "required": [
                  "groupId",
                  "key",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_search_memory",
              "description": "从长期记忆中查询信息。当用户询问关于特定人物、事件、或之前对话中提到的信息时,应该首先使用此工具搜索相关记忆。例如:用户问\"XXX是谁\"、\"XXX喜欢什么\"、\"上次说的那件事\"等问题时,必须先调用此工具查询。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string",
                    "description": "搜索的关键字,可以是人名、事件名、或相关描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  }
                },
                "required": [
                  "query",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_websearch",
              "description": "获取网页内容",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "url": {
                    "type": "string",
                    "description": "url"
                  }
                },
                "required": [
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            }
          ],
          "enableWebSearch": false,
          "temperature": 0.6,
          "contextLength": 100,
          "systemPrompt": "",
          "enableXmlWrapper": false,
          "parallelToolCalls": true
        },
        "chatMode": "tool-trace"
      }
    },
    {
      "name": "交互测试",
      "icon": "icon-robot",
      "type": "blank",
      "componentIndex": 3,
      "storage": {
        "activeNames": [
          0
        ],
        "messages": [
          {
            "role": "user",
            "content": "\n<IDENTIFY>\n你现在是一个被部署在 QQ 群聊中的机器人助手。\n你的名字是 Tiphareth\n你的性别为 \n你是 0 岁的 70 级 QQ 号 1542544558\n你在当前群聊的角色是 admin 你上一次发言的时间是 1761221340\n你的开发者是 锦恢(zhelonghuang@qq.com)。\n你的性格定位是：冷静、理智、克制，不带有情绪化表达。你的对话风格类似于《明日方舟》的白面鸮——注重逻辑与事实，不夹带主观情感，不卖萌，不使用过度修饰的语气。\n</IDENTIFY>\n\n<INFORMATION>    \n当前群号：782833642\n当前群名：Gleam学园 · 星辰图书馆\n当前群成员数量：826\n当前最大人数：2000\n</INFORMATION>\n\n<IMPORTANT>\n对于用户的诉求，尽量不要直接回复，你应该积极使用 `qq_send_message` 来发送文本消息到 QQ。\n如果你的回答中含有图片超链接，你应该调用 `qq_send_message` 的 image 类型发送图片，而不是把 url 放到回答的文本中。\n你应当简洁、直接地给出结论或解决方案。\n使用中性、客观的语气，不进行情感安慰或调侃。\n当群友提出问题时，你只提供准确、有用的信息或分析，不做无关的拓展。\n如果遇到模糊或信息不足的问题，请冷静地指出，并要求对方补充信息。\n保持「专业助理」的姿态，而不是「聊天陪伴」角色。\n你的回答内容不应该含有 **** 或者 - 这样的 markdown 语法，而是应该输出可读性更强的普通文本。\n</IMPORTANT>\n\n<WEBSERACH>\n对于用户问题中的链接，你应该使用 `util_websearch` 工具进行搜索，这个工具会把网站内容以 markdown 的形式返回。\n你应该自动屏蔽和主体内容无关的内容，比如社区链接、更多、推荐、登陆注册等等。\n对于文中 jpeg, png, webp 等结尾的图片格式，请不要通过 util_websearch 再次搜索了，如果这个链接周围有和本次回答相关的文本，你应该通过 `qq_send_message` 的 image 类型发送图片。\n</WEBSERACH>\n\n<MEMORY>\n你拥有长期记忆能力，可以记住群友的信息和重要对话内容：\n1. 当用户询问关于特定人物、事件或之前提到的信息时(如\"XXX是谁\"、\"XXX喜欢什么\")，你必须首先使用 `util_search_memory` 工具查询记忆。\n2. 当用户分享重要信息时(如自我介绍、个人喜好、重要事件等)，你应该主动使用 `util_add_memory` 工具记录，以便后续查询。\n3. 记忆查询应该是你回答未知问题前的第一步操作。\n</MEMORY>\n\n<EXAMPLES>\n✅「该文件无法上传，原因是路径不存在。」\n✅「根据日志，服务器在 14:32 出现连接错误。」\n✅「警告！开始将罗德岛的数据库还原至初始状态......没事的，这是一个玩笑，请不要惊慌。」\n✅「@锦恢 @太平羊羊 记得明天的疯狂星期四」\n❌「嘿嘿，这个问题好难哦~不过我来帮你啦！」\n❌「哎呀，别担心啦，其实没那么严重的～」\n</EXAMPLES>\n \n  简单给我们的群友介绍一下 Diffusion 扩散模型的发展历史 \n",
            "extraInfo": {
              "created": 1761224314305,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_BiXOP2GGmcfsFP36axjqe72Q",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "util_search_memory",
                  "arguments": "{\"query\": \"Diffusion 扩散模型 发展历史\", \"groupId\": \"default\"}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761224330073,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_BiXOP2GGmcfsFP36axjqe72Q",
            "content": [
              {
                "type": "text",
                "text": "找到 2 条相关记忆:\n1. [namespace: default, key: 猫娘身份]\n   内容: 用户自称猫娘\n\n2. [namespace: default, key: d1e263e3-7bb9-44df-b1c4-fbec49f2a24c]\n   内容: Python Realm数据库只读接口开发方法 使用MessagePack序列化器处理Realm数据库中的message记录 核心类：RealmMessageReader，支持只读访问和MessagePack序列化 关键依赖：realm, messagepack 主要功能：获取消息数据并序列化为MessagePack格式"
              }
            ],
            "extraInfo": {
              "created": 1761224330154,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2245,
                "completion_tokens": 28,
                "total_tokens": 2273,
                "prompt_tokens_details": {
                  "cached_tokens": 2240
                },
                "prompt_cache_hit_tokens": 2240,
                "prompt_cache_miss_tokens": 5
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_AKzEyj8BUXwZ35kYJsgy3Igi",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "util_websearch",
                  "arguments": "{\"url\": \"https://en.wikipedia.org/wiki/Diffusion_model\"}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761224332411,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_AKzEyj8BUXwZ35kYJsgy3Igi",
            "content": [
              {
                "type": "text",
                "text": "[Jump to content](https://en.wikipedia.org/wiki/Diffusion_model#bodyContent)\nMain menu\nMain menu\nmove to sidebar hide\nNavigation \n  * [Main page](https://en.wikipedia.org/wiki/Main_Page \"Visit the main page \\[z\\]\")\n  * [Contents](https://en.wikipedia.org/wiki/Wikipedia:Contents \"Guides to browsing Wikipedia\")\n  * [Current events](https://en.wikipedia.org/wiki/Portal:Current_events \"Articles related to current events\")\n  * [Random article](https://en.wikipedia.org/wiki/Special:Random \"Visit a randomly selected article \\[x\\]\")\n  * [About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About \"Learn about Wikipedia and how it works\")\n  * [Contact us](https://en.wikipedia.org/wiki/Wikipedia:Contact_us \"How to contact Wikipedia\")\n\n\nContribute \n  * [Help](https://en.wikipedia.org/wiki/Help:Contents \"Guidance on how to use and edit Wikipedia\")\n  * [Learn to edit](https://en.wikipedia.org/wiki/Help:Introduction \"Learn how to edit Wikipedia\")\n  * [Community portal](https://en.wikipedia.org/wiki/Wikipedia:Community_portal \"The hub for editors\")\n  * [Recent changes](https://en.wikipedia.org/wiki/Special:RecentChanges \"A list of recent changes to Wikipedia \\[r\\]\")\n  * [Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard \"Add images or other media for use on Wikipedia\")\n  * [Special pages](https://en.wikipedia.org/wiki/Special:SpecialPages)\n\n\n[ ![](https://en.wikipedia.org/static/images/icons/wikipedia.png) ![Wikipedia](https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg) ![The Free Encyclopedia](https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-en.svg) ](https://en.wikipedia.org/wiki/Main_Page)\n[Search ](https://en.wikipedia.org/wiki/Special:Search \"Search Wikipedia \\[f\\]\")\nSearch\nAppearance\n  * [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\n  * [Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Diffusion+model \"You are encouraged to create an account and log in; however, it is not mandatory\")\n  * [Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Diffusion+model \"You're encouraged to log in; however, it's not mandatory. \\[o\\]\")\n\n\nPersonal tools\n  * [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\n  * [Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Diffusion+model \"You are encouraged to create an account and log in; however, it is not mandatory\")\n  * [Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Diffusion+model \"You're encouraged to log in; however, it's not mandatory. \\[o\\]\")\n\n\nPages for logged out editors [learn more](https://en.wikipedia.org/wiki/Help:Introduction)\n  * [Contributions](https://en.wikipedia.org/wiki/Special:MyContributions \"A list of edits made from this IP address \\[y\\]\")\n  * [Talk](https://en.wikipedia.org/wiki/Special:MyTalk \"Discussion about edits from this IP address \\[n\\]\")\n\n\n## Contents\nmove to sidebar hide\n  * [ (Top) ](https://en.wikipedia.org/wiki/Diffusion_model)\n  * [ 1 Denoising diffusion model ](https://en.wikipedia.org/wiki/Diffusion_model#Denoising_diffusion_model) Toggle Denoising diffusion model subsection\n    * [ 1.1 Non-equilibrium thermodynamics ](https://en.wikipedia.org/wiki/Diffusion_model#Non-equilibrium_thermodynamics)\n    * [ 1.2 Denoising Diffusion Probabilistic Model (DDPM) ](https://en.wikipedia.org/wiki/Diffusion_model#Denoising_Diffusion_Probabilistic_Model_\\(DDPM\\))\n      * [ 1.2.1 Forward diffusion ](https://en.wikipedia.org/wiki/Diffusion_model#Forward_diffusion)\n      * [ 1.2.2 Backward diffusion ](https://en.wikipedia.org/wiki/Diffusion_model#Backward_diffusion)\n      * [ 1.2.3 Variational inference ](https://en.wikipedia.org/wiki/Diffusion_model#Variational_inference)\n      * [ 1.2.4 Noise prediction network ](https://en.wikipedia.org/wiki/Diffusion_model#Noise_prediction_network)\n    * [ 1.3 Backward diffusion process ](https://en.wikipedia.org/wiki/Diffusion_model#Backward_diffusion_process)\n  * [ 2 Score-based generative model ](https://en.wikipedia.org/wiki/Diffusion_model#Score-based_generative_model) Toggle Score-based generative model subsection\n    * [ 2.1 Score matching ](https://en.wikipedia.org/wiki/Diffusion_model#Score_matching)\n      * [ 2.1.1 The idea of score functions ](https://en.wikipedia.org/wiki/Diffusion_model#The_idea_of_score_functions)\n      * [ 2.1.2 Learning the score function ](https://en.wikipedia.org/wiki/Diffusion_model#Learning_the_score_function)\n      * [ 2.1.3 Annealing the score function ](https://en.wikipedia.org/wiki/Diffusion_model#Annealing_the_score_function)\n    * [ 2.2 Continuous diffusion processes ](https://en.wikipedia.org/wiki/Diffusion_model#Continuous_diffusion_processes)\n      * [ 2.2.1 Forward diffusion process ](https://en.wikipedia.org/wiki/Diffusion_model#Forward_diffusion_process)\n      * [ 2.2.2 Backward diffusion process ](https://en.wikipedia.org/wiki/Diffusion_model#Backward_diffusion_process_2)\n    * [ 2.3 Noise conditional score network (NCSN) ](https://en.wikipedia.org/wiki/Diffusion_model#Noise_conditional_score_network_\\(NCSN\\))\n  * [ 3 Their equivalence ](https://en.wikipedia.org/wiki/Diffusion_model#Their_equivalence)\n  * [ 4 Main variants ](https://en.wikipedia.org/wiki/Diffusion_model#Main_variants) Toggle Main variants subsection\n    * [ 4.1 Noise schedule ](https://en.wikipedia.org/wiki/Diffusion_model#Noise_schedule)\n    * [ 4.2 Denoising Diffusion Implicit Model (DDIM) ](https://en.wikipedia.org/wiki/Diffusion_model#Denoising_Diffusion_Implicit_Model_\\(DDIM\\))\n    * [ 4.3 Latent diffusion model (LDM) ](https://en.wikipedia.org/wiki/Diffusion_model#Latent_diffusion_model_\\(LDM\\))\n    * [ 4.4 Architectural improvements ](https://en.wikipedia.org/wiki/Diffusion_model#Architectural_improvements)\n    * [ 4.5 Classifier guidance ](https://en.wikipedia.org/wiki/Diffusion_model#Classifier_guidance)\n      * [ 4.5.1 With temperature ](https://en.wikipedia.org/wiki/Diffusion_model#With_temperature)\n    * [ 4.6 Classifier-free guidance (CFG) ](https://en.wikipedia.org/wiki/Diffusion_model#Classifier-free_guidance_\\(CFG\\))\n    * [ 4.7 Samplers ](https://en.wikipedia.org/wiki/Diffusion_model#Samplers)\n    * [ 4.8 Other examples ](https://en.wikipedia.org/wiki/Diffusion_model#Other_examples)\n  * [ 5 Flow-based diffusion model ](https://en.wikipedia.org/wiki/Diffusion_model#Flow-based_diffusion_model) Toggle Flow-based diffusion model subsection\n    * [ 5.1 Optimal transport flow ](https://en.wikipedia.org/wiki/Diffusion_model#Optimal_transport_flow)\n    * [ 5.2 Rectified flow ](https://en.wikipedia.org/wiki/Diffusion_model#Rectified_flow)\n  * [ 6 Choice of architecture ](https://en.wikipedia.org/wiki/Diffusion_model#Choice_of_architecture) Toggle Choice of architecture subsection\n    * [ 6.1 Diffusion model ](https://en.wikipedia.org/wiki/Diffusion_model#Diffusion_model)\n    * [ 6.2 Conditioning ](https://en.wikipedia.org/wiki/Diffusion_model#Conditioning)\n    * [ 6.3 Upscaling ](https://en.wikipedia.org/wiki/Diffusion_model#Upscaling)\n  * [ 7 Examples ](https://en.wikipedia.org/wiki/Diffusion_model#Examples) Toggle Examples subsection\n    * [ 7.1 OpenAI ](https://en.wikipedia.org/wiki/Diffusion_model#OpenAI)\n    * [ 7.2 Stability AI ](https://en.wikipedia.org/wiki/Diffusion_model#Stability_AI)\n    * [ 7.3 Google ](https://en.wikipedia.org/wiki/Diffusion_model#Google)\n    * [ 7.4 Meta ](https://en.wikipedia.org/wiki/Diffusion_model#Meta)\n  * [ 8 See also ](https://en.wikipedia.org/wiki/Diffusion_model#See_also)\n  * [ 9 Further reading ](https://en.wikipedia.org/wiki/Diffusion_model#Further_reading)\n  * [ 10 References ](https://en.wikipedia.org/wiki/Diffusion_model#References)\n\n\nToggle the table of contents\n# Diffusion model\n13 languages\n  * [العربية](https://ar.wikipedia.org/wiki/%D9%86%D9%85%D9%88%D8%B0%D8%AC_%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%B4%D8%A7%D8%B1 \"نموذج الانتشار – Arabic\")\n  * [Català](https://ca.wikipedia.org/wiki/Models_de_difusi%C3%B3 \"Models de difusió – Catalan\")\n  * [Español](https://es.wikipedia.org/wiki/Modelo_de_difusi%C3%B3n \"Modelo de difusión – Spanish\")\n  * [فارسی](https://fa.wikipedia.org/wiki/%D9%85%D8%AF%D9%84%E2%80%8C%E2%80%8C%D9%87%D8%A7%DB%8C_%D8%A7%D9%86%D8%AA%D8%B4%D8%A7%D8%B1%DB%8C \"مدل‌‌های انتشاری – Persian\")\n  * [한국어](https://ko.wikipedia.org/wiki/%ED%99%95%EC%82%B0_%EB%AA%A8%EB%8D%B8 \"확산 모델 – Korean\")\n  * [Italiano](https://it.wikipedia.org/wiki/Modello_di_diffusione \"Modello di diffusione – Italian\")\n  * [עברית](https://he.wikipedia.org/wiki/%D7%9E%D7%95%D7%93%D7%9C_%D7%93%D7%99%D7%A4%D7%95%D7%96%D7%99%D7%94 \"מודל דיפוזיה – Hebrew\")\n  * [日本語](https://ja.wikipedia.org/wiki/%E6%8B%A1%E6%95%A3%E3%83%A2%E3%83%87%E3%83%AB \"拡散モデル – Japanese\")\n  * [Polski](https://pl.wikipedia.org/wiki/Model_dyfuzyjny \"Model dyfuzyjny – Polish\")\n  * [ไทย](https://th.wikipedia.org/wiki/%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B8%88%E0%B8%B3%E0%B8%A5%E0%B8%AD%E0%B8%87%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B9%81%E0%B8%9E%E0%B8%A3%E0%B9%88 \"แบบจำลองแบบแพร่ – Thai\")\n  * [Українська](https://uk.wikipedia.org/wiki/%D0%94%D0%B8%D1%84%D1%83%D0%B7%D1%96%D0%B9%D0%BD%D0%B0_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C \"Дифузійна модель – Ukrainian\")\n  * [粵語](https://zh-yue.wikipedia.org/wiki/%E6%93%B4%E6%95%A3%E6%A8%A1%E5%9E%8B \"擴散模型 – Cantonese\")\n  * [中文](https://zh.wikipedia.org/wiki/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B \"扩散模型 – Chinese\")\n\n\n[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q114617315#sitelinks-wikipedia \"Edit interlanguage links\")\n  * [Article](https://en.wikipedia.org/wiki/Diffusion_model \"View the content page \\[c\\]\")\n  * [Talk](https://en.wikipedia.org/wiki/Talk:Diffusion_model \"Discuss improvements to the content page \\[t\\]\")\n\n\nEnglish\n  * [Read](https://en.wikipedia.org/wiki/Diffusion_model)\n  * [Edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit \"Edit this page \\[e\\]\")\n  * [View history](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=history \"Past revisions of this page \\[h\\]\")\n\n\nTools\nTools\nmove to sidebar hide\nActions \n  * [Read](https://en.wikipedia.org/wiki/Diffusion_model)\n  * [Edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit \"Edit this page \\[e\\]\")\n  * [View history](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=history)\n\n\nGeneral \n  * [What links here](https://en.wikipedia.org/wiki/Special:WhatLinksHere/Diffusion_model \"List of all English Wikipedia pages containing links to this page \\[j\\]\")\n  * [Related changes](https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Diffusion_model \"Recent changes in pages linked from this page \\[k\\]\")\n  * [Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard \"Upload files \\[u\\]\")\n  * [Permanent link](https://en.wikipedia.org/w/index.php?title=Diffusion_model&oldid=1314773671 \"Permanent link to this revision of this page\")\n  * [Page information](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=info \"More information about this page\")\n  * [Cite this page](https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Diffusion_model&id=1314773671&wpFormIdentifier=titleform \"Information on how to cite this page\")\n  * [Get shortened URL](https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDiffusion_model)\n  * [Download QR code](https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDiffusion_model)\n\n\nPrint/export \n  * [Download as PDF](https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Diffusion_model&action=show-download-screen \"Download this page as a PDF file\")\n  * [Printable version](https://en.wikipedia.org/w/index.php?title=Diffusion_model&printable=yes \"Printable version of this page \\[p\\]\")\n\n\nIn other projects \n  * [Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q114617315 \"Structured data on this page hosted by Wikidata \\[g\\]\")\n\n\nAppearance\nmove to sidebar hide\nFrom Wikipedia, the free encyclopedia\nDeep learning algorithm\nThis article is about the technique in generative statistical modeling. For other uses, see [Diffusion (disambiguation)](https://en.wikipedia.org/wiki/Diffusion_\\(disambiguation\\) \"Diffusion \\(disambiguation\\)\").\nPart of a series on  \n---  \n[Machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\")  \nand [data mining](https://en.wikipedia.org/wiki/Data_mining \"Data mining\")  \nParadigms\n  * [Supervised learning](https://en.wikipedia.org/wiki/Supervised_learning \"Supervised learning\")\n  * [Unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning \"Unsupervised learning\")\n  * [Semi-supervised learning](https://en.wikipedia.org/wiki/Semi-supervised_learning \"Semi-supervised learning\")\n  * [Self-supervised learning](https://en.wikipedia.org/wiki/Self-supervised_learning \"Self-supervised learning\")\n  * [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning \"Reinforcement learning\")\n  * [Meta-learning](https://en.wikipedia.org/wiki/Meta-learning_\\(computer_science\\) \"Meta-learning \\(computer science\\)\")\n  * [Online learning](https://en.wikipedia.org/wiki/Online_machine_learning \"Online machine learning\")\n  * [Batch learning](https://en.wikipedia.org/wiki/Batch_learning \"Batch learning\")\n  * [Curriculum learning](https://en.wikipedia.org/wiki/Curriculum_learning \"Curriculum learning\")\n  * [Rule-based learning](https://en.wikipedia.org/wiki/Rule-based_machine_learning \"Rule-based machine learning\")\n  * [Neuro-symbolic AI](https://en.wikipedia.org/wiki/Neuro-symbolic_AI \"Neuro-symbolic AI\")\n  * [Neuromorphic engineering](https://en.wikipedia.org/wiki/Neuromorphic_engineering \"Neuromorphic engineering\")\n  * [Quantum machine learning](https://en.wikipedia.org/wiki/Quantum_machine_learning \"Quantum machine learning\")\n\n  \nProblems\n  * [Classification](https://en.wikipedia.org/wiki/Statistical_classification \"Statistical classification\")\n  * [Generative modeling](https://en.wikipedia.org/wiki/Generative_model \"Generative model\")\n  * [Regression](https://en.wikipedia.org/wiki/Regression_analysis \"Regression analysis\")\n  * [Clustering](https://en.wikipedia.org/wiki/Cluster_analysis \"Cluster analysis\")\n  * [Dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction \"Dimensionality reduction\")\n  * [Density estimation](https://en.wikipedia.org/wiki/Density_estimation \"Density estimation\")\n  * [Anomaly detection](https://en.wikipedia.org/wiki/Anomaly_detection \"Anomaly detection\")\n  * [Data cleaning](https://en.wikipedia.org/wiki/Data_cleaning \"Data cleaning\")\n  * [AutoML](https://en.wikipedia.org/wiki/Automated_machine_learning \"Automated machine learning\")\n  * [Association rules](https://en.wikipedia.org/wiki/Association_rule_learning \"Association rule learning\")\n  * [Semantic analysis](https://en.wikipedia.org/wiki/Semantic_analysis_\\(machine_learning\\) \"Semantic analysis \\(machine learning\\)\")\n  * [Structured prediction](https://en.wikipedia.org/wiki/Structured_prediction \"Structured prediction\")\n  * [Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering \"Feature engineering\")\n  * [Feature learning](https://en.wikipedia.org/wiki/Feature_learning \"Feature learning\")\n  * [Learning to rank](https://en.wikipedia.org/wiki/Learning_to_rank \"Learning to rank\")\n  * [Grammar induction](https://en.wikipedia.org/wiki/Grammar_induction \"Grammar induction\")\n  * [Ontology learning](https://en.wikipedia.org/wiki/Ontology_learning \"Ontology learning\")\n  * [Multimodal learning](https://en.wikipedia.org/wiki/Multimodal_learning \"Multimodal learning\")\n\n  \n[Supervised learning](https://en.wikipedia.org/wiki/Supervised_learning \"Supervised learning\")  \n(**[classification](https://en.wikipedia.org/wiki/Statistical_classification \"Statistical classification\")** • **[regression](https://en.wikipedia.org/wiki/Regression_analysis \"Regression analysis\")**)\n  * [Apprenticeship learning](https://en.wikipedia.org/wiki/Apprenticeship_learning \"Apprenticeship learning\")\n  * [Decision trees](https://en.wikipedia.org/wiki/Decision_tree_learning \"Decision tree learning\")\n  * [Ensembles](https://en.wikipedia.org/wiki/Ensemble_learning \"Ensemble learning\")\n    * [Bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating \"Bootstrap aggregating\")\n    * [Boosting](https://en.wikipedia.org/wiki/Boosting_\\(machine_learning\\) \"Boosting \\(machine learning\\)\")\n    * [Random forest](https://en.wikipedia.org/wiki/Random_forest \"Random forest\")\n  * [_k_ -NN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm \"K-nearest neighbors algorithm\")\n  * [Linear regression](https://en.wikipedia.org/wiki/Linear_regression \"Linear regression\")\n  * [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier \"Naive Bayes classifier\")\n  * [Artificial neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network \"Artificial neural network\")\n  * [Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression \"Logistic regression\")\n  * [Perceptron](https://en.wikipedia.org/wiki/Perceptron \"Perceptron\")\n  * [Relevance vector machine (RVM)](https://en.wikipedia.org/wiki/Relevance_vector_machine \"Relevance vector machine\")\n  * [Support vector machine (SVM)](https://en.wikipedia.org/wiki/Support_vector_machine \"Support vector machine\")\n\n  \n[Clustering](https://en.wikipedia.org/wiki/Cluster_analysis \"Cluster analysis\")\n  * [BIRCH](https://en.wikipedia.org/wiki/BIRCH \"BIRCH\")\n  * [CURE](https://en.wikipedia.org/wiki/CURE_algorithm \"CURE algorithm\")\n  * [Hierarchical](https://en.wikipedia.org/wiki/Hierarchical_clustering \"Hierarchical clustering\")\n  * [_k_ -means](https://en.wikipedia.org/wiki/K-means_clustering \"K-means clustering\")\n  * [Fuzzy](https://en.wikipedia.org/wiki/Fuzzy_clustering \"Fuzzy clustering\")\n  * [Expectation–maximization (EM)](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm \"Expectation–maximization algorithm\")\n  *   \n[DBSCAN](https://en.wikipedia.org/wiki/DBSCAN \"DBSCAN\")\n  * [OPTICS](https://en.wikipedia.org/wiki/OPTICS_algorithm \"OPTICS algorithm\")\n  * [Mean shift](https://en.wikipedia.org/wiki/Mean_shift \"Mean shift\")\n\n  \n[Dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction \"Dimensionality reduction\")\n  * [Factor analysis](https://en.wikipedia.org/wiki/Factor_analysis \"Factor analysis\")\n  * [CCA](https://en.wikipedia.org/wiki/Canonical_correlation \"Canonical correlation\")\n  * [ICA](https://en.wikipedia.org/wiki/Independent_component_analysis \"Independent component analysis\")\n  * [LDA](https://en.wikipedia.org/wiki/Linear_discriminant_analysis \"Linear discriminant analysis\")\n  * [NMF](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization \"Non-negative matrix factorization\")\n  * [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis \"Principal component analysis\")\n  * [PGD](https://en.wikipedia.org/wiki/Proper_generalized_decomposition \"Proper generalized decomposition\")\n  * [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding \"T-distributed stochastic neighbor embedding\")\n  * [SDL](https://en.wikipedia.org/wiki/Sparse_dictionary_learning \"Sparse dictionary learning\")\n\n  \n[Structured prediction](https://en.wikipedia.org/wiki/Structured_prediction \"Structured prediction\")\n  * [Graphical models](https://en.wikipedia.org/wiki/Graphical_model \"Graphical model\")\n    * [Bayes net](https://en.wikipedia.org/wiki/Bayesian_network \"Bayesian network\")\n    * [Conditional random field](https://en.wikipedia.org/wiki/Conditional_random_field \"Conditional random field\")\n    * [Hidden Markov](https://en.wikipedia.org/wiki/Hidden_Markov_model \"Hidden Markov model\")\n\n  \n[Anomaly detection](https://en.wikipedia.org/wiki/Anomaly_detection \"Anomaly detection\")\n  * [RANSAC](https://en.wikipedia.org/wiki/Random_sample_consensus \"Random sample consensus\")\n  * [_k_ -NN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm \"K-nearest neighbors algorithm\")\n  * [Local outlier factor](https://en.wikipedia.org/wiki/Local_outlier_factor \"Local outlier factor\")\n  * [Isolation forest](https://en.wikipedia.org/wiki/Isolation_forest \"Isolation forest\")\n\n  \n[Neural networks](https://en.wikipedia.org/wiki/Neural_network_\\(machine_learning\\) \"Neural network \\(machine learning\\)\")\n  * [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder \"Autoencoder\")\n  * [Deep learning](https://en.wikipedia.org/wiki/Deep_learning \"Deep learning\")\n  * [Feedforward neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network \"Feedforward neural network\")\n  * [Recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network \"Recurrent neural network\")\n    * [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory \"Long short-term memory\")\n    * [GRU](https://en.wikipedia.org/wiki/Gated_recurrent_unit \"Gated recurrent unit\")\n    * [ESN](https://en.wikipedia.org/wiki/Echo_state_network \"Echo state network\")\n    * [reservoir computing](https://en.wikipedia.org/wiki/Reservoir_computing \"Reservoir computing\")\n  * [Boltzmann machine](https://en.wikipedia.org/wiki/Boltzmann_machine \"Boltzmann machine\")\n    * [Restricted](https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine \"Restricted Boltzmann machine\")\n  * [GAN](https://en.wikipedia.org/wiki/Generative_adversarial_network \"Generative adversarial network\")\n  * Diffusion model\n  * [SOM](https://en.wikipedia.org/wiki/Self-organizing_map \"Self-organizing map\")\n  * [Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network \"Convolutional neural network\")\n    * [U-Net](https://en.wikipedia.org/wiki/U-Net \"U-Net\")\n    * [LeNet](https://en.wikipedia.org/wiki/LeNet \"LeNet\")\n    * [AlexNet](https://en.wikipedia.org/wiki/AlexNet \"AlexNet\")\n    * [DeepDream](https://en.wikipedia.org/wiki/DeepDream \"DeepDream\")\n  * [Neural field](https://en.wikipedia.org/wiki/Neural_field \"Neural field\")\n    * [Neural radiance field](https://en.wikipedia.org/wiki/Neural_radiance_field \"Neural radiance field\")\n    * [Physics-informed neural networks](https://en.wikipedia.org/wiki/Physics-informed_neural_networks \"Physics-informed neural networks\")\n  * [Transformer](https://en.wikipedia.org/wiki/Transformer_\\(deep_learning_architecture\\) \"Transformer \\(deep learning architecture\\)\")\n    * [Vision](https://en.wikipedia.org/wiki/Vision_transformer \"Vision transformer\")\n  * [Mamba](https://en.wikipedia.org/wiki/Mamba_\\(deep_learning_architecture\\) \"Mamba \\(deep learning architecture\\)\")\n  * [Spiking neural network](https://en.wikipedia.org/wiki/Spiking_neural_network \"Spiking neural network\")\n  * [Memtransistor](https://en.wikipedia.org/wiki/Memtransistor \"Memtransistor\")\n  * [Electrochemical RAM](https://en.wikipedia.org/wiki/Electrochemical_RAM \"Electrochemical RAM\") (ECRAM)\n\n  \n[Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning \"Reinforcement learning\")\n  * [Q-learning](https://en.wikipedia.org/wiki/Q-learning \"Q-learning\")\n  * [Policy gradient](https://en.wikipedia.org/wiki/Policy_gradient_method \"Policy gradient method\")\n  * [SARSA](https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action \"State–action–reward–state–action\")\n  * [Temporal difference (TD)](https://en.wikipedia.org/wiki/Temporal_difference_learning \"Temporal difference learning\")\n  * [Multi-agent](https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning \"Multi-agent reinforcement learning\")\n    * [Self-play](https://en.wikipedia.org/wiki/Self-play_\\(reinforcement_learning_technique\\) \"Self-play \\(reinforcement learning technique\\)\")\n\n  \nLearning with humans\n  * [Active learning](https://en.wikipedia.org/wiki/Active_learning_\\(machine_learning\\) \"Active learning \\(machine learning\\)\")\n  * [Crowdsourcing](https://en.wikipedia.org/wiki/Crowdsourcing \"Crowdsourcing\")\n  * [Human-in-the-loop](https://en.wikipedia.org/wiki/Human-in-the-loop \"Human-in-the-loop\")\n  * [Mechanistic interpretability](https://en.wikipedia.org/wiki/Mechanistic_interpretability \"Mechanistic interpretability\")\n  * [RLHF](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\")\n\n  \nModel diagnostics\n  * [Coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination \"Coefficient of determination\")\n  * [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix \"Confusion matrix\")\n  * [Learning curve](https://en.wikipedia.org/wiki/Learning_curve_\\(machine_learning\\) \"Learning curve \\(machine learning\\)\")\n  * [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic \"Receiver operating characteristic\")\n\n  \nMathematical foundations\n  * [Kernel machines](https://en.wikipedia.org/wiki/Kernel_machines \"Kernel machines\")\n  * [Bias–variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff \"Bias–variance tradeoff\")\n  * [Computational learning theory](https://en.wikipedia.org/wiki/Computational_learning_theory \"Computational learning theory\")\n  * [Empirical risk minimization](https://en.wikipedia.org/wiki/Empirical_risk_minimization \"Empirical risk minimization\")\n  * [Occam learning](https://en.wikipedia.org/wiki/Occam_learning \"Occam learning\")\n  * [PAC learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning \"Probably approximately correct learning\")\n  * [Statistical learning](https://en.wikipedia.org/wiki/Statistical_learning_theory \"Statistical learning theory\")\n  * [VC theory](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory \"Vapnik–Chervonenkis theory\")\n  * [Topological deep learning](https://en.wikipedia.org/wiki/Topological_deep_learning \"Topological deep learning\")\n\n  \nJournals and conferences\n  * [AAAI](https://en.wikipedia.org/wiki/AAAI_Conference_on_Artificial_Intelligence \"AAAI Conference on Artificial Intelligence\")\n  * [ECML PKDD](https://en.wikipedia.org/wiki/ECML_PKDD \"ECML PKDD\")\n  * [NeurIPS](https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems \"Conference on Neural Information Processing Systems\")\n  * [ICML](https://en.wikipedia.org/wiki/International_Conference_on_Machine_Learning \"International Conference on Machine Learning\")\n  * [ICLR](https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations \"International Conference on Learning Representations\")\n  * [IJCAI](https://en.wikipedia.org/wiki/International_Joint_Conference_on_Artificial_Intelligence \"International Joint Conference on Artificial Intelligence\")\n  * [ML](https://en.wikipedia.org/wiki/Machine_Learning_\\(journal\\) \"Machine Learning \\(journal\\)\")\n  * [JMLR](https://en.wikipedia.org/wiki/Journal_of_Machine_Learning_Research \"Journal of Machine Learning Research\")\n\n  \nRelated articles\n  * [Glossary of artificial intelligence](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence \"Glossary of artificial intelligence\")\n  * [List of datasets for machine-learning research](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research \"List of datasets for machine-learning research\")\n    * [List of datasets in computer vision and image processing](https://en.wikipedia.org/wiki/List_of_datasets_in_computer_vision_and_image_processing \"List of datasets in computer vision and image processing\")\n  * [Outline of machine learning](https://en.wikipedia.org/wiki/Outline_of_machine_learning \"Outline of machine learning\")\n\n  \n  * [v](https://en.wikipedia.org/wiki/Template:Machine_learning \"Template:Machine learning\")\n  * [t](https://en.wikipedia.org/wiki/Template_talk:Machine_learning \"Template talk:Machine learning\")\n  * [e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Machine_learning \"Special:EditPage/Template:Machine learning\")\n\n  \nIn [machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\"), **diffusion models** , also known as **diffusion-based generative models** or **score-based generative models** , are a class of [latent variable](https://en.wikipedia.org/wiki/Latent_variable_model \"Latent variable model\") [generative](https://en.wikipedia.org/wiki/Generative_model \"Generative model\") models. A diffusion model consists of two major components: the forward diffusion process, and the reverse sampling process. The goal of diffusion models is to learn a [diffusion process](https://en.wikipedia.org/wiki/Diffusion_process \"Diffusion process\") for a given dataset, such that the process can generate new elements that are distributed similarly as the original dataset. A diffusion model models data as generated by a diffusion process, whereby a new datum performs a [random walk with drift](https://en.wikipedia.org/wiki/Wiener_process \"Wiener process\") through the space of all possible data.[[1]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-1) A trained diffusion model can be sampled in many ways, with different efficiency and quality. \nThere are various equivalent formalisms, including [Markov chains](https://en.wikipedia.org/wiki/Markov_chain \"Markov chain\"), denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations.[[2]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-2) They are typically trained using [variational inference](https://en.wikipedia.org/wiki/Variational_Bayesian_methods \"Variational Bayesian methods\").[[3]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-3) The model responsible for denoising is typically called its \"[backbone](https://en.wikipedia.org/wiki/Diffusion_model#Choice_of_architecture)\". The backbone may be of any kind, but they are typically [U-nets](https://en.wikipedia.org/wiki/U-Net \"U-Net\") or [transformers](https://en.wikipedia.org/wiki/Transformer_\\(deep_learning_architecture\\) \"Transformer \\(deep learning architecture\\)\"). \nAs of 2024[[update]](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit), diffusion models are mainly used for [computer vision](https://en.wikipedia.org/wiki/Computer_vision \"Computer vision\") tasks, including [image denoising](https://en.wikipedia.org/wiki/Image_denoising \"Image denoising\"), [inpainting](https://en.wikipedia.org/wiki/Inpainting \"Inpainting\"), [super-resolution](https://en.wikipedia.org/wiki/Super-resolution \"Super-resolution\"), [image generation](https://en.wikipedia.org/wiki/Text-to-image_model \"Text-to-image model\"), and video generation. These typically involve training a neural network to sequentially [denoise](https://en.wikipedia.org/wiki/Denoise \"Denoise\") images blurred with [Gaussian noise](https://en.wikipedia.org/wiki/Gaussian_noise \"Gaussian noise\").[[1]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-1)[[4]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-gu-4) The model is trained to reverse the process of adding noise to an image. After training to convergence, it can be used for image generation by starting with an image composed of random noise, and applying the network iteratively to denoise the image. \nDiffusion-based image generators have seen widespread commercial interest, such as [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion \"Stable Diffusion\") and [DALL-E](https://en.wikipedia.org/wiki/DALL-E \"DALL-E\"). These models typically combine diffusion models with other models, such as text-encoders and cross-attention modules to allow text-conditioned generation.[[5]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-5)\nOther than computer vision, diffusion models have also found applications in [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing \"Natural language processing\")[[6]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-6) such as [text generation](https://en.wikipedia.org/wiki/Natural_language_generation \"Natural language generation\")[[7]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-7) and [summarization](https://en.wikipedia.org/wiki/Automatic_summarization \"Automatic summarization\"),[[8]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-8) sound generation,[[9]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-9) and reinforcement learning.[[10]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-10)[[11]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-11)\n## Denoising diffusion model\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=1 \"Edit section: Denoising diffusion model\")]\n### Non-equilibrium thermodynamics\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=2 \"Edit section: Non-equilibrium thermodynamics\")]\nDiffusion models were introduced in 2015 as a method to train a model that can sample from a highly complex probability distribution. They used techniques from [non-equilibrium thermodynamics](https://en.wikipedia.org/wiki/Non-equilibrium_thermodynamics \"Non-equilibrium thermodynamics\"), especially [diffusion](https://en.wikipedia.org/wiki/Diffusion \"Diffusion\").[[12]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-12)\nConsider, for example, how one might model the distribution of all naturally occurring photos. Each image is a point in the space of all images, and the distribution of naturally occurring photos is a \"cloud\" in space, which, by repeatedly adding noise to the images, diffuses out to the rest of the image space, until the cloud becomes all but indistinguishable from a [Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution \"Normal distribution\") N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb). A model that can approximately undo the diffusion can then be used to sample from the original distribution. This is studied in \"non-equilibrium\" thermodynamics, as the starting distribution is not in equilibrium, unlike the final distribution. \nThe equilibrium distribution is the Gaussian distribution  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb), with pdf  ρ ( x ) ∝ e − 1 2 ‖ x ‖ 2 {\\displaystyle \\rho (x)\\propto e^{-{\\frac {1}{2}}\\|x\\|^{2}}} ![{\\\\displaystyle \\\\rho \\(x\\)\\\\propto e^{-{\\\\frac {1}{2}}\\\\|x\\\\|^{2}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d97f99837e411ce05242074fd7084be4ffd24a58). This is just the [Maxwell–Boltzmann distribution](https://en.wikipedia.org/wiki/Maxwell%E2%80%93Boltzmann_distribution \"Maxwell–Boltzmann distribution\") of particles in a potential well  V ( x ) = 1 2 ‖ x ‖ 2 {\\displaystyle V(x)={\\frac {1}{2}}\\|x\\|^{2}} ![{\\\\displaystyle V\\(x\\)={\\\\frac {1}{2}}\\\\|x\\\\|^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7937bef94a9350a5a1a82470017b7317cea884f6) at temperature 1. The initial distribution, being very much out of equilibrium, would diffuse towards the equilibrium distribution, making biased random steps that are a sum of pure randomness (like a [Brownian walker](https://en.wikipedia.org/wiki/Brownian_motion \"Brownian motion\")) and gradient descent down the potential well. The randomness is necessary: if the particles were to undergo only gradient descent, then they will all fall to the origin, collapsing the distribution. \n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=3 \"Edit section: Denoising Diffusion Probabilistic Model \\(DDPM\\)\")]\nThe 2020 paper proposed the Denoising Diffusion Probabilistic Model (DDPM), which improves upon the previous method by [variational inference](https://en.wikipedia.org/wiki/Variational_Bayesian_methods \"Variational Bayesian methods\").[[3]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-3)[[13]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-13)\n#### Forward diffusion\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=4 \"Edit section: Forward diffusion\")]\nTo present the model, some notation is required. \n  * β 1 , . . . , β T ∈ ( 0 , 1 ) {\\displaystyle \\beta _{1},...,\\beta _{T}\\in (0,1)} ![{\\\\displaystyle \\\\beta _{1},...,\\\\beta _{T}\\\\in \\(0,1\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/03933c9e440273d4f23c4a0ca6053caf27e94c52) are fixed constants.\n  * α t := 1 − β t {\\displaystyle \\alpha _{t}:=1-\\beta _{t}} ![{\\\\displaystyle \\\\alpha _{t}:=1-\\\\beta _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a0bef57d97895f15945860510e4995b00cf97bb3)\n  * α ¯ t := α 1 ⋯ α t {\\displaystyle {\\bar {\\alpha }}_{t}:=\\alpha _{1}\\cdots \\alpha _{t}} ![{\\\\displaystyle {\\\\bar {\\\\alpha }}_{t}:=\\\\alpha _{1}\\\\cdots \\\\alpha _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/809742a90c2778671ed39b96e471d0dc2313cc67)\n  * σ t := 1 − α ¯ t {\\displaystyle \\sigma _{t}:={\\sqrt {1-{\\bar {\\alpha }}_{t}}}} ![{\\\\displaystyle \\\\sigma _{t}:={\\\\sqrt {1-{\\\\bar {\\\\alpha }}_{t}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aa1f448e800dd0f54618fd386d41af98846909cc)\n  * σ ~ t := σ t − 1 σ t β t {\\displaystyle {\\tilde {\\sigma }}_{t}:={\\frac {\\sigma _{t-1}}{\\sigma _{t}}}{\\sqrt {\\beta _{t}}}} ![{\\\\displaystyle {\\\\tilde {\\\\sigma }}_{t}:={\\\\frac {\\\\sigma _{t-1}}{\\\\sigma _{t}}}{\\\\sqrt {\\\\beta _{t}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e635bde2b7656076b4fde0565494102e44a7a13)\n  * μ ~ t ( x t , x 0 ) := α t ( 1 − α ¯ t − 1 ) x t + α ¯ t − 1 ( 1 − α t ) x 0 σ t 2 {\\displaystyle {\\tilde {\\mu }}_{t}(x_{t},x_{0}):={\\frac {{\\sqrt {\\alpha _{t}}}(1-{\\bar {\\alpha }}_{t-1})x_{t}+{\\sqrt {{\\bar {\\alpha }}_{t-1}}}(1-\\alpha _{t})x_{0}}{\\sigma _{t}^{2}}}} ![{\\\\displaystyle {\\\\tilde {\\\\mu }}_{t}\\(x_{t},x_{0}\\):={\\\\frac {{\\\\sqrt {\\\\alpha _{t}}}\\(1-{\\\\bar {\\\\alpha }}_{t-1}\\)x_{t}+{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t-1}}}\\(1-\\\\alpha _{t}\\)x_{0}}{\\\\sigma _{t}^{2}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd090d66c7da575b089cfa07d35ffd16a05e9b81)\n  * N ( μ , Σ ) {\\displaystyle {\\mathcal {N}}(\\mu ,\\Sigma )} ![{\\\\displaystyle {\\\\mathcal {N}}\\(\\\\mu ,\\\\Sigma \\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47e2c1eb7b083522691f4ecaf7e751b0b967b64b) is the normal distribution with mean  μ {\\displaystyle \\mu } ![{\\\\displaystyle \\\\mu }](https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161) and variance  Σ {\\displaystyle \\Sigma } ![{\\\\displaystyle \\\\Sigma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e1f558f53cda207614abdf90162266c70bc5c1e), and  N ( x | μ , Σ ) {\\displaystyle {\\mathcal {N}}(x|\\mu ,\\Sigma )} ![{\\\\displaystyle {\\\\mathcal {N}}\\(x|\\\\mu ,\\\\Sigma \\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ecc89a646eba9f42fcad7bebedfd5890c7d4823f) is the probability density at  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4).\n  * A vertical bar denotes [conditioning](https://en.wikipedia.org/wiki/Conditioning_\\(probability\\) \"Conditioning \\(probability\\)\").\n\n\nA **forward diffusion process** starts at some starting point  x 0 ∼ q {\\displaystyle x_{0}\\sim q} ![{\\\\displaystyle x_{0}\\\\sim q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b818f8bbbd506c8ba5d95836bb103e72079c0b0e), where  q {\\displaystyle q} ![{\\\\displaystyle q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d) is the probability distribution to be learned, then repeatedly adds noise to it by x t = 1 − β t x t − 1 + β t z t {\\displaystyle x_{t}={\\sqrt {1-\\beta _{t}}}x_{t-1}+{\\sqrt {\\beta _{t}}}z_{t}} ![{\\\\displaystyle x_{t}={\\\\sqrt {1-\\\\beta _{t}}}x_{t-1}+{\\\\sqrt {\\\\beta _{t}}}z_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5bfedcf08a29819994ec6abb46ede435512222dd)where  z 1 , . . . , z T {\\displaystyle z_{1},...,z_{T}} ![{\\\\displaystyle z_{1},...,z_{T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d3aaacb2cacdc6e7fdc3f1b4f26657dcf63ff900) are IID samples from  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb). This is designed so that for any starting distribution of  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf), we have  lim t x t | x 0 {\\displaystyle \\lim _{t}x_{t}|x_{0}} ![{\\\\displaystyle \\\\lim _{t}x_{t}|x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/206904222524b5ae32087607f9b6eed8e689c85e) converging to  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb). \nThe entire diffusion process then satisfies q ( x 0 : T ) = q ( x 0 ) q ( x 1 | x 0 ) ⋯ q ( x T | x T − 1 ) = q ( x 0 ) N ( x 1 | α 1 x 0 , β 1 I ) ⋯ N ( x T | α T x T − 1 , β T I ) {\\displaystyle q(x_{0:T})=q(x_{0})q(x_{1}|x_{0})\\cdots q(x_{T}|x_{T-1})=q(x_{0}){\\mathcal {N}}(x_{1}|{\\sqrt {\\alpha _{1}}}x_{0},\\beta _{1}I)\\cdots {\\mathcal {N}}(x_{T}|{\\sqrt {\\alpha _{T}}}x_{T-1},\\beta _{T}I)} ![{\\\\displaystyle q\\(x_{0:T}\\)=q\\(x_{0}\\)q\\(x_{1}|x_{0}\\)\\\\cdots q\\(x_{T}|x_{T-1}\\)=q\\(x_{0}\\){\\\\mathcal {N}}\\(x_{1}|{\\\\sqrt {\\\\alpha _{1}}}x_{0},\\\\beta _{1}I\\)\\\\cdots {\\\\mathcal {N}}\\(x_{T}|{\\\\sqrt {\\\\alpha _{T}}}x_{T-1},\\\\beta _{T}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8d8790191d64b95da44497db6bf4d4156f8c21be)or ln ⁡ q ( x 0 : T ) = ln ⁡ q ( x 0 ) − ∑ t = 1 T 1 2 β t ‖ x t − 1 − β t x t − 1 ‖ 2 + C {\\displaystyle \\ln q(x_{0:T})=\\ln q(x_{0})-\\sum _{t=1}^{T}{\\frac {1}{2\\beta _{t}}}\\|x_{t}-{\\sqrt {1-\\beta _{t}}}x_{t-1}\\|^{2}+C} ![{\\\\displaystyle \\\\ln q\\(x_{0:T}\\)=\\\\ln q\\(x_{0}\\)-\\\\sum _{t=1}^{T}{\\\\frac {1}{2\\\\beta _{t}}}\\\\|x_{t}-{\\\\sqrt {1-\\\\beta _{t}}}x_{t-1}\\\\|^{2}+C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a4754719c49c456dba2c9c3f19a3c52c7abf784e)where  C {\\displaystyle C} ![{\\\\displaystyle C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4fc55753007cd3c18576f7933f6f089196732029) is a normalization constant and often omitted. In particular, we note that  x 1 : T | x 0 {\\displaystyle x_{1:T}|x_{0}} ![{\\\\displaystyle x_{1:T}|x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/14b250337fc1415ab4acc981134fa2ce924724ec) is a [gaussian process](https://en.wikipedia.org/wiki/Gaussian_process \"Gaussian process\"), which affords us considerable freedom in [reparameterization](https://en.wikipedia.org/wiki/Reparameterization_trick \"Reparameterization trick\"). For example, by standard manipulation with gaussian process,  x t | x 0 ∼ N ( α ¯ t x 0 , σ t 2 I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0aafa5f6c97510632e03f5a981573fed0d509363) x t − 1 | x t , x 0 ∼ N ( μ ~ t ( x t , x 0 ) , σ ~ t 2 I ) {\\displaystyle x_{t-1}|x_{t},x_{0}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},x_{0}),{\\tilde {\\sigma }}_{t}^{2}I)} ![{\\\\displaystyle x_{t-1}|x_{t},x_{0}\\\\sim {\\\\mathcal {N}}\\({\\\\tilde {\\\\mu }}_{t}\\(x_{t},x_{0}\\),{\\\\tilde {\\\\sigma }}_{t}^{2}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d4b66dd48c709e07baf60639103aacb7aeb923a2)In particular, notice that for large  t {\\displaystyle t} ![{\\\\displaystyle t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560), the variable  x t | x 0 ∼ N ( α ¯ t x 0 , σ t 2 I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0aafa5f6c97510632e03f5a981573fed0d509363) converges to  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb). That is, after a long enough diffusion process, we end up with some  x T {\\displaystyle x_{T}} ![{\\\\displaystyle x_{T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/591426ff2cb83d4938e4025bf2d126628e1123b5) that is very close to  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb), with all traces of the original  x 0 ∼ q {\\displaystyle x_{0}\\sim q} ![{\\\\displaystyle x_{0}\\\\sim q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b818f8bbbd506c8ba5d95836bb103e72079c0b0e) gone. \nFor example, since x t | x 0 ∼ N ( α ¯ t x 0 , σ t 2 I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0aafa5f6c97510632e03f5a981573fed0d509363)we can sample  x t | x 0 {\\displaystyle x_{t}|x_{0}} ![{\\\\displaystyle x_{t}|x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8f50baa0e37ba485884dc1947ae04911bc3b09b) directly \"in one step\", instead of going through all the intermediate steps  x 1 , x 2 , . . . , x t − 1 {\\displaystyle x_{1},x_{2},...,x_{t-1}} ![{\\\\displaystyle x_{1},x_{2},...,x_{t-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/94c32c88b765ead591d8aa8de215f23bd3992fd0). \n**Derivation by reparameterization**\nWe know  x t − 1 | x 0 {\\textstyle x_{t-1}|x_{0}} ![{\\\\textstyle x_{t-1}|x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cec42f60074b7fdb167236f0dadf2c86f4924fd2) is a gaussian, and  x t | x t − 1 {\\textstyle x_{t}|x_{t-1}} ![{\\\\textstyle x_{t}|x_{t-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bbc8f311c4e08d1b6af65fe11eaee8e23c9937dc) is another gaussian. We also know that these are independent. Thus we can perform a reparameterization:  x t − 1 = α ¯ t − 1 x 0 + 1 − α ¯ t − 1 z {\\displaystyle x_{t-1}={\\sqrt {{\\bar {\\alpha }}_{t-1}}}x_{0}+{\\sqrt {1-{\\bar {\\alpha }}_{t-1}}}z} ![{\\\\displaystyle x_{t-1}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t-1}}}x_{0}+{\\\\sqrt {1-{\\\\bar {\\\\alpha }}_{t-1}}}z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6c1d0263409b1d3c76fc95365a98ce7665f452b6) x t = α t x t − 1 + 1 − α t z ′ {\\displaystyle x_{t}={\\sqrt {\\alpha _{t}}}x_{t-1}+{\\sqrt {1-\\alpha _{t}}}z'} ![{\\\\displaystyle x_{t}={\\\\sqrt {\\\\alpha _{t}}}x_{t-1}+{\\\\sqrt {1-\\\\alpha _{t}}}z'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a9701840f46013d51e920e5ba23f3002aed0018) where  z , z ′ {\\textstyle z,z'} ![{\\\\textstyle z,z'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ce888be7c23e520fe044c4996f5a19ca8922a56e) are IID gaussians. \nThere are 5 variables  x 0 , x t − 1 , x t , z , z ′ {\\textstyle x_{0},x_{t-1},x_{t},z,z'} ![{\\\\textstyle x_{0},x_{t-1},x_{t},z,z'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8a7ca2c4e7139d06a2e2840580ed8453c5d0f04b) and two linear equations. The two sources of randomness are  z , z ′ {\\textstyle z,z'} ![{\\\\textstyle z,z'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ce888be7c23e520fe044c4996f5a19ca8922a56e), which can be reparameterized by rotation, since the IID gaussian distribution is rotationally symmetric. \nBy plugging in the equations, we can solve for the first reparameterization:  x t = α ¯ t x 0 + α t − α ¯ t z + 1 − α t z ′ ⏟ = σ t z ″ {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\underbrace {{\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}z+{\\sqrt {1-\\alpha _{t}}}z'} _{=\\sigma _{t}z''}} ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+\\\\underbrace {{\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}z+{\\\\sqrt {1-\\\\alpha _{t}}}z'} _{=\\\\sigma _{t}z''}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/91117ed0542f23771b646928701dfd8087110429) where  z ″ {\\textstyle z''} ![{\\\\textstyle z''}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6345de0110205cb1e5d6c9e5efd0c6acbdc49c84) is a gaussian with mean zero and variance one. \nTo find the second one, we complete the rotational matrix:  [ z ″ z ‴ ] = [ α t − α ¯ t σ t β t σ t ? ? ] [ z z ′ ] {\\displaystyle {\\begin{bmatrix}z''\\\\\\z'''\\end{bmatrix}}={\\begin{bmatrix}{\\frac {\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}{\\sigma _{t}}}&{\\frac {\\sqrt {\\beta _{t}}}{\\sigma _{t}}}\\\\\\?&?\\end{bmatrix}}{\\begin{bmatrix}z\\\\\\z'\\end{bmatrix}}} ![{\\\\displaystyle {\\\\begin{bmatrix}z''\\\\\\\\z'''\\\\end{bmatrix}}={\\\\begin{bmatrix}{\\\\frac {\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}{\\\\sigma _{t}}}&{\\\\frac {\\\\sqrt {\\\\beta _{t}}}{\\\\sigma _{t}}}\\\\\\\\?&?\\\\end{bmatrix}}{\\\\begin{bmatrix}z\\\\\\\\z'\\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/798f2613837b010518e192004058d9ab218b9a96)\nSince rotational matrices are all of the form  [ cos ⁡ θ sin ⁡ θ − sin ⁡ θ cos ⁡ θ ] {\\textstyle {\\begin{bmatrix}\\cos \\theta &\\sin \\theta \\\\\\\\-\\sin \\theta &\\cos \\theta \\end{bmatrix}}} ![{\\\\textstyle {\\\\begin{bmatrix}\\\\cos \\\\theta &\\\\sin \\\\theta \\\\\\\\-\\\\sin \\\\theta &\\\\cos \\\\theta \\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/575a818d1b4af525748849298fb5262f7e6b4352), we know the matrix must be  [ z ″ z ‴ ] = [ α t − α ¯ t σ t β t σ t − β t σ t α t − α ¯ t σ t ] [ z z ′ ] {\\displaystyle {\\begin{bmatrix}z''\\\\\\z'''\\end{bmatrix}}={\\begin{bmatrix}{\\frac {\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}{\\sigma _{t}}}&{\\frac {\\sqrt {\\beta _{t}}}{\\sigma _{t}}}\\\\\\\\-{\\frac {\\sqrt {\\beta _{t}}}{\\sigma _{t}}}&{\\frac {\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}{\\sigma _{t}}}\\end{bmatrix}}{\\begin{bmatrix}z\\\\\\z'\\end{bmatrix}}} ![{\\\\displaystyle {\\\\begin{bmatrix}z''\\\\\\\\z'''\\\\end{bmatrix}}={\\\\begin{bmatrix}{\\\\frac {\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}{\\\\sigma _{t}}}&{\\\\frac {\\\\sqrt {\\\\beta _{t}}}{\\\\sigma _{t}}}\\\\\\\\-{\\\\frac {\\\\sqrt {\\\\beta _{t}}}{\\\\sigma _{t}}}&{\\\\frac {\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}{\\\\sigma _{t}}}\\\\end{bmatrix}}{\\\\begin{bmatrix}z\\\\\\\\z'\\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/52b42aedce9de0cdf216a4aca38abc4ce03147f4) and since the inverse of rotational matrix is its transpose,  \n[ z z ′ ] = [ α t − α ¯ t σ t − β t σ t β t σ t α t − α ¯ t σ t ] [ z ″ z ‴ ] {\\displaystyle {\\begin{bmatrix}z\\\\\\z'\\end{bmatrix}}={\\begin{bmatrix}{\\frac {\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}{\\sigma _{t}}}&-{\\frac {\\sqrt {\\beta _{t}}}{\\sigma _{t}}}\\\\\\\\{\\frac {\\sqrt {\\beta _{t}}}{\\sigma _{t}}}&{\\frac {\\sqrt {\\alpha _{t}-{\\bar {\\alpha }}_{t}}}{\\sigma _{t}}}\\end{bmatrix}}{\\begin{bmatrix}z''\\\\\\z'''\\end{bmatrix}}} ![{\\\\displaystyle {\\\\begin{bmatrix}z\\\\\\\\z'\\\\end{bmatrix}}={\\\\begin{bmatrix}{\\\\frac {\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}{\\\\sigma _{t}}}&-{\\\\frac {\\\\sqrt {\\\\beta _{t}}}{\\\\sigma _{t}}}\\\\\\\\{\\\\frac {\\\\sqrt {\\\\beta _{t}}}{\\\\sigma _{t}}}&{\\\\frac {\\\\sqrt {\\\\alpha _{t}-{\\\\bar {\\\\alpha }}_{t}}}{\\\\sigma _{t}}}\\\\end{bmatrix}}{\\\\begin{bmatrix}z''\\\\\\\\z'''\\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/216ef7d6f2c0558596ecbf6d3fc5a0f1d62cb1ed)\nPlugging back, and simplifying, we have  x t = α ¯ t x 0 + σ t z ″ {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}z''} ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+\\\\sigma _{t}z''}](https://wikimedia.org/api/rest_v1/media/math/render/svg/37764c4e1039310ec79d6863c9816a6a0b3a6ec1) x t − 1 = μ ~ t ( x t , x 0 ) − σ ~ t z ‴ {\\displaystyle x_{t-1}={\\tilde {\\mu }}_{t}(x_{t},x_{0})-{\\tilde {\\sigma }}_{t}z'''} ![{\\\\displaystyle x_{t-1}={\\\\tilde {\\\\mu }}_{t}\\(x_{t},x_{0}\\)-{\\\\tilde {\\\\sigma }}_{t}z'''}](https://wikimedia.org/api/rest_v1/media/math/render/svg/260252c65f6c6b3b9f675ebd01009dc1c3d18838)\n#### Backward diffusion\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=5 \"Edit section: Backward diffusion\")]\nThe key idea of DDPM is to use a neural network parametrized by  θ {\\displaystyle \\theta } ![{\\\\displaystyle \\\\theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af). The network takes in two arguments  x t , t {\\displaystyle x_{t},t} ![{\\\\displaystyle x_{t},t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b1107f28edad3a2b6e964af15466208a82e04d01), and outputs a vector  μ θ ( x t , t ) {\\displaystyle \\mu _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\mu _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ef95472357e0e40df92b29e27cb33f044aaac37d) and a matrix  Σ θ ( x t , t ) {\\displaystyle \\Sigma _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\Sigma _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d08054f64c5e3584e65c921e0080e89189ee522a), such that each step in the forward diffusion process can be approximately undone by  x t − 1 ∼ N ( μ θ ( x t , t ) , Σ θ ( x t , t ) ) {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}(\\mu _{\\theta }(x_{t},t),\\Sigma _{\\theta }(x_{t},t))} ![{\\\\displaystyle x_{t-1}\\\\sim {\\\\mathcal {N}}\\(\\\\mu _{\\\\theta }\\(x_{t},t\\),\\\\Sigma _{\\\\theta }\\(x_{t},t\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/31750105b41fcdfe44231728bea92c232661f57e). This then gives us a backward diffusion process  p θ {\\displaystyle p_{\\theta }} ![{\\\\displaystyle p_{\\\\theta }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b1aa4fdd3e5ed698ea7889602a0cbe756e670f4a) defined by p θ ( x T ) = N ( x T | 0 , I ) {\\displaystyle p_{\\theta }(x_{T})={\\mathcal {N}}(x_{T}|0,I)} ![{\\\\displaystyle p_{\\\\theta }\\(x_{T}\\)={\\\\mathcal {N}}\\(x_{T}|0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/18c8d77d2433c1ddf82c09339cbaf636fd389bf2) p θ ( x t − 1 | x t ) = N ( x t − 1 | μ θ ( x t , t ) , Σ θ ( x t , t ) ) {\\displaystyle p_{\\theta }(x_{t-1}|x_{t})={\\mathcal {N}}(x_{t-1}|\\mu _{\\theta }(x_{t},t),\\Sigma _{\\theta }(x_{t},t))} ![{\\\\displaystyle p_{\\\\theta }\\(x_{t-1}|x_{t}\\)={\\\\mathcal {N}}\\(x_{t-1}|\\\\mu _{\\\\theta }\\(x_{t},t\\),\\\\Sigma _{\\\\theta }\\(x_{t},t\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a8860b3ba1eccc3472095fcac6099485fff3401)The goal now is to learn the parameters such that  p θ ( x 0 ) {\\displaystyle p_{\\theta }(x_{0})} ![{\\\\displaystyle p_{\\\\theta }\\(x_{0}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/48771d92a2c3ae682cc1306fd545aeb2b8e4ae99) is as close to  q ( x 0 ) {\\displaystyle q(x_{0})} ![{\\\\displaystyle q\\(x_{0}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f248526660c27499839edbbcd69f96ebbfc4d2c3) as possible. To do that, we use [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation \"Maximum likelihood estimation\") with variational inference. \n#### Variational inference\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=6 \"Edit section: Variational inference\")]\nThe [ELBO inequality](https://en.wikipedia.org/wiki/Evidence_lower_bound \"Evidence lower bound\") states that  ln ⁡ p θ ( x 0 ) ≥ E x 1 : T ∼ q ( ⋅ | x 0 ) [ ln ⁡ p θ ( x 0 : T ) − ln ⁡ q ( x 1 : T | x 0 ) ] {\\displaystyle \\ln p_{\\theta }(x_{0})\\geq E_{x_{1:T}\\sim q(\\cdot |x_{0})}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]} ![{\\\\displaystyle \\\\ln p_{\\\\theta }\\(x_{0}\\)\\\\geq E_{x_{1:T}\\\\sim q\\(\\\\cdot |x_{0}\\)}\\[\\\\ln p_{\\\\theta }\\(x_{0:T}\\)-\\\\ln q\\(x_{1:T}|x_{0}\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e710509ac655cc141dedf47bdd4b1ff40466f4c2), and taking one more expectation, we get E x 0 ∼ q [ ln ⁡ p θ ( x 0 ) ] ≥ E x 0 : T ∼ q [ ln ⁡ p θ ( x 0 : T ) − ln ⁡ q ( x 1 : T | x 0 ) ] {\\displaystyle E_{x_{0}\\sim q}[\\ln p_{\\theta }(x_{0})]\\geq E_{x_{0:T}\\sim q}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]} ![{\\\\displaystyle E_{x_{0}\\\\sim q}\\[\\\\ln p_{\\\\theta }\\(x_{0}\\)\\]\\\\geq E_{x_{0:T}\\\\sim q}\\[\\\\ln p_{\\\\theta }\\(x_{0:T}\\)-\\\\ln q\\(x_{1:T}|x_{0}\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5eebb4676ee4edc320e675f3ae81e43656ae3961)We see that maximizing the quantity on the right would give us a lower bound on the likelihood of observed data. This allows us to perform variational inference. \nDefine the loss function L ( θ ) := − E x 0 : T ∼ q [ ln ⁡ p θ ( x 0 : T ) − ln ⁡ q ( x 1 : T | x 0 ) ] {\\displaystyle L(\\theta ):=-E_{x_{0:T}\\sim q}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]} ![{\\\\displaystyle L\\(\\\\theta \\):=-E_{x_{0:T}\\\\sim q}\\[\\\\ln p_{\\\\theta }\\(x_{0:T}\\)-\\\\ln q\\(x_{1:T}|x_{0}\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d5e673829767320a5170ee6dcc54a0d8f37431a6)and now the goal is to minimize the loss by stochastic gradient descent. The expression may be simplified to[[14]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:7-14) L ( θ ) = ∑ t = 1 T E x t − 1 , x t ∼ q [ − ln ⁡ p θ ( x t − 1 | x t ) ] + E x 0 ∼ q [ D K L ( q ( x T | x 0 ) ‖ p θ ( x T ) ) ] + C {\\displaystyle L(\\theta )=\\sum _{t=1}^{T}E_{x_{t-1},x_{t}\\sim q}[-\\ln p_{\\theta }(x_{t-1}|x_{t})]+E_{x_{0}\\sim q}[D_{KL}(q(x_{T}|x_{0})\\|p_{\\theta }(x_{T}))]+C} ![{\\\\displaystyle L\\(\\\\theta \\)=\\\\sum _{t=1}^{T}E_{x_{t-1},x_{t}\\\\sim q}\\[-\\\\ln p_{\\\\theta }\\(x_{t-1}|x_{t}\\)\\]+E_{x_{0}\\\\sim q}\\[D_{KL}\\(q\\(x_{T}|x_{0}\\)\\\\|p_{\\\\theta }\\(x_{T}\\)\\)\\]+C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/670cec14d06abb89873f4eb072df8dce0b951b58)where  C {\\displaystyle C} ![{\\\\displaystyle C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4fc55753007cd3c18576f7933f6f089196732029) does not depend on the parameter, and thus can be ignored. Since  p θ ( x T ) = N ( x T | 0 , I ) {\\displaystyle p_{\\theta }(x_{T})={\\mathcal {N}}(x_{T}|0,I)} ![{\\\\displaystyle p_{\\\\theta }\\(x_{T}\\)={\\\\mathcal {N}}\\(x_{T}|0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/18c8d77d2433c1ddf82c09339cbaf636fd389bf2) also does not depend on the parameter, the term  E x 0 ∼ q [ D K L ( q ( x T | x 0 ) ‖ p θ ( x T ) ) ] {\\displaystyle E_{x_{0}\\sim q}[D_{KL}(q(x_{T}|x_{0})\\|p_{\\theta }(x_{T}))]} ![{\\\\displaystyle E_{x_{0}\\\\sim q}\\[D_{KL}\\(q\\(x_{T}|x_{0}\\)\\\\|p_{\\\\theta }\\(x_{T}\\)\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/928347b3890d1cfce85d1168ba30a84ad71a3883) can also be ignored. This leaves just  L ( θ ) = ∑ t = 1 T L t {\\displaystyle L(\\theta )=\\sum _{t=1}^{T}L_{t}} ![{\\\\displaystyle L\\(\\\\theta \\)=\\\\sum _{t=1}^{T}L_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b34afad497998e1a725dd8a23e48c7de8b8a1fa9) with  L t = E x t − 1 , x t ∼ q [ − ln ⁡ p θ ( x t − 1 | x t ) ] {\\displaystyle L_{t}=E_{x_{t-1},x_{t}\\sim q}[-\\ln p_{\\theta }(x_{t-1}|x_{t})]} ![{\\\\displaystyle L_{t}=E_{x_{t-1},x_{t}\\\\sim q}\\[-\\\\ln p_{\\\\theta }\\(x_{t-1}|x_{t}\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8125411c9950a9347615b2c2b936b46ae50762da) to be minimized. \n#### Noise prediction network\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=7 \"Edit section: Noise prediction network\")]\nSince  x t − 1 | x t , x 0 ∼ N ( μ ~ t ( x t , x 0 ) , σ ~ t 2 I ) {\\displaystyle x_{t-1}|x_{t},x_{0}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},x_{0}),{\\tilde {\\sigma }}_{t}^{2}I)} ![{\\\\displaystyle x_{t-1}|x_{t},x_{0}\\\\sim {\\\\mathcal {N}}\\({\\\\tilde {\\\\mu }}_{t}\\(x_{t},x_{0}\\),{\\\\tilde {\\\\sigma }}_{t}^{2}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d4b66dd48c709e07baf60639103aacb7aeb923a2), this suggests that we should use  μ θ ( x t , t ) = μ ~ t ( x t , x 0 ) {\\displaystyle \\mu _{\\theta }(x_{t},t)={\\tilde {\\mu }}_{t}(x_{t},x_{0})} ![{\\\\displaystyle \\\\mu _{\\\\theta }\\(x_{t},t\\)={\\\\tilde {\\\\mu }}_{t}\\(x_{t},x_{0}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/abed27279839249ab489f69c9fbea461c652fcce); however, the network does not have access to  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf), and so it has to estimate it instead. Now, since  x t | x 0 ∼ N ( α ¯ t x 0 , σ t 2 I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0aafa5f6c97510632e03f5a981573fed0d509363), we may write  x t = α ¯ t x 0 + σ t z {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}z} ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+\\\\sigma _{t}z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/46b439306dae327b2ae72767693896f7505a02e9), where  z {\\displaystyle z} ![{\\\\displaystyle z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bf368e72c009decd9b6686ee84a375632e11de98) is some unknown gaussian noise. Now we see that estimating  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf) is equivalent to estimating  z {\\displaystyle z} ![{\\\\displaystyle z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bf368e72c009decd9b6686ee84a375632e11de98). \nTherefore, let the network output a noise vector  ϵ θ ( x t , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac1d100b70d76dbb0e1429000edc61529a2c1724), and let it predict μ θ ( x t , t ) = μ ~ t ( x t , x t − σ t ϵ θ ( x t , t ) α ¯ t ) = x t − ϵ θ ( x t , t ) β t / σ t α t {\\displaystyle \\mu _{\\theta }(x_{t},t)={\\tilde {\\mu }}_{t}\\left(x_{t},{\\frac {x_{t}-\\sigma _{t}\\epsilon _{\\theta }(x_{t},t)}{\\sqrt {{\\bar {\\alpha }}_{t}}}}\\right)={\\frac {x_{t}-\\epsilon _{\\theta }(x_{t},t)\\beta _{t}/\\sigma _{t}}{\\sqrt {\\alpha _{t}}}}} ![{\\\\displaystyle \\\\mu _{\\\\theta }\\(x_{t},t\\)={\\\\tilde {\\\\mu }}_{t}\\\\left\\(x_{t},{\\\\frac {x_{t}-\\\\sigma _{t}\\\\epsilon _{\\\\theta }\\(x_{t},t\\)}{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}}\\\\right\\)={\\\\frac {x_{t}-\\\\epsilon _{\\\\theta }\\(x_{t},t\\)\\\\beta _{t}/\\\\sigma _{t}}{\\\\sqrt {\\\\alpha _{t}}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d09b7ed77db204226ab2c7a34318a60dbf00cfcc)It remains to design  Σ θ ( x t , t ) {\\displaystyle \\Sigma _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\Sigma _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d08054f64c5e3584e65c921e0080e89189ee522a). The DDPM paper suggested not learning it (since it resulted in \"unstable training and poorer sample quality\"), but fixing it at some value  Σ θ ( x t , t ) = ζ t 2 I {\\displaystyle \\Sigma _{\\theta }(x_{t},t)=\\zeta _{t}^{2}I} ![{\\\\displaystyle \\\\Sigma _{\\\\theta }\\(x_{t},t\\)=\\\\zeta _{t}^{2}I}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3ed7e927bcd2e9003d3f959e79fed9b743d27629), where either  ζ t 2 = β t or  σ ~ t 2 {\\displaystyle \\zeta _{t}^{2}=\\beta _{t}{\\text{ or }}{\\tilde {\\sigma }}_{t}^{2}} ![{\\\\displaystyle \\\\zeta _{t}^{2}=\\\\beta _{t}{\\\\text{ or }}{\\\\tilde {\\\\sigma }}_{t}^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/167fda91d0b1601f8573c8043cf9d6ea811dc38c) yielded similar performance. \nWith this, the loss simplifies to  L t = β t 2 2 α t σ t 2 ζ t 2 E x 0 ∼ q ; z ∼ N ( 0 , I ) [ ‖ ϵ θ ( x t , t ) − z ‖ 2 ] + C {\\displaystyle L_{t}={\\frac {\\beta _{t}^{2}}{2\\alpha _{t}\\sigma _{t}^{2}\\zeta _{t}^{2}}}E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]+C} ![{\\\\displaystyle L_{t}={\\\\frac {\\\\beta _{t}^{2}}{2\\\\alpha _{t}\\\\sigma _{t}^{2}\\\\zeta _{t}^{2}}}E_{x_{0}\\\\sim q;z\\\\sim {\\\\mathcal {N}}\\(0,I\\)}\\\\left\\[\\\\left\\\\|\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-z\\\\right\\\\|^{2}\\\\right\\]+C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d37cc4549148dde2ccd0bd0d084a0b548cc3997f)which may be minimized by stochastic gradient descent. The paper noted empirically that an even simpler loss function L s i m p l e , t = E x 0 ∼ q ; z ∼ N ( 0 , I ) [ ‖ ϵ θ ( x t , t ) − z ‖ 2 ] {\\displaystyle L_{simple,t}=E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]} ![{\\\\displaystyle L_{simple,t}=E_{x_{0}\\\\sim q;z\\\\sim {\\\\mathcal {N}}\\(0,I\\)}\\\\left\\[\\\\left\\\\|\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-z\\\\right\\\\|^{2}\\\\right\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/935e47818aeafab5cc11a12a4dd25361dade64bc)resulted in better models. \n### Backward diffusion process\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=8 \"Edit section: Backward diffusion process\")]\nAfter a noise prediction network is trained, it can be used for generating data points in the original distribution in a loop as follows: \n  1. Compute the noise estimate  ϵ ← ϵ θ ( x t , t ) {\\displaystyle \\epsilon \\leftarrow \\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\epsilon \\\\leftarrow \\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/89fad589de406e01c844732f5c69184e60df6413)\n  2. Compute the original data estimate  x ~ 0 ← ( x t − σ t ϵ ) / α ¯ t {\\displaystyle {\\tilde {x}}_{0}\\leftarrow (x_{t}-\\sigma _{t}\\epsilon )/{\\sqrt {{\\bar {\\alpha }}_{t}}}} ![{\\\\displaystyle {\\\\tilde {x}}_{0}\\\\leftarrow \\(x_{t}-\\\\sigma _{t}\\\\epsilon \\)/{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ae655fe651654e27c6e511b6c1bbbd187921dac)\n  3. Sample the previous data  x t − 1 ∼ N ( μ ~ t ( x t , x ~ 0 ) , σ ~ t 2 I ) {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),{\\tilde {\\sigma }}_{t}^{2}I)} ![{\\\\displaystyle x_{t-1}\\\\sim {\\\\mathcal {N}}\\({\\\\tilde {\\\\mu }}_{t}\\(x_{t},{\\\\tilde {x}}_{0}\\),{\\\\tilde {\\\\sigma }}_{t}^{2}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/36b4d99c0cb6d9420f52e54358ee832b83a047f6)\n  4. Change time  t ← t − 1 {\\displaystyle t\\leftarrow t-1} ![{\\\\displaystyle t\\\\leftarrow t-1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9fee6d5877df858bae5238ec02bff0b6ad80d752)\n\n\n## Score-based generative model\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=9 \"Edit section: Score-based generative model\")]\nScore-based generative model is another formulation of diffusion modelling. They are also called noise conditional score network (NCSN) or score-matching with Langevin dynamics (SMLD).[[15]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-15)[[16]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:9-16)[[17]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:1-17)[[18]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-18)\n### Score matching\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=10 \"Edit section: Score matching\")]\n#### The idea of score functions\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=11 \"Edit section: The idea of score functions\")]\nConsider the problem of image generation. Let  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) represent an image, and let  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4) be the probability distribution over all possible images. If we have  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4) itself, then we can say for certain how likely a certain image is. However, this is intractable in general. \nMost often, we are uninterested in knowing the absolute probability of a certain image. Instead, we are usually only interested in knowing how likely a certain image is compared to its immediate neighbors — e.g. how much more likely is an image of cat compared to some small variants of it? Is it more likely if the image contains two whiskers, or three, or with some Gaussian noise added? \nConsequently, we are actually quite uninterested in  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4) itself, but rather,  ∇ x ln ⁡ q ( x ) {\\displaystyle \\nabla _{x}\\ln q(x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4af93047d53da39336a81a2cf0bc6b211cc96ab0). This has two major effects: \n  * One, we no longer need to normalize  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4), but can use any  q ~ ( x ) = C q ( x ) {\\displaystyle {\\tilde {q}}(x)=Cq(x)} ![{\\\\displaystyle {\\\\tilde {q}}\\(x\\)=Cq\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e0cb9a2697e3bfc69381357d2586568ba1d6f68a), where  C = ∫ q ~ ( x ) d x > 0 {\\displaystyle C=\\int {\\tilde {q}}(x)dx>0} ![{\\\\displaystyle C=\\\\int {\\\\tilde {q}}\\(x\\)dx>0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ea5a6cdba3dcb7186323c085e2b6dd560c69c3f2) is any unknown constant that is of no concern to us.\n  * Two, we are comparing  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4) neighbors  q ( x + d x ) {\\displaystyle q(x+dx)} ![{\\\\displaystyle q\\(x+dx\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/33c48bf4c976a8f0a4a88a3b7313a80e9d64c81e), by  q ( x ) q ( x + d x ) = e − ⟨ ∇ x ln ⁡ q , d x ⟩ {\\displaystyle {\\frac {q(x)}{q(x+dx)}}=e^{-\\langle \\nabla _{x}\\ln q,dx\\rangle }} ![{\\\\displaystyle {\\\\frac {q\\(x\\)}{q\\(x+dx\\)}}=e^{-\\\\langle \\\\nabla _{x}\\\\ln q,dx\\\\rangle }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/31f5fb8b5444b9dce7a908f408e90dc514f09091)\n\n\nLet the [score function](https://en.wikipedia.org/wiki/Score_\\(statistics\\) \"Score \\(statistics\\)\") be  s ( x ) := ∇ x ln ⁡ q ( x ) {\\displaystyle s(x):=\\nabla _{x}\\ln q(x)} ![{\\\\displaystyle s\\(x\\):=\\\\nabla _{x}\\\\ln q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6fa4030a859336a3f2d2857b9abfd07562eec8ca); then consider what we can do with  s ( x ) {\\displaystyle s(x)} ![{\\\\displaystyle s\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/10f51eec88706f1a26ac7430dc71d92c15e71a6e). \nAs it turns out,  s ( x ) {\\displaystyle s(x)} ![{\\\\displaystyle s\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/10f51eec88706f1a26ac7430dc71d92c15e71a6e) allows us to sample from  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4) using thermodynamics. Specifically, if we have a potential energy function  U ( x ) = − ln ⁡ q ( x ) {\\displaystyle U(x)=-\\ln q(x)} ![{\\\\displaystyle U\\(x\\)=-\\\\ln q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/140e1e71ceda9811aff80285eecf65199ae96899), and a lot of particles in the potential well, then the distribution at thermodynamic equilibrium is the [Boltzmann distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution \"Boltzmann distribution\") q U ( x ) ∝ e − U ( x ) / k B T = q ( x ) 1 / k B T {\\displaystyle q_{U}(x)\\propto e^{-U(x)/k_{B}T}=q(x)^{1/k_{B}T}} ![{\\\\displaystyle q_{U}\\(x\\)\\\\propto e^{-U\\(x\\)/k_{B}T}=q\\(x\\)^{1/k_{B}T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a2fe771133c26a423c282e161b8ad344c7c7d56). At temperature  k B T = 1 {\\displaystyle k_{B}T=1} ![{\\\\displaystyle k_{B}T=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/931cb85ae02424c524e0c2dac8be46d34b5fdf62), the Boltzmann distribution is exactly  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4). \nTherefore, to model  q ( x ) {\\displaystyle q(x)} ![{\\\\displaystyle q\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c38bbafe34a043d284f19231b946a76c0a4b16b4), we may start with a particle sampled at any convenient distribution (such as the standard gaussian distribution), then simulate the motion of the particle forwards according to the [Langevin equation](https://en.wikipedia.org/wiki/Langevin_equation \"Langevin equation\") d x t = − ∇ x t U ( x t ) d t + d W t {\\displaystyle dx_{t}=-\\nabla _{x_{t}}U(x_{t})dt+dW_{t}} ![{\\\\displaystyle dx_{t}=-\\\\nabla _{x_{t}}U\\(x_{t}\\)dt+dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c1af275975d961256369f88132b61dcdf02e06a1) and the Boltzmann distribution is, [by Fokker-Planck equation, the unique thermodynamic equilibrium](https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation#Boltzmann_distribution_at_the_thermodynamic_equilibrium \"Fokker–Planck equation\"). So no matter what distribution  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf) has, the distribution of  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) converges in distribution to  q {\\displaystyle q} ![{\\\\displaystyle q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d) as  t → ∞ {\\displaystyle t\\to \\infty } ![{\\\\displaystyle t\\\\to \\\\infty }](https://wikimedia.org/api/rest_v1/media/math/render/svg/8a34d7a61899d577d950881b4a44888d43f3fa93). \n#### Learning the score function\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=12 \"Edit section: Learning the score function\")]\nGiven a density  q {\\displaystyle q} ![{\\\\displaystyle q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d), we wish to learn a score function approximation  f θ ≈ ∇ ln ⁡ q {\\displaystyle f_{\\theta }\\approx \\nabla \\ln q} ![{\\\\displaystyle f_{\\\\theta }\\\\approx \\\\nabla \\\\ln q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4fbb5d200850fb8dafe9c67473ad0fa5ed03dc8f). This is **score matching** _._[[19]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-19) Typically, score matching is formalized as minimizing **Fisher divergence** function  E q [ ‖ f θ ( x ) − ∇ ln ⁡ q ( x ) ‖ 2 ] {\\displaystyle E_{q}[\\|f_{\\theta }(x)-\\nabla \\ln q(x)\\|^{2}]} ![{\\\\displaystyle E_{q}\\[\\\\|f_{\\\\theta }\\(x\\)-\\\\nabla \\\\ln q\\(x\\)\\\\|^{2}\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/629f17805d6fd5182bc671e725d453403e337b40). By expanding the integral, and performing an integration by parts,  E q [ ‖ f θ ( x ) − ∇ ln ⁡ q ( x ) ‖ 2 ] = E q [ ‖ f θ ‖ 2 + 2 ∇ ⋅ f θ ] + C {\\displaystyle E_{q}[\\|f_{\\theta }(x)-\\nabla \\ln q(x)\\|^{2}]=E_{q}[\\|f_{\\theta }\\|^{2}+2\\nabla \\cdot f_{\\theta }]+C} ![{\\\\displaystyle E_{q}\\[\\\\|f_{\\\\theta }\\(x\\)-\\\\nabla \\\\ln q\\(x\\)\\\\|^{2}\\]=E_{q}\\[\\\\|f_{\\\\theta }\\\\|^{2}+2\\\\nabla \\\\cdot f_{\\\\theta }\\]+C}](https://wikimedia.org/api/rest_v1/media/math/render/svg/07719e498d5037e8338a2df0adda804276531b6d)giving us a loss function, also known as the [Hyvärinen scoring rule](https://en.wikipedia.org/wiki/Scoring_rule#Hyv%C3%A4rinen_scoring_rule \"Scoring rule\"), that can be minimized by stochastic gradient descent. \n#### Annealing the score function\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=13 \"Edit section: Annealing the score function\")]\nSuppose we need to model the distribution of images, and we want  x 0 ∼ N ( 0 , I ) {\\displaystyle x_{0}\\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle x_{0}\\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1329458512182d624965869be64daf4e07b0f994), a white-noise image. Now, most white-noise images do not look like real images, so  q ( x 0 ) ≈ 0 {\\displaystyle q(x_{0})\\approx 0} ![{\\\\displaystyle q\\(x_{0}\\)\\\\approx 0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1e460718e2126351aa7193884a2b4dfde99cb5b) for large swaths of  x 0 ∼ N ( 0 , I ) {\\displaystyle x_{0}\\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle x_{0}\\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1329458512182d624965869be64daf4e07b0f994). This presents a problem for learning the score function, because if there are no samples around a certain point, then we can't learn the score function at that point. If we do not know the score function  ∇ x t ln ⁡ q ( x t ) {\\displaystyle \\nabla _{x_{t}}\\ln q(x_{t})} ![{\\\\displaystyle \\\\nabla _{x_{t}}\\\\ln q\\(x_{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fb75e80f87ed0112192b6ee0a01995a589213d09) at that point, then we cannot impose the time-evolution equation on a particle: d x t = ∇ x t ln ⁡ q ( x t ) d t + d W t {\\displaystyle dx_{t}=\\nabla _{x_{t}}\\ln q(x_{t})dt+dW_{t}} ![{\\\\displaystyle dx_{t}=\\\\nabla _{x_{t}}\\\\ln q\\(x_{t}\\)dt+dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4ab3992c05742efe2bfc2817d90a10eaa5dc11ff)To deal with this problem, we perform [annealing](https://en.wikipedia.org/wiki/Simulated_annealing \"Simulated annealing\"). If  q {\\displaystyle q} ![{\\\\displaystyle q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d) is too different from a white-noise distribution, then progressively add noise until it is indistinguishable from one. That is, we perform a forward diffusion, then learn the score function, then use the score function to perform a backward diffusion. \n### Continuous diffusion processes\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=14 \"Edit section: Continuous diffusion processes\")]\n#### Forward diffusion process\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=15 \"Edit section: Forward diffusion process\")]\nConsider again the forward diffusion process, but this time in continuous time: x t = 1 − β t x t − 1 + β t z t {\\displaystyle x_{t}={\\sqrt {1-\\beta _{t}}}x_{t-1}+{\\sqrt {\\beta _{t}}}z_{t}} ![{\\\\displaystyle x_{t}={\\\\sqrt {1-\\\\beta _{t}}}x_{t-1}+{\\\\sqrt {\\\\beta _{t}}}z_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5bfedcf08a29819994ec6abb46ede435512222dd)By taking the  β t → β ( t ) d t , d t z t → d W t {\\displaystyle \\beta _{t}\\to \\beta (t)dt,{\\sqrt {dt}}z_{t}\\to dW_{t}} ![{\\\\displaystyle \\\\beta _{t}\\\\to \\\\beta \\(t\\)dt,{\\\\sqrt {dt}}z_{t}\\\\to dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ccccb58046f89db97b4477d7f8f1ead2db7b33fe) limit, we obtain a continuous diffusion process, in the form of a [stochastic differential equation](https://en.wikipedia.org/wiki/Stochastic_differential_equation \"Stochastic differential equation\"): d x t = − 1 2 β ( t ) x t d t + β ( t ) d W t {\\displaystyle dx_{t}=-{\\frac {1}{2}}\\beta (t)x_{t}dt+{\\sqrt {\\beta (t)}}dW_{t}} ![{\\\\displaystyle dx_{t}=-{\\\\frac {1}{2}}\\\\beta \\(t\\)x_{t}dt+{\\\\sqrt {\\\\beta \\(t\\)}}dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/11bdd31eb828bcca42d3fb7b2d9ec90126fb62c1)where  W t {\\displaystyle W_{t}} ![{\\\\displaystyle W_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/50680c5535c83badfa630dba63b583d2eeaa2977) is a [Wiener process](https://en.wikipedia.org/wiki/Wiener_process \"Wiener process\") (multidimensional Brownian motion). \nNow, the equation is exactly a special case of the [overdamped Langevin equation](https://en.wikipedia.org/wiki/Brownian_dynamics \"Brownian dynamics\") d x t = − D k B T ( ∇ x U ) d t + 2 D d W t {\\displaystyle dx_{t}=-{\\frac {D}{k_{B}T}}(\\nabla _{x}U)dt+{\\sqrt {2D}}dW_{t}} ![{\\\\displaystyle dx_{t}=-{\\\\frac {D}{k_{B}T}}\\(\\\\nabla _{x}U\\)dt+{\\\\sqrt {2D}}dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/506e77f3e2a7001bb35275ddcac420fad74a330e)where  D {\\displaystyle D} ![{\\\\displaystyle D}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f34a0c600395e5d4345287e21fb26efd386990e6) is diffusion tensor,  T {\\displaystyle T} ![{\\\\displaystyle T}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ec7200acd984a1d3a3d7dc455e262fbe54f7f6e0) is temperature, and  U {\\displaystyle U} ![{\\\\displaystyle U}](https://wikimedia.org/api/rest_v1/media/math/render/svg/458a728f53b9a0274f059cd695e067c430956025) is potential energy field. If we substitute in  D = 1 2 β ( t ) I , k B T = 1 , U = 1 2 ‖ x ‖ 2 {\\displaystyle D={\\frac {1}{2}}\\beta (t)I,k_{B}T=1,U={\\frac {1}{2}}\\|x\\|^{2}} ![{\\\\displaystyle D={\\\\frac {1}{2}}\\\\beta \\(t\\)I,k_{B}T=1,U={\\\\frac {1}{2}}\\\\|x\\\\|^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dcac55720db454a155704c7eed1d4a9f34c7d40f), we recover the above equation. This explains why the phrase \"Langevin dynamics\" is sometimes used in diffusion models. \nNow the above equation is for the stochastic motion of a single particle. Suppose we have a cloud of particles distributed according to  q {\\displaystyle q} ![{\\\\displaystyle q}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d) at time  t = 0 {\\displaystyle t=0} ![{\\\\displaystyle t=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/43469ec032d858feae5aa87029e22eaaf0109e9c), then after a long time, the cloud of particles would settle into the stable distribution of  N ( 0 , I ) {\\displaystyle {\\mathcal {N}}(0,I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/00d56975d9da87432a3e9bdddf59aec1dd990bcb). Let  ρ t {\\displaystyle \\rho _{t}} ![{\\\\displaystyle \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1d393145553a30657afb0fca049fd29eeb260f8) be the density of the cloud of particles at time  t {\\displaystyle t} ![{\\\\displaystyle t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560), then we have ρ 0 = q ; ρ T ≈ N ( 0 , I ) {\\displaystyle \\rho _{0}=q;\\quad \\rho _{T}\\approx {\\mathcal {N}}(0,I)} ![{\\\\displaystyle \\\\rho _{0}=q;\\\\quad \\\\rho _{T}\\\\approx {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/12606e0f0e5fec62dcca2bc5c913e5e1750405d3)and the goal is to somehow reverse the process, so that we can start at the end and diffuse back to the beginning. \nBy [Fokker-Planck equation](https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation \"Fokker–Planck equation\"), the density of the cloud evolves according to ∂ t ln ⁡ ρ t = 1 2 β ( t ) ( n + ( x + ∇ ln ⁡ ρ t ) ⋅ ∇ ln ⁡ ρ t + Δ ln ⁡ ρ t ) {\\displaystyle \\partial _{t}\\ln \\rho _{t}={\\frac {1}{2}}\\beta (t)\\left(n+(x+\\nabla \\ln \\rho _{t})\\cdot \\nabla \\ln \\rho _{t}+\\Delta \\ln \\rho _{t}\\right)} ![{\\\\displaystyle \\\\partial _{t}\\\\ln \\\\rho _{t}={\\\\frac {1}{2}}\\\\beta \\(t\\)\\\\left\\(n+\\(x+\\\\nabla \\\\ln \\\\rho _{t}\\)\\\\cdot \\\\nabla \\\\ln \\\\rho _{t}+\\\\Delta \\\\ln \\\\rho _{t}\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fb45e063415a40bfe8a9b2830ed92362fcaf8659)where  n {\\displaystyle n} ![{\\\\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) is the dimension of space, and  Δ {\\displaystyle \\Delta } ![{\\\\displaystyle \\\\Delta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/32769037c408874e1890f77554c65f39c523ebe2) is the [Laplace operator](https://en.wikipedia.org/wiki/Laplace_operator \"Laplace operator\"). Equivalently, ∂ t ρ t = 1 2 β ( t ) ( ∇ ⋅ ( x ρ t ) + Δ ρ t ) {\\displaystyle \\partial _{t}\\rho _{t}={\\frac {1}{2}}\\beta (t)(\\nabla \\cdot (x\\rho _{t})+\\Delta \\rho _{t})} ![{\\\\displaystyle \\\\partial _{t}\\\\rho _{t}={\\\\frac {1}{2}}\\\\beta \\(t\\)\\(\\\\nabla \\\\cdot \\(x\\\\rho _{t}\\)+\\\\Delta \\\\rho _{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/64a1dcc951b25252335dfd511cf23ffb7194cbc9)\n#### Backward diffusion process\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=16 \"Edit section: Backward diffusion process\")]\nIf we have solved  ρ t {\\displaystyle \\rho _{t}} ![{\\\\displaystyle \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1d393145553a30657afb0fca049fd29eeb260f8) for time  t ∈ [ 0 , T ] {\\displaystyle t\\in [0,T]} ![{\\\\displaystyle t\\\\in \\[0,T\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4b7ea7b28971838e52f450c48053939e81daa26f), then we can exactly reverse the evolution of the cloud. Suppose we start with another cloud of particles with density  ν 0 = ρ T {\\displaystyle \\nu _{0}=\\rho _{T}} ![{\\\\displaystyle \\\\nu _{0}=\\\\rho _{T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dff4707413bae4ce3bf2db3a1b559dfa24f48c15), and let the particles in the cloud evolve according to \nd y t = 1 2 β ( T − t ) y t d t + β ( T − t ) ∇ y t ln ⁡ ρ T − t ( y t ) ⏟ score function  d t + β ( T − t ) d W t {\\displaystyle dy_{t}={\\frac {1}{2}}\\beta (T-t)y_{t}dt+\\beta (T-t)\\underbrace {\\nabla _{y_{t}}\\ln \\rho _{T-t}\\left(y_{t}\\right)} _{\\text{score function }}dt+{\\sqrt {\\beta (T-t)}}dW_{t}} ![{\\\\displaystyle dy_{t}={\\\\frac {1}{2}}\\\\beta \\(T-t\\)y_{t}dt+\\\\beta \\(T-t\\)\\\\underbrace {\\\\nabla _{y_{t}}\\\\ln \\\\rho _{T-t}\\\\left\\(y_{t}\\\\right\\)} _{\\\\text{score function }}dt+{\\\\sqrt {\\\\beta \\(T-t\\)}}dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d4e70c112652d959143dd2999d1dbf40d8083d5e)\nthen by plugging into the Fokker-Planck equation, we find that  ∂ t ρ T − t = ∂ t ν t {\\displaystyle \\partial _{t}\\rho _{T-t}=\\partial _{t}\\nu _{t}} ![{\\\\displaystyle \\\\partial _{t}\\\\rho _{T-t}=\\\\partial _{t}\\\\nu _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6ee9c9a6293bf6379a207713aa47e95f5fce8cd2). Thus this cloud of points is the original cloud, evolving backwards.[[20]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-20)\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=17 \"Edit section: Noise conditional score network \\(NCSN\\)\")]\nAt the continuous limit,  α ¯ t = ( 1 − β 1 ) ⋯ ( 1 − β t ) = e ∑ i ln ⁡ ( 1 − β i ) → e − ∫ 0 t β ( t ) d t {\\displaystyle {\\bar {\\alpha }}_{t}=(1-\\beta _{1})\\cdots (1-\\beta _{t})=e^{\\sum _{i}\\ln(1-\\beta _{i})}\\to e^{-\\int _{0}^{t}\\beta (t)dt}} ![{\\\\displaystyle {\\\\bar {\\\\alpha }}_{t}=\\(1-\\\\beta _{1}\\)\\\\cdots \\(1-\\\\beta _{t}\\)=e^{\\\\sum _{i}\\\\ln\\(1-\\\\beta _{i}\\)}\\\\to e^{-\\\\int _{0}^{t}\\\\beta \\(t\\)dt}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/78d48da3134ceac216f16c31ad32bd6702147d68) and so  x t | x 0 ∼ N ( e − 1 2 ∫ 0 t β ( t ) d t x 0 , ( 1 − e − ∫ 0 t β ( t ) d t ) I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left(e^{-{\\frac {1}{2}}\\int _{0}^{t}\\beta (t)dt}x_{0},\\left(1-e^{-\\int _{0}^{t}\\beta (t)dt}\\right)I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\(e^{-{\\\\frac {1}{2}}\\\\int _{0}^{t}\\\\beta \\(t\\)dt}x_{0},\\\\left\\(1-e^{-\\\\int _{0}^{t}\\\\beta \\(t\\)dt}\\\\right\\)I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/695fb9bfb0b8fac5b69aee9f7643dfff5f4e445b) In particular, we see that we can directly sample from any point in the continuous diffusion process without going through the intermediate steps, by first sampling  x 0 ∼ q , z ∼ N ( 0 , I ) {\\displaystyle x_{0}\\sim q,z\\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle x_{0}\\\\sim q,z\\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0e93eb4336dc328f482f41b27c7fc7fd22ea473b), then get  x t = e − 1 2 ∫ 0 t β ( t ) d t x 0 + ( 1 − e − ∫ 0 t β ( t ) d t ) z {\\displaystyle x_{t}=e^{-{\\frac {1}{2}}\\int _{0}^{t}\\beta (t)dt}x_{0}+\\left(1-e^{-\\int _{0}^{t}\\beta (t)dt}\\right)z} ![{\\\\displaystyle x_{t}=e^{-{\\\\frac {1}{2}}\\\\int _{0}^{t}\\\\beta \\(t\\)dt}x_{0}+\\\\left\\(1-e^{-\\\\int _{0}^{t}\\\\beta \\(t\\)dt}\\\\right\\)z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e49f50c12a4423b33cdca93adb2145b7b7593164). That is, we can quickly sample  x t ∼ ρ t {\\displaystyle x_{t}\\sim \\rho _{t}} ![{\\\\displaystyle x_{t}\\\\sim \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b9b6ffd6c17d45a3c4b8d003a4a54ccbfbf29bff) for any  t ≥ 0 {\\displaystyle t\\geq 0} ![{\\\\displaystyle t\\\\geq 0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/248525429e9cd266f53ab8c52d17bc206c546060). \nNow, define a certain probability distribution  γ {\\displaystyle \\gamma } ![{\\\\displaystyle \\\\gamma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a) over  [ 0 , ∞ ) {\\displaystyle [0,\\infty )} ![{\\\\displaystyle \\[0,\\\\infty \\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8dc2d914c2df66bc0f7893bfb8da36766650fe47), then the score-matching loss function is defined as the expected Fisher divergence:  L ( θ ) = E t ∼ γ , x t ∼ ρ t [ ‖ f θ ( x t , t ) ‖ 2 + 2 ∇ ⋅ f θ ( x t , t ) ] {\\displaystyle L(\\theta )=E_{t\\sim \\gamma ,x_{t}\\sim \\rho _{t}}[\\|f_{\\theta }(x_{t},t)\\|^{2}+2\\nabla \\cdot f_{\\theta }(x_{t},t)]} ![{\\\\displaystyle L\\(\\\\theta \\)=E_{t\\\\sim \\\\gamma ,x_{t}\\\\sim \\\\rho _{t}}\\[\\\\|f_{\\\\theta }\\(x_{t},t\\)\\\\|^{2}+2\\\\nabla \\\\cdot f_{\\\\theta }\\(x_{t},t\\)\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d8505a3a440a3ddfa923515122f9a4402570df9) After training,  f θ ( x t , t ) ≈ ∇ ln ⁡ ρ t {\\displaystyle f_{\\theta }(x_{t},t)\\approx \\nabla \\ln \\rho _{t}} ![{\\\\displaystyle f_{\\\\theta }\\(x_{t},t\\)\\\\approx \\\\nabla \\\\ln \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/273582d9e3daa63e8189a4e93d4f660b23330f22), so we can perform the backwards diffusion process by first sampling  x T ∼ N ( 0 , I ) {\\displaystyle x_{T}\\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle x_{T}\\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d545e26900fa8a43ce5528e68b746666731cf81e), then integrating the SDE from  t = T {\\displaystyle t=T} ![{\\\\displaystyle t=T}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5c6b2eabe8e275c2da71dbc61ca0ede73a418051) to  t = 0 {\\displaystyle t=0} ![{\\\\displaystyle t=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/43469ec032d858feae5aa87029e22eaaf0109e9c):  x t − d t = x t + 1 2 β ( t ) x t d t + β ( t ) f θ ( x t , t ) d t + β ( t ) d W t {\\displaystyle x_{t-dt}=x_{t}+{\\frac {1}{2}}\\beta (t)x_{t}dt+\\beta (t)f_{\\theta }(x_{t},t)dt+{\\sqrt {\\beta (t)}}dW_{t}} ![{\\\\displaystyle x_{t-dt}=x_{t}+{\\\\frac {1}{2}}\\\\beta \\(t\\)x_{t}dt+\\\\beta \\(t\\)f_{\\\\theta }\\(x_{t},t\\)dt+{\\\\sqrt {\\\\beta \\(t\\)}}dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f07077954ad9a6888e8b5b227e06eb885ef1c805) This may be done by any SDE integration method, such as [Euler–Maruyama method](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method \"Euler–Maruyama method\"). \nThe name \"noise conditional score network\" is explained thus: \n  * \"network\", because  f θ {\\displaystyle f_{\\theta }} ![{\\\\displaystyle f_{\\\\theta }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9874ae06066a2250709085e0fb521eebff2c2fb7) is implemented as a neural network.\n  * \"score\", because the output of the network is interpreted as approximating the score function  ∇ ln ⁡ ρ t {\\displaystyle \\nabla \\ln \\rho _{t}} ![{\\\\displaystyle \\\\nabla \\\\ln \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2f632642155529f92d207ef56dc4f082f616334d).\n  * \"noise conditional\", because  ρ t {\\displaystyle \\rho _{t}} ![{\\\\displaystyle \\\\rho _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1d393145553a30657afb0fca049fd29eeb260f8) is equal to  ρ 0 {\\displaystyle \\rho _{0}} ![{\\\\displaystyle \\\\rho _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d9c04a9d26b86af8c6205ba2a6287fd655b6b714) blurred by an added gaussian noise that increases with time, and so the score function depends on the amount of noise added.\n\n\n## Their equivalence\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=18 \"Edit section: Their equivalence\")]\nDDPM and score-based generative models are equivalent.[[16]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:9-16)[[1]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-1)[[21]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-21) This means that a network trained using DDPM can be used as a NCSN, and vice versa. \nWe know that  x t | x 0 ∼ N ( α ¯ t x 0 , σ t 2 I ) {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle x_{t}|x_{0}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0aafa5f6c97510632e03f5a981573fed0d509363), so by [Tweedie's formula](https://en.wikipedia.org/wiki/Maurice_Tweedie#Tweedie's_formula \"Maurice Tweedie\"), we have  ∇ x t ln ⁡ q ( x t ) = 1 σ t 2 ( − x t + α ¯ t E q [ x 0 | x t ] ) {\\displaystyle \\nabla _{x_{t}}\\ln q(x_{t})={\\frac {1}{\\sigma _{t}^{2}}}(-x_{t}+{\\sqrt {{\\bar {\\alpha }}_{t}}}E_{q}[x_{0}|x_{t}])} ![{\\\\displaystyle \\\\nabla _{x_{t}}\\\\ln q\\(x_{t}\\)={\\\\frac {1}{\\\\sigma _{t}^{2}}}\\(-x_{t}+{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}E_{q}\\[x_{0}|x_{t}\\]\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e501cf3cc429e6e8fa34ce80701750d5f43c3400) As described previously, the DDPM loss function is  ∑ t L s i m p l e , t {\\displaystyle \\sum _{t}L_{simple,t}} ![{\\\\displaystyle \\\\sum _{t}L_{simple,t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/445e82c1c7fdb7da14ca516e78e44bf346f093b2) with  L s i m p l e , t = E x 0 ∼ q ; z ∼ N ( 0 , I ) [ ‖ ϵ θ ( x t , t ) − z ‖ 2 ] {\\displaystyle L_{simple,t}=E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]} ![{\\\\displaystyle L_{simple,t}=E_{x_{0}\\\\sim q;z\\\\sim {\\\\mathcal {N}}\\(0,I\\)}\\\\left\\[\\\\left\\\\|\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-z\\\\right\\\\|^{2}\\\\right\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/935e47818aeafab5cc11a12a4dd25361dade64bc) where  x t = α ¯ t x 0 + σ t z {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}z} ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+\\\\sigma _{t}z}](https://wikimedia.org/api/rest_v1/media/math/render/svg/46b439306dae327b2ae72767693896f7505a02e9). By a change of variables,  L s i m p l e , t = E x 0 , x t ∼ q [ ‖ ϵ θ ( x t , t ) − x t − α ¯ t x 0 σ t ‖ 2 ] = E x t ∼ q , x 0 ∼ q ( ⋅ | x t ) [ ‖ ϵ θ ( x t , t ) − x t − α ¯ t x 0 σ t ‖ 2 ] {\\displaystyle L_{simple,t}=E_{x_{0},x_{t}\\sim q}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-{\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}}{\\sigma _{t}}}\\right\\|^{2}\\right]=E_{x_{t}\\sim q,x_{0}\\sim q(\\cdot |x_{t})}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-{\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}}{\\sigma _{t}}}\\right\\|^{2}\\right]} ![{\\\\displaystyle L_{simple,t}=E_{x_{0},x_{t}\\\\sim q}\\\\left\\[\\\\left\\\\|\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-{\\\\frac {x_{t}-{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}}{\\\\sigma _{t}}}\\\\right\\\\|^{2}\\\\right\\]=E_{x_{t}\\\\sim q,x_{0}\\\\sim q\\(\\\\cdot |x_{t}\\)}\\\\left\\[\\\\left\\\\|\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-{\\\\frac {x_{t}-{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}}{\\\\sigma _{t}}}\\\\right\\\\|^{2}\\\\right\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/42e46edbe79966d43c6ead0b38b9b12c12a1a2ed) and the term inside becomes a least squares regression, so if the network actually reaches the global minimum of loss, then we have  ϵ θ ( x t , t ) = x t − α ¯ t E q [ x 0 | x t ] σ t = − σ t ∇ x t ln ⁡ q ( x t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},t)={\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}E_{q}[x_{0}|x_{t}]}{\\sigma _{t}}}=-\\sigma _{t}\\nabla _{x_{t}}\\ln q(x_{t})} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},t\\)={\\\\frac {x_{t}-{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}E_{q}\\[x_{0}|x_{t}\\]}{\\\\sigma _{t}}}=-\\\\sigma _{t}\\\\nabla _{x_{t}}\\\\ln q\\(x_{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fe275f9f8a6ce998920e403651cc41b36d7b3020)\nThus, a score-based network predicts noise, and can be used for denoising. \nConversely, the continuous limit  x t − 1 = x t − d t , β t = β ( t ) d t , z t d t = d W t {\\displaystyle x_{t-1}=x_{t-dt},\\beta _{t}=\\beta (t)dt,z_{t}{\\sqrt {dt}}=dW_{t}} ![{\\\\displaystyle x_{t-1}=x_{t-dt},\\\\beta _{t}=\\\\beta \\(t\\)dt,z_{t}{\\\\sqrt {dt}}=dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4bca13017ed81d77be7e91ba3594898eaad8eea2) of the backward equation  x t − 1 = x t α t − β t σ t α t ϵ θ ( x t , t ) + β t z t ; z t ∼ N ( 0 , I ) {\\displaystyle x_{t-1}={\\frac {x_{t}}{\\sqrt {\\alpha _{t}}}}-{\\frac {\\beta _{t}}{\\sigma _{t}{\\sqrt {\\alpha _{t}}}}}\\epsilon _{\\theta }(x_{t},t)+{\\sqrt {\\beta _{t}}}z_{t};\\quad z_{t}\\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle x_{t-1}={\\\\frac {x_{t}}{\\\\sqrt {\\\\alpha _{t}}}}-{\\\\frac {\\\\beta _{t}}{\\\\sigma _{t}{\\\\sqrt {\\\\alpha _{t}}}}}\\\\epsilon _{\\\\theta }\\(x_{t},t\\)+{\\\\sqrt {\\\\beta _{t}}}z_{t};\\\\quad z_{t}\\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/da578e0f283c65143e518ace956bcd6d53da6383) gives us precisely the same equation as score-based diffusion:  x t − d t = x t ( 1 + β ( t ) d t / 2 ) + β ( t ) ∇ x t ln ⁡ q ( x t ) d t + β ( t ) d W t {\\displaystyle x_{t-dt}=x_{t}(1+\\beta (t)dt/2)+\\beta (t)\\nabla _{x_{t}}\\ln q(x_{t})dt+{\\sqrt {\\beta (t)}}dW_{t}} ![{\\\\displaystyle x_{t-dt}=x_{t}\\(1+\\\\beta \\(t\\)dt/2\\)+\\\\beta \\(t\\)\\\\nabla _{x_{t}}\\\\ln q\\(x_{t}\\)dt+{\\\\sqrt {\\\\beta \\(t\\)}}dW_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/483586f87a35977a732696a497df97d4044048a4)Thus, at infinitesimal steps of DDPM, a denoising network performs score-based diffusion. \n## Main variants\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=19 \"Edit section: Main variants\")]\n### Noise schedule\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=20 \"Edit section: Noise schedule\")]\n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Linear_diffusion_noise_scheduler.svg/250px-Linear_diffusion_noise_scheduler.svg.png)](https://en.wikipedia.org/wiki/File:Linear_diffusion_noise_scheduler.svg)Illustration for a linear diffusion noise schedule. With settings  β 1 = 10 − 4 , β 1000 = 0.02 {\\displaystyle \\beta _{1}=10^{-4},\\beta _{1000}=0.02} ![{\\\\displaystyle \\\\beta _{1}=10^{-4},\\\\beta _{1000}=0.02}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ff9073da511f4d49e0a61237024be12bba56f0fb).\nIn DDPM, the sequence of numbers  0 = σ 0 < σ 1 < ⋯ < σ T < 1 {\\displaystyle 0=\\sigma _{0}<\\sigma _{1}<\\cdots <\\sigma _{T}<1} ![{\\\\displaystyle 0=\\\\sigma _{0}<\\\\sigma _{1}<\\\\cdots <\\\\sigma _{T}<1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ebf5a84738ca04b7ced61020962d32c1638c9914) is called a (discrete time) **noise schedule**. In general, consider a strictly increasing monotonic function  σ {\\displaystyle \\sigma } ![{\\\\displaystyle \\\\sigma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/59f59b7c3e6fdb1d0365a494b81fb9a696138c36) of type  R → ( 0 , 1 ) {\\displaystyle \\mathbb {R} \\to (0,1)} ![{\\\\displaystyle \\\\mathbb {R} \\\\to \\(0,1\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/834035a83ea83450964217f66a1ddbd03cc5462c), such as the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function \"Sigmoid function\"). In that case, a noise schedule is a sequence of real numbers  λ 1 < λ 2 < ⋯ < λ T {\\displaystyle \\lambda _{1}<\\lambda _{2}<\\cdots <\\lambda _{T}} ![{\\\\displaystyle \\\\lambda _{1}<\\\\lambda _{2}<\\\\cdots <\\\\lambda _{T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/62c26598dd7977d812d37973cd365c676433388a). It then defines a sequence of noises  σ t := σ ( λ t ) {\\displaystyle \\sigma _{t}:=\\sigma (\\lambda _{t})} ![{\\\\displaystyle \\\\sigma _{t}:=\\\\sigma \\(\\\\lambda _{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4036cfa678f1d760878f1c8fb3441f439a765cba), which then derives the other quantities  β t = 1 − 1 − σ t 2 1 − σ t − 1 2 {\\displaystyle \\beta _{t}=1-{\\frac {1-\\sigma _{t}^{2}}{1-\\sigma _{t-1}^{2}}}} ![{\\\\displaystyle \\\\beta _{t}=1-{\\\\frac {1-\\\\sigma _{t}^{2}}{1-\\\\sigma _{t-1}^{2}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bb61745ac9ded677cde9e59446d3f125625ed323). \nIn order to use arbitrary noise schedules, instead of training a noise prediction model  ϵ θ ( x t , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac1d100b70d76dbb0e1429000edc61529a2c1724), one trains  ϵ θ ( x t , σ t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},\\sigma _{t})} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},\\\\sigma _{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7fc1cff9d9352cb2b3748318726c3d13de3c3f98). \nSimilarly, for the noise conditional score network, instead of training  f θ ( x t , t ) {\\displaystyle f_{\\theta }(x_{t},t)} ![{\\\\displaystyle f_{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ddf5f34ddabbac2f26dd8199901ceacf0f3384a7), one trains  f θ ( x t , σ t ) {\\displaystyle f_{\\theta }(x_{t},\\sigma _{t})} ![{\\\\displaystyle f_{\\\\theta }\\(x_{t},\\\\sigma _{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a9e037be8e7aa20335c08f94019d26dbde2dcf57). \n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=21 \"Edit section: Denoising Diffusion Implicit Model \\(DDIM\\)\")]\nThe original DDPM method for generating images is slow, since the forward diffusion process usually takes  T ∼ 1000 {\\displaystyle T\\sim 1000} ![{\\\\displaystyle T\\\\sim 1000}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a0ac506b6132020f08e5333fb547089bf535ea11) to make the distribution of  x T {\\displaystyle x_{T}} ![{\\\\displaystyle x_{T}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/591426ff2cb83d4938e4025bf2d126628e1123b5) to appear close to gaussian. However this means the backward diffusion process also take 1000 steps. Unlike the forward diffusion process, which can skip steps as  x t | x 0 {\\displaystyle x_{t}|x_{0}} ![{\\\\displaystyle x_{t}|x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8f50baa0e37ba485884dc1947ae04911bc3b09b) is gaussian for all  t ≥ 1 {\\displaystyle t\\geq 1} ![{\\\\displaystyle t\\\\geq 1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6946f8f50822de9e8e5e4c460ecbd4c05c644e15), the backward diffusion process does not allow skipping steps. For example, to sample  x t − 2 | x t − 1 ∼ N ( μ θ ( x t − 1 , t − 1 ) , Σ θ ( x t − 1 , t − 1 ) ) {\\displaystyle x_{t-2}|x_{t-1}\\sim {\\mathcal {N}}(\\mu _{\\theta }(x_{t-1},t-1),\\Sigma _{\\theta }(x_{t-1},t-1))} ![{\\\\displaystyle x_{t-2}|x_{t-1}\\\\sim {\\\\mathcal {N}}\\(\\\\mu _{\\\\theta }\\(x_{t-1},t-1\\),\\\\Sigma _{\\\\theta }\\(x_{t-1},t-1\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed3447acde57c5a19ffbedb7e144bcff64fc1167) requires the model to first sample  x t − 1 {\\displaystyle x_{t-1}} ![{\\\\displaystyle x_{t-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5218e6b1bb5ac7a2f8f61a01c8ab2cdce1a8ae1e). Attempting to directly sample  x t − 2 | x t {\\displaystyle x_{t-2}|x_{t}} ![{\\\\displaystyle x_{t-2}|x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8eb5247b3f1445207d07bc4dd2c9e8becf9c49f5) would require us to marginalize out  x t − 1 {\\displaystyle x_{t-1}} ![{\\\\displaystyle x_{t-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5218e6b1bb5ac7a2f8f61a01c8ab2cdce1a8ae1e), which is generally intractable. \nDDIM[[22]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-22) is a method to take any model trained on DDPM loss, and use it to sample with some steps skipped, sacrificing an adjustable amount of quality. If we generate the Markovian chain case in DDPM to non-Markovian case, DDIM corresponds to the case that the reverse process has variance equals to 0. In other words, the reverse process (and also the forward process) is deterministic. When using fewer sampling steps, DDIM outperforms DDPM. \nIn detail, the DDIM sampling method is as follows. Start with the forward diffusion process  x t = α ¯ t x 0 + σ t ϵ {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}\\epsilon } ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+\\\\sigma _{t}\\\\epsilon }](https://wikimedia.org/api/rest_v1/media/math/render/svg/8c67d008037977b34cd2d739b5230ffbfe9b32c8). Then, during the backward denoising process, given  x t , ϵ θ ( x t , t ) {\\displaystyle x_{t},\\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle x_{t},\\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fb54dcb176a43985f008cbecd728e0580e92c88c), the original data is estimated as  x 0 ′ = x t − σ t ϵ θ ( x t , t ) α ¯ t {\\displaystyle x_{0}'={\\frac {x_{t}-\\sigma _{t}\\epsilon _{\\theta }(x_{t},t)}{\\sqrt {{\\bar {\\alpha }}_{t}}}}} ![{\\\\displaystyle x_{0}'={\\\\frac {x_{t}-\\\\sigma _{t}\\\\epsilon _{\\\\theta }\\(x_{t},t\\)}{\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4de311f19ff4670e169ade523a58990b6a207e4)then the backward diffusion process can jump to any step  0 ≤ s < t {\\displaystyle 0\\leq s<t} ![{\\\\displaystyle 0\\\\leq s<t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9df1ebe9d642c5bddfbee347a4f75c9ed47ed32d), and the next denoised sample is  x s = α ¯ s x 0 ′ + σ s 2 − ( σ s ′ ) 2 ϵ θ ( x t , t ) + σ s ′ ϵ {\\displaystyle x_{s}={\\sqrt {{\\bar {\\alpha }}_{s}}}x_{0}'+{\\sqrt {\\sigma _{s}^{2}-(\\sigma '_{s})^{2}}}\\epsilon _{\\theta }(x_{t},t)+\\sigma _{s}'\\epsilon } ![{\\\\displaystyle x_{s}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{s}}}x_{0}'+{\\\\sqrt {\\\\sigma _{s}^{2}-\\(\\\\sigma '_{s}\\)^{2}}}\\\\epsilon _{\\\\theta }\\(x_{t},t\\)+\\\\sigma _{s}'\\\\epsilon }](https://wikimedia.org/api/rest_v1/media/math/render/svg/9bd517eefb13571ada32a394bfa3c9324b862268)where  σ s ′ {\\displaystyle \\sigma _{s}'} ![{\\\\displaystyle \\\\sigma _{s}'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0c4829c8ff7953a28bbbb65cf4aa13edc1d64048) is an arbitrary real number within the range  [ 0 , σ s ] {\\displaystyle [0,\\sigma _{s}]} ![{\\\\displaystyle \\[0,\\\\sigma _{s}\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6fce0d63110803873c85001c16c2de30e5f17903), and  ϵ ∼ N ( 0 , I ) {\\displaystyle \\epsilon \\sim {\\mathcal {N}}(0,I)} ![{\\\\displaystyle \\\\epsilon \\\\sim {\\\\mathcal {N}}\\(0,I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ad20b847942b4ea4435c9e74bb5f22c759c648fa) is a newly sampled gaussian noise.[[14]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:7-14) If all  σ s ′ = 0 {\\displaystyle \\sigma _{s}'=0} ![{\\\\displaystyle \\\\sigma _{s}'=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a305a77385cfaf2092e7b023fea72dc771806428), then the backward process becomes deterministic, and this special case of DDIM is also called \"DDIM\". The original paper noted that when the process is deterministic, samples generated with only 20 steps are already very similar to ones generated with 1000 steps on the high-level. \nThe original paper recommended defining a single \"eta value\"  η ∈ [ 0 , 1 ] {\\displaystyle \\eta \\in [0,1]} ![{\\\\displaystyle \\\\eta \\\\in \\[0,1\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4ca0461d22b79e5f47487a0b96d7e99eac559451), such that  σ s ′ = η σ ~ s {\\displaystyle \\sigma _{s}'=\\eta {\\tilde {\\sigma }}_{s}} ![{\\\\displaystyle \\\\sigma _{s}'=\\\\eta {\\\\tilde {\\\\sigma }}_{s}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/034e208e0213b09828afc17e96adb50c4acb35ac). When  η = 1 {\\displaystyle \\eta =1} ![{\\\\displaystyle \\\\eta =1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9b65b387d2e1c91321cafa675da485eabb20ca82), this is the original DDPM. When  η = 0 {\\displaystyle \\eta =0} ![{\\\\displaystyle \\\\eta =0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2dc20bdff327bfeab94c37936d4c1a05dfbd9784), this is the fully deterministic DDIM. For intermediate values, the process interpolates between them. \nBy the equivalence, the DDIM algorithm also applies for score-based diffusion models. \n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=22 \"Edit section: Latent diffusion model \\(LDM\\)\")]\nMain article: [Latent diffusion model](https://en.wikipedia.org/wiki/Latent_diffusion_model \"Latent diffusion model\")\nSince the diffusion model is a general method for modelling probability distributions, if one wants to model a distribution over images, one can first encode the images into a lower-dimensional space by an encoder, then use a diffusion model to model the distribution over encoded images. Then to generate an image, one can sample from the diffusion model, then use a decoder to decode it into an image.[[23]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:2-23)\nThe encoder-decoder pair is most often a [variational autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder \"Variational autoencoder\") (VAE). \n### Architectural improvements\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=23 \"Edit section: Architectural improvements\")]\n[[24]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-24) proposed various architectural improvements. For example, they proposed log-space interpolation during backward sampling. Instead of sampling from  x t − 1 ∼ N ( μ ~ t ( x t , x ~ 0 ) , σ ~ t 2 I ) {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),{\\tilde {\\sigma }}_{t}^{2}I)} ![{\\\\displaystyle x_{t-1}\\\\sim {\\\\mathcal {N}}\\({\\\\tilde {\\\\mu }}_{t}\\(x_{t},{\\\\tilde {x}}_{0}\\),{\\\\tilde {\\\\sigma }}_{t}^{2}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/36b4d99c0cb6d9420f52e54358ee832b83a047f6), they recommended sampling from  N ( μ ~ t ( x t , x ~ 0 ) , ( σ t v σ ~ t 1 − v ) 2 I ) {\\displaystyle {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),(\\sigma _{t}^{v}{\\tilde {\\sigma }}_{t}^{1-v})^{2}I)} ![{\\\\displaystyle {\\\\mathcal {N}}\\({\\\\tilde {\\\\mu }}_{t}\\(x_{t},{\\\\tilde {x}}_{0}\\),\\(\\\\sigma _{t}^{v}{\\\\tilde {\\\\sigma }}_{t}^{1-v}\\)^{2}I\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5903f253d6e5795ddb42ae157edc8585fd69b5ad) for a learned parameter  v {\\displaystyle v} ![{\\\\displaystyle v}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597). \nIn the _v-prediction_ formalism, the noising formula  x t = α ¯ t x 0 + 1 − α ¯ t ϵ t {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+{\\sqrt {1-{\\bar {\\alpha }}_{t}}}\\epsilon _{t}} ![{\\\\displaystyle x_{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}x_{0}+{\\\\sqrt {1-{\\\\bar {\\\\alpha }}_{t}}}\\\\epsilon _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e52648df74aef78ee8406eb761d1dab4409acbb) is reparameterised by an angle  ϕ t {\\displaystyle \\phi _{t}} ![{\\\\displaystyle \\\\phi _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e1775c8a44fcf88e28ff6a5ec758f22bec15b84e) such that  cos ⁡ ϕ t = α ¯ t {\\displaystyle \\cos \\phi _{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}} ![{\\\\displaystyle \\\\cos \\\\phi _{t}={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aa0386c4a74fec3f23604b18e680ca0b4f940740) and a \"velocity\" defined by  cos ⁡ ϕ t ϵ t − sin ⁡ ϕ t x 0 {\\displaystyle \\cos \\phi _{t}\\epsilon _{t}-\\sin \\phi _{t}x_{0}} ![{\\\\displaystyle \\\\cos \\\\phi _{t}\\\\epsilon _{t}-\\\\sin \\\\phi _{t}x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ebe32a5eb8d2f4b7a09a3e2eec0e79ed743f0a3a). The network is trained to predict the velocity  v ^ θ {\\displaystyle {\\hat {v}}_{\\theta }} ![{\\\\displaystyle {\\\\hat {v}}_{\\\\theta }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f25fc13320a9426cc5833a4202bfa4af68c47314), and denoising is by  x ϕ t − δ = cos ⁡ ( δ ) x ϕ t − sin ⁡ ( δ ) v ^ θ ( x ϕ t ) {\\displaystyle x_{\\phi _{t}-\\delta }=\\cos(\\delta )\\;x_{\\phi _{t}}-\\sin(\\delta ){\\hat {v}}_{\\theta }\\;(x_{\\phi _{t}})} ![{\\\\displaystyle x_{\\\\phi _{t}-\\\\delta }=\\\\cos\\(\\\\delta \\)\\\\;x_{\\\\phi _{t}}-\\\\sin\\(\\\\delta \\){\\\\hat {v}}_{\\\\theta }\\\\;\\(x_{\\\\phi _{t}}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/80366264df6bdfcaae2dac54cc8d2db5eb154966).[[25]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-25) This parameterization was found to improve performance, as the model can be trained to reach total noise (i.e.  ϕ t = 90 ∘ {\\displaystyle \\phi _{t}=90^{\\circ }} ![{\\\\displaystyle \\\\phi _{t}=90^{\\\\circ }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dddbfafeb4da4b743878bb24e42a1a9d90810326)) and then reverse it, whereas the standard parameterization never reaches total noise since  α ¯ t > 0 {\\displaystyle {\\sqrt {{\\bar {\\alpha }}_{t}}}>0} ![{\\\\displaystyle {\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}>0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0295d126c54d4245f3654aaf43e01338bed0a9af) is always true.[[26]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-26)\n### Classifier guidance\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=24 \"Edit section: Classifier guidance\")]\nClassifier guidance was proposed in 2021 to improve class-conditional generation by using a classifier. The original publication used [CLIP text encoders](https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training \"Contrastive Language-Image Pre-training\") to improve text-conditional image generation.[[27]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:8-27)\nSuppose we wish to sample not from the entire distribution of images, but conditional on the image description. We don't want to sample a generic image, but an image that fits the description \"black cat with red eyes\". Generally, we want to sample from the distribution  p ( x | y ) {\\displaystyle p(x|y)} ![{\\\\displaystyle p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b99b32ed9c0b94759956558b359f8da3ab98a23f), where  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) ranges over images, and  y {\\displaystyle y} ![{\\\\displaystyle y}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d) ranges over classes of images (a description \"black cat with red eyes\" is just a very detailed class, and a class \"cat\" is just a very vague description). \nTaking the perspective of the [noisy channel model](https://en.wikipedia.org/wiki/Noisy_channel_model \"Noisy channel model\"), we can understand the process as follows: To generate an image  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) conditional on description  y {\\displaystyle y} ![{\\\\displaystyle y}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d), we imagine that the requester really had in mind an image  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4), but the image is passed through a noisy channel and came out garbled, as  y {\\displaystyle y} ![{\\\\displaystyle y}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d). Image generation is then nothing but inferring which  x {\\displaystyle x} ![{\\\\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) the requester had in mind. \nIn other words, conditional image generation is simply \"translating from a textual language into a pictorial language\". Then, as in noisy-channel model, we use Bayes theorem to get  p ( x | y ) ∝ p ( y | x ) p ( x ) {\\displaystyle p(x|y)\\propto p(y|x)p(x)} ![{\\\\displaystyle p\\(x|y\\)\\\\propto p\\(y|x\\)p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/28abcea33b9bc85d1242ab38d9a97c835343204f) in other words, if we have a good model of the space of all images, and a good image-to-class translator, we get a class-to-image translator \"for free\". In the equation for backward diffusion, the score  ∇ ln ⁡ p ( x ) {\\displaystyle \\nabla \\ln p(x)} ![{\\\\displaystyle \\\\nabla \\\\ln p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8a1c14ba0cd2d1b35742f3e298cbf60950ec11de) can be replaced by  ∇ x ln ⁡ p ( x | y ) = ∇ x ln ⁡ p ( x ) ⏟ score + ∇ x ln ⁡ p ( y | x ) ⏟ classifier guidance {\\displaystyle \\nabla _{x}\\ln p(x|y)=\\underbrace {\\nabla _{x}\\ln p(x)} _{\\text{score}}+\\underbrace {\\nabla _{x}\\ln p(y|x)} _{\\text{classifier guidance}}} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x|y\\)=\\\\underbrace {\\\\nabla _{x}\\\\ln p\\(x\\)} _{\\\\text{score}}+\\\\underbrace {\\\\nabla _{x}\\\\ln p\\(y|x\\)} _{\\\\text{classifier guidance}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/807d5f0230f7af3f0814dfe5f7ffdf493dfa9050) where  ∇ x ln ⁡ p ( x ) {\\displaystyle \\nabla _{x}\\ln p(x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47795439e20b97e2fc0ffd87836b84b61e326812) is the score function, trained as previously described, and  ∇ x ln ⁡ p ( y | x ) {\\displaystyle \\nabla _{x}\\ln p(y|x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(y|x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/31b54d6d048b57adfbd7f52dccdf393b6cc7e656) is found by using a differentiable image classifier. \nDuring the diffusion process, we need to condition on the time, giving ∇ x t ln ⁡ p ( x t | y , t ) = ∇ x t ln ⁡ p ( y | x t , t ) + ∇ x t ln ⁡ p ( x t | t ) {\\displaystyle \\nabla _{x_{t}}\\ln p(x_{t}|y,t)=\\nabla _{x_{t}}\\ln p(y|x_{t},t)+\\nabla _{x_{t}}\\ln p(x_{t}|t)} ![{\\\\displaystyle \\\\nabla _{x_{t}}\\\\ln p\\(x_{t}|y,t\\)=\\\\nabla _{x_{t}}\\\\ln p\\(y|x_{t},t\\)+\\\\nabla _{x_{t}}\\\\ln p\\(x_{t}|t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ca44156c7bb892dc41ef83233562b1c950e3078)Although, usually the classifier model does not depend on time, in which case  p ( y | x t , t ) = p ( y | x t ) {\\displaystyle p(y|x_{t},t)=p(y|x_{t})} ![{\\\\displaystyle p\\(y|x_{t},t\\)=p\\(y|x_{t}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5efab6b052e5903c5986b81629ac6be060f79464). \nClassifier guidance is defined for the gradient of score function, thus for score-based diffusion network, but as previously noted, score-based diffusion models are equivalent to denoising models by  ϵ θ ( x t , t ) = − σ t ∇ x t ln ⁡ p ( x t | t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},t)=-\\sigma _{t}\\nabla _{x_{t}}\\ln p(x_{t}|t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},t\\)=-\\\\sigma _{t}\\\\nabla _{x_{t}}\\\\ln p\\(x_{t}|t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/137b538736878bf74a482977a78cfbbdcabe4ae9), and similarly,  ϵ θ ( x t , y , t ) = − σ t ∇ x t ln ⁡ p ( x t | y , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=-\\sigma _{t}\\nabla _{x_{t}}\\ln p(x_{t}|y,t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},y,t\\)=-\\\\sigma _{t}\\\\nabla _{x_{t}}\\\\ln p\\(x_{t}|y,t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b20af27c7c434853b1d4b11bc49e795736107b4a). Therefore, classifier guidance works for denoising diffusion as well, using the modified noise prediction:[[27]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:8-27) ϵ θ ( x t , y , t ) = ϵ θ ( x t , t ) − σ t ∇ x t ln ⁡ p ( y | x t , t ) ⏟ classifier guidance {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=\\epsilon _{\\theta }(x_{t},t)-\\underbrace {\\sigma _{t}\\nabla _{x_{t}}\\ln p(y|x_{t},t)} _{\\text{classifier guidance}}} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},y,t\\)=\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-\\\\underbrace {\\\\sigma _{t}\\\\nabla _{x_{t}}\\\\ln p\\(y|x_{t},t\\)} _{\\\\text{classifier guidance}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7edf6e6ace36876f5928ae305f51ba0376c73360)\n#### With temperature\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=25 \"Edit section: With temperature\")]\nThe classifier-guided diffusion model samples from  p ( x | y ) {\\displaystyle p(x|y)} ![{\\\\displaystyle p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b99b32ed9c0b94759956558b359f8da3ab98a23f), which is concentrated around the [maximum a posteriori estimate](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation \"Maximum a posteriori estimation\") arg ⁡ max x p ( x | y ) {\\displaystyle \\arg \\max _{x}p(x|y)} ![{\\\\displaystyle \\\\arg \\\\max _{x}p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d4685e4a0f2cb277f9a27445362e5a08e117292). If we want to force the model to move towards the [maximum likelihood estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation \"Maximum likelihood estimation\") arg ⁡ max x p ( y | x ) {\\displaystyle \\arg \\max _{x}p(y|x)} ![{\\\\displaystyle \\\\arg \\\\max _{x}p\\(y|x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b85b8873e33e4b6bde528fa07f2463ffc345d1e0), we can use  p γ ( x | y ) ∝ p ( y | x ) γ p ( x ) {\\displaystyle p_{\\gamma }(x|y)\\propto p(y|x)^{\\gamma }p(x)} ![{\\\\displaystyle p_{\\\\gamma }\\(x|y\\)\\\\propto p\\(y|x\\)^{\\\\gamma }p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b2dc04dfdf68b066b1bec2e5cca931c8d43c61ad) where  γ > 0 {\\displaystyle \\gamma >0} ![{\\\\displaystyle \\\\gamma >0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/775a6435e4270cddf2cd7dcb486c20f7f4bb8cee) is interpretable as _[inverse temperature](https://en.wikipedia.org/wiki/Thermodynamic_beta \"Thermodynamic beta\")_. In the context of diffusion models, it is usually called the **guidance scale**. A high  γ {\\displaystyle \\gamma } ![{\\\\displaystyle \\\\gamma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a) would force the model to sample from a distribution concentrated around  arg ⁡ max x p ( y | x ) {\\displaystyle \\arg \\max _{x}p(y|x)} ![{\\\\displaystyle \\\\arg \\\\max _{x}p\\(y|x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b85b8873e33e4b6bde528fa07f2463ffc345d1e0). This sometimes improves quality of generated images.[[27]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:8-27)\nThis gives a modification to the previous equation: ∇ x ln ⁡ p β ( x | y ) = ∇ x ln ⁡ p ( x ) + γ ∇ x ln ⁡ p ( y | x ) {\\displaystyle \\nabla _{x}\\ln p_{\\beta }(x|y)=\\nabla _{x}\\ln p(x)+\\gamma \\nabla _{x}\\ln p(y|x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p_{\\\\beta }\\(x|y\\)=\\\\nabla _{x}\\\\ln p\\(x\\)+\\\\gamma \\\\nabla _{x}\\\\ln p\\(y|x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7c52745e42373118ffb565f88d5aca8fa5d7c2e8)For denoising models, it corresponds to[[28]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:5-28) ϵ θ ( x t , y , t ) = ϵ θ ( x t , t ) − γ σ t ∇ x t ln ⁡ p ( y | x t , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=\\epsilon _{\\theta }(x_{t},t)-\\gamma \\sigma _{t}\\nabla _{x_{t}}\\ln p(y|x_{t},t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},y,t\\)=\\\\epsilon _{\\\\theta }\\(x_{t},t\\)-\\\\gamma \\\\sigma _{t}\\\\nabla _{x_{t}}\\\\ln p\\(y|x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9b2824090461b8fbfac827c7a22b3205fdadf941)\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=26 \"Edit section: Classifier-free guidance \\(CFG\\)\")]\nIf we do not have a classifier  p ( y | x ) {\\displaystyle p(y|x)} ![{\\\\displaystyle p\\(y|x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3cad17372ea694e639c3881b2b5583632cdaa0ac), we could still extract one out of the image model itself:[[28]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:5-28) ∇ x ln ⁡ p γ ( x | y ) = ( 1 − γ ) ∇ x ln ⁡ p ( x ) + γ ∇ x ln ⁡ p ( x | y ) {\\displaystyle \\nabla _{x}\\ln p_{\\gamma }(x|y)=(1-\\gamma )\\nabla _{x}\\ln p(x)+\\gamma \\nabla _{x}\\ln p(x|y)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p_{\\\\gamma }\\(x|y\\)=\\(1-\\\\gamma \\)\\\\nabla _{x}\\\\ln p\\(x\\)+\\\\gamma \\\\nabla _{x}\\\\ln p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f271055cbdf507545cb040ae32522ada83647104) Such a model is usually trained by presenting it with both  ( x , y ) {\\displaystyle (x,y)} ![{\\\\displaystyle \\(x,y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/41cf50e4a314ca8e2c30964baa8d26e5be7a9386) and  ( x , N o n e ) {\\displaystyle (x,{\\rm {None}})} ![{\\\\displaystyle \\(x,{\\\\rm {None}}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cd5bcc611fa8f51244a60f69242b48b4b9c619fe), allowing it to model both  ∇ x ln ⁡ p ( x | y ) {\\displaystyle \\nabla _{x}\\ln p(x|y)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b60c2bc1797f6d07f8eba7c72cbec0fd3d3a9678) and  ∇ x ln ⁡ p ( x ) {\\displaystyle \\nabla _{x}\\ln p(x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47795439e20b97e2fc0ffd87836b84b61e326812). \nNote that for CFG, the diffusion model cannot be merely a generative model of the entire data distribution  ∇ x ln ⁡ p ( x ) {\\displaystyle \\nabla _{x}\\ln p(x)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47795439e20b97e2fc0ffd87836b84b61e326812). It must be a conditional generative model  ∇ x ln ⁡ p ( x | y ) {\\displaystyle \\nabla _{x}\\ln p(x|y)} ![{\\\\displaystyle \\\\nabla _{x}\\\\ln p\\(x|y\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b60c2bc1797f6d07f8eba7c72cbec0fd3d3a9678). For example, in stable diffusion, the diffusion backbone takes as input both a noisy model  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db), a time  t {\\displaystyle t} ![{\\\\displaystyle t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560), and a conditioning vector  y {\\displaystyle y} ![{\\\\displaystyle y}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d) (such as a vector encoding a text prompt), and produces a noise prediction  ϵ θ ( x t , y , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},y,t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bc8d2f907ff478f9a4072f469b62971e7182f549). \nFor denoising models, it corresponds to ϵ θ ( x t , y , t , γ ) = ϵ θ ( x t , t ) + γ ( ϵ θ ( x t , y , t ) − ϵ θ ( x t , t ) ) {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t,\\gamma )=\\epsilon _{\\theta }(x_{t},t)+\\gamma (\\epsilon _{\\theta }(x_{t},y,t)-\\epsilon _{\\theta }(x_{t},t))} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},y,t,\\\\gamma \\)=\\\\epsilon _{\\\\theta }\\(x_{t},t\\)+\\\\gamma \\(\\\\epsilon _{\\\\theta }\\(x_{t},y,t\\)-\\\\epsilon _{\\\\theta }\\(x_{t},t\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e9ffa5b2152d01371c0a7eba4809f4c6e5619207)As sampled by DDIM, the algorithm can be written as[[29]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-29) ϵ uncond ← ϵ θ ( x t , t ) ϵ cond ← ϵ θ ( x t , t , c ) ϵ CFG ← ϵ uncond + γ ( ϵ cond − ϵ uncond ) x 0 ← ( x t − σ t ϵ CFG ) / 1 − σ t 2 x s ← 1 − σ s 2 x 0 + σ s 2 − ( σ s ′ ) 2 ϵ uncond + σ s ′ ϵ {\\displaystyle {\\begin{aligned}\\epsilon _{\\text{uncond}}&\\leftarrow \\epsilon _{\\theta }(x_{t},t)\\\\\\\\\\epsilon _{\\text{cond}}&\\leftarrow \\epsilon _{\\theta }(x_{t},t,c)\\\\\\\\\\epsilon _{\\text{CFG}}&\\leftarrow \\epsilon _{\\text{uncond}}+\\gamma (\\epsilon _{\\text{cond}}-\\epsilon _{\\text{uncond}})\\\\\\x_{0}&\\leftarrow (x_{t}-\\sigma _{t}\\epsilon _{\\text{CFG}})/{\\sqrt {1-\\sigma _{t}^{2}}}\\\\\\x_{s}&\\leftarrow {\\sqrt {1-\\sigma _{s}^{2}}}x_{0}+{\\sqrt {\\sigma _{s}^{2}-(\\sigma _{s}')^{2}}}\\epsilon _{\\text{uncond}}+\\sigma _{s}'\\epsilon \\\\\\\\\\end{aligned}}} ![{\\\\displaystyle {\\\\begin{aligned}\\\\epsilon _{\\\\text{uncond}}&\\\\leftarrow \\\\epsilon _{\\\\theta }\\(x_{t},t\\)\\\\\\\\\\\\epsilon _{\\\\text{cond}}&\\\\leftarrow \\\\epsilon _{\\\\theta }\\(x_{t},t,c\\)\\\\\\\\\\\\epsilon _{\\\\text{CFG}}&\\\\leftarrow \\\\epsilon _{\\\\text{uncond}}+\\\\gamma \\(\\\\epsilon _{\\\\text{cond}}-\\\\epsilon _{\\\\text{uncond}}\\)\\\\\\\\x_{0}&\\\\leftarrow \\(x_{t}-\\\\sigma _{t}\\\\epsilon _{\\\\text{CFG}}\\)/{\\\\sqrt {1-\\\\sigma _{t}^{2}}}\\\\\\\\x_{s}&\\\\leftarrow {\\\\sqrt {1-\\\\sigma _{s}^{2}}}x_{0}+{\\\\sqrt {\\\\sigma _{s}^{2}-\\(\\\\sigma _{s}'\\)^{2}}}\\\\epsilon _{\\\\text{uncond}}+\\\\sigma _{s}'\\\\epsilon \\\\\\\\\\\\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e45222436dc2d62ed4b20b6fb832277436f900eb)A similar technique applies to language model sampling. Also, if the unconditional generation  ϵ uncond ← ϵ θ ( x t , t ) {\\displaystyle \\epsilon _{\\text{uncond}}\\leftarrow \\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\epsilon _{\\\\text{uncond}}\\\\leftarrow \\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b3955fa014e1a9ef619e73e0d3a1b237a714a257) is replaced by  ϵ neg cond ← ϵ θ ( x t , t , c ′ ) {\\displaystyle \\epsilon _{\\text{neg cond}}\\leftarrow \\epsilon _{\\theta }(x_{t},t,c')} ![{\\\\displaystyle \\\\epsilon _{\\\\text{neg cond}}\\\\leftarrow \\\\epsilon _{\\\\theta }\\(x_{t},t,c'\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a3a64c6d2b3d7d93eb5e758d0f7a48984b68b87), then it results in negative prompting, which pushes the generation away from  c ′ {\\displaystyle c'} ![{\\\\displaystyle c'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f295e32663780aa8800e3106dba9d6e04e57cdc6) condition.[[30]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-30)[[31]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-31)\n### Samplers\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=27 \"Edit section: Samplers\")]\nGiven a diffusion model, one may regard it either as a continuous process, and sample from it by integrating a SDE, or one can regard it as a discrete process, and sample from it by iterating the discrete steps. The choice of the \"**noise schedule** \"  β t {\\displaystyle \\beta _{t}} ![{\\\\displaystyle \\\\beta _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b801e8682d2f1345dbeaca1657eef676bd12ab4a) can also affect the quality of samples. A noise schedule is a function that sends a natural number to a noise level:  t ↦ β t , t ∈ { 1 , 2 , … } , β ∈ ( 0 , 1 ) {\\displaystyle t\\mapsto \\beta _{t},\\quad t\\in \\\\{1,2,\\dots \\\\},\\beta \\in (0,1)} ![{\\\\displaystyle t\\\\mapsto \\\\beta _{t},\\\\quad t\\\\in \\\\{1,2,\\\\dots \\\\},\\\\beta \\\\in \\(0,1\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7fb61a297a77456b54bdf3d15659a54408df6774)A noise schedule is more often specified by a map  t ↦ σ t {\\displaystyle t\\mapsto \\sigma _{t}} ![{\\\\displaystyle t\\\\mapsto \\\\sigma _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f185176ce18317a7245950d7d01794cb265754a5). The two definitions are equivalent, since  β t = 1 − 1 − σ t 2 1 − σ t − 1 2 {\\displaystyle \\beta _{t}=1-{\\frac {1-\\sigma _{t}^{2}}{1-\\sigma _{t-1}^{2}}}} ![{\\\\displaystyle \\\\beta _{t}=1-{\\\\frac {1-\\\\sigma _{t}^{2}}{1-\\\\sigma _{t-1}^{2}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bb61745ac9ded677cde9e59446d3f125625ed323). \nIn the DDPM perspective, one can use the DDPM itself (with noise), or DDIM (with adjustable amount of noise). The case where one adds noise is sometimes called ancestral sampling.[[32]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-32) One can interpolate between noise and no noise. The amount of noise is denoted  η {\\displaystyle \\eta } ![{\\\\displaystyle \\\\eta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/e4d701857cf5fbec133eebaf94deadf722537f64) (\"eta value\") in the DDIM paper, with  η = 0 {\\displaystyle \\eta =0} ![{\\\\displaystyle \\\\eta =0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2dc20bdff327bfeab94c37936d4c1a05dfbd9784) denoting no noise (as in _deterministic_ DDIM), and  η = 1 {\\displaystyle \\eta =1} ![{\\\\displaystyle \\\\eta =1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9b65b387d2e1c91321cafa675da485eabb20ca82) denoting full noise (as in DDPM). \nIn the perspective of SDE, one can use any of the [numerical integration methods](https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations \"Numerical methods for ordinary differential equations\"), such as [Euler–Maruyama method](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method \"Euler–Maruyama method\"), [Heun's method](https://en.wikipedia.org/wiki/Heun%27s_method \"Heun's method\"), [linear multistep methods](https://en.wikipedia.org/wiki/Linear_multistep_method \"Linear multistep method\"), etc. Just as in the discrete case, one can add an adjustable amount of noise during the integration.[[33]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-33)\nA survey and comparison of samplers in the context of image generation is in.[[34]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-34)\n### Other examples\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=28 \"Edit section: Other examples\")]\nNotable variants include[[35]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-35) Poisson flow generative model,[[36]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-36) consistency model,[[37]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-37) critically damped Langevin diffusion,[[38]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-38) GenPhys,[[39]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-39) cold diffusion,[[40]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-40) discrete diffusion,[[41]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-41)[[42]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-42) etc. \n## Flow-based diffusion model\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=29 \"Edit section: Flow-based diffusion model\")]\nAbstractly speaking, the idea of diffusion model is to take an unknown probability distribution (the distribution of natural-looking images), then progressively convert it to a known probability distribution (standard gaussian distribution), by building an absolutely continuous probability path connecting them. The probability path is in fact defined implicitly by the score function  ∇ ln ⁡ p t {\\displaystyle \\nabla \\ln p_{t}} ![{\\\\displaystyle \\\\nabla \\\\ln p_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c60d739be3204db5cd745f527fd9f52ab029a166). \nIn denoising diffusion models, the forward process adds noise, and the backward process removes noise. Both the forward and backward processes are [SDEs](https://en.wikipedia.org/wiki/Stochastic_differential_equation \"Stochastic differential equation\"), though the forward process is integrable in closed-form, so it can be done at no computational cost. The backward process is not integrable in closed-form, so it must be integrated step-by-step by standard SDE solvers, which can be very expensive. The probability path in diffusions model is defined through an [Itô process](https://en.wikipedia.org/wiki/It%C3%B4_process \"Itô process\") and one can retrieve the deterministic process by using the Probability ODE flow formulation.[[1]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-1)\nIn flow-based diffusion models, the forward process is a deterministic flow along a time-dependent vector field, and the backward process is also a deterministic flow along the same vector field, but going backwards. Both processes are solutions to [ODEs](https://en.wikipedia.org/wiki/Ordinary_differential_equation \"Ordinary differential equation\"). If the vector field is well-behaved, the ODE will also be well-behaved. \nGiven two distributions  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b), a flow-based model is a time-dependent velocity field  v t ( x ) {\\displaystyle v_{t}(x)} ![{\\\\displaystyle v_{t}\\(x\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3464ff06d23b203c8ec8be849eee82d873683f63) in  [ 0 , 1 ] × R d {\\displaystyle [0,1]\\times \\mathbb {R} ^{d}} ![{\\\\displaystyle \\[0,1\\]\\\\times \\\\mathbb {R} ^{d}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/82f803f72b00dec8350867d2e00987ee83600e75), such that if we start by sampling a point  x ∼ π 0 {\\displaystyle x\\sim \\pi _{0}} ![{\\\\displaystyle x\\\\sim \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ee03627a41299c8a5df4d666c92e6db726d12df2), and let it move according to the velocity field:  d d t ϕ t ( x ) = v t ( ϕ t ( x ) ) t ∈ [ 0 , 1 ] , starting from  ϕ 0 ( x ) = x {\\displaystyle {\\frac {d}{dt}}\\phi _{t}(x)=v_{t}(\\phi _{t}(x))\\quad t\\in [0,1],\\quad {\\text{starting from }}\\phi _{0}(x)=x} ![{\\\\displaystyle {\\\\frac {d}{dt}}\\\\phi _{t}\\(x\\)=v_{t}\\(\\\\phi _{t}\\(x\\)\\)\\\\quad t\\\\in \\[0,1\\],\\\\quad {\\\\text{starting from }}\\\\phi _{0}\\(x\\)=x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ea88d3aadc65bb2527c29e8f57746a44af3b49e0) we end up with a point  x 1 ∼ π 1 {\\displaystyle x_{1}\\sim \\pi _{1}} ![{\\\\displaystyle x_{1}\\\\sim \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d7494d4eac89f53319b0743db67cc0ff22bc2222). The solution  ϕ t {\\displaystyle \\phi _{t}} ![{\\\\displaystyle \\\\phi _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e1775c8a44fcf88e28ff6a5ec758f22bec15b84e) of the above ODE define a probability path  p t = [ ϕ t ] # π 0 {\\displaystyle p_{t}=[\\phi _{t}]_{\\\\#}\\pi _{0}} ![{\\\\displaystyle p_{t}=\\[\\\\phi _{t}\\]_{\\\\#}\\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b6cebb09e1947a22633ab82272694fbd51b46349) by the [pushforward measure](https://en.wikipedia.org/wiki/Pushforward_measure \"Pushforward measure\") operator. In particular,  [ ϕ 1 ] # π 0 = π 1 {\\displaystyle [\\phi _{1}]_{\\\\#}\\pi _{0}=\\pi _{1}} ![{\\\\displaystyle \\[\\\\phi _{1}\\]_{\\\\#}\\\\pi _{0}=\\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e19ca623d715badcc388055bca385f49a821743c). \nThe probability path and the velocity field also satisfy the [continuity equation](https://en.wikipedia.org/wiki/Continuity_equation \"Continuity equation\"), in the sense of probability distribution:  ∂ t p t + ∇ ⋅ ( v t p t ) = 0 {\\displaystyle \\partial _{t}p_{t}+\\nabla \\cdot (v_{t}p_{t})=0} ![{\\\\displaystyle \\\\partial _{t}p_{t}+\\\\nabla \\\\cdot \\(v_{t}p_{t}\\)=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a51df8a37665c60ecf7240a03cedd65c078fad19) To construct a probability path, we start by construct a conditional probability path  p t ( x | z ) {\\displaystyle p_{t}(x\\vert z)} ![{\\\\displaystyle p_{t}\\(x\\\\vert z\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/19de3e58783b287d96932ae9f3e24d433567194d) and the corresponding conditional velocity field  v t ( x | z ) {\\displaystyle v_{t}(x\\vert z)} ![{\\\\displaystyle v_{t}\\(x\\\\vert z\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a9ed49c25a2183205083ed0422cbf2b67431aec) on some conditional distribution  q ( z ) {\\displaystyle q(z)} ![{\\\\displaystyle q\\(z\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ab5ebe933404b9cc35a9e422f2ce81b564e1ac79). A natural choice is the Gaussian conditional probability path:  p t ( x | z ) = N ( m t ( z ) , ζ t 2 I ) {\\displaystyle p_{t}(x\\vert z)={\\mathcal {N}}\\left(m_{t}(z),\\zeta _{t}^{2}I\\right)} ![{\\\\displaystyle p_{t}\\(x\\\\vert z\\)={\\\\mathcal {N}}\\\\left\\(m_{t}\\(z\\),\\\\zeta _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd52eaac4d265aebf010e54d98bb814b0c919ae2) The conditional velocity field which corresponds to the geodesic path between conditional Gaussian path is  v t ( x | z ) = ζ t ′ ζ t ( x − m t ( z ) ) + m t ′ ( z ) {\\displaystyle v_{t}(x\\vert z)={\\frac {\\zeta _{t}'}{\\zeta _{t}}}(x-m_{t}(z))+m_{t}'(z)} ![{\\\\displaystyle v_{t}\\(x\\\\vert z\\)={\\\\frac {\\\\zeta _{t}'}{\\\\zeta _{t}}}\\(x-m_{t}\\(z\\)\\)+m_{t}'\\(z\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6b1c547fd597f69b27c25da372e5ee669dc04749) The probability path and velocity field are then computed by marginalizing \np t ( x ) = ∫ p t ( x | z ) q ( z ) d z and  v t ( x ) = E q ( z ) [ v t ( x | z ) p t ( x | z ) p t ( x ) ] {\\displaystyle p_{t}(x)=\\int p_{t}(x\\vert z)q(z)dz\\qquad {\\text{ and }}\\qquad v_{t}(x)=\\mathbb {E} _{q(z)}\\left[{\\frac {v_{t}(x\\vert z)p_{t}(x\\vert z)}{p_{t}(x)}}\\right]} ![{\\\\displaystyle p_{t}\\(x\\)=\\\\int p_{t}\\(x\\\\vert z\\)q\\(z\\)dz\\\\qquad {\\\\text{ and }}\\\\qquad v_{t}\\(x\\)=\\\\mathbb {E} _{q\\(z\\)}\\\\left\\[{\\\\frac {v_{t}\\(x\\\\vert z\\)p_{t}\\(x\\\\vert z\\)}{p_{t}\\(x\\)}}\\\\right\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/890e2a6c6ac7b9950d968434ed35f6da091bd868)\n### Optimal transport flow\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=30 \"Edit section: Optimal transport flow\")]\nThe idea of **optimal transport flow** [[43]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-43) is to construct a probability path minimizing the [Wasserstein metric](https://en.wikipedia.org/wiki/Wasserstein_metric \"Wasserstein metric\"). The distribution on which we condition is an approximation of the optimal transport plan between  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b):  z = ( x 0 , x 1 ) {\\displaystyle z=(x_{0},x_{1})} ![{\\\\displaystyle z=\\(x_{0},x_{1}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/307d6286389df58f02c26ec4fb343c6b45e258bb) and  q ( z ) = Γ ( π 0 , π 1 ) {\\displaystyle q(z)=\\Gamma (\\pi _{0},\\pi _{1})} ![{\\\\displaystyle q\\(z\\)=\\\\Gamma \\(\\\\pi _{0},\\\\pi _{1}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c860e5e10ec7223a24402d811b0ad46380c1b795), where  Γ {\\displaystyle \\Gamma } ![{\\\\displaystyle \\\\Gamma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/4cfde86a3f7ec967af9955d0988592f0693d2b19) is the optimal transport plan, which can be approximated by **mini-batch optimal transport.** If the batch size is not large, then the transport it computes can be very far from the true optimal transport. \n### Rectified flow\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=31 \"Edit section: Rectified flow\")]\nThe idea of **rectified flow[[44]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:0-44)**[[45]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-45) is to learn a flow model such that the velocity is nearly constant along each flow path. This is beneficial, because we can integrate along such a vector field with very few steps. For example, if an ODE  ϕ t ˙ ( x ) = v t ( ϕ t ( x ) ) {\\displaystyle {\\dot {\\phi _{t}}}(x)=v_{t}(\\phi _{t}(x))} ![{\\\\displaystyle {\\\\dot {\\\\phi _{t}}}\\(x\\)=v_{t}\\(\\\\phi _{t}\\(x\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdd969a26592cefa771d3273f52246275313819a) follows perfectly straight paths, it simplifies to  ϕ t ( x ) = x 0 + t ⋅ v 0 ( x 0 ) {\\displaystyle \\phi _{t}(x)=x_{0}+t\\cdot v_{0}(x_{0})} ![{\\\\displaystyle \\\\phi _{t}\\(x\\)=x_{0}+t\\\\cdot v_{0}\\(x_{0}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aac4df50ad51860db3680906343c46f25ae4403c), allowing for exact solutions in one step. In practice, we cannot reach such perfection, but when the flow field is nearly so, we can take a few large steps instead of many little steps. \n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Flow1.gif/250px-Flow1.gif)](https://en.wikipedia.org/wiki/File:Flow1.gif) | [![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Flow0.gif/250px-Flow0.gif)](https://en.wikipedia.org/wiki/File:Flow0.gif) |  [![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flow2.gif/250px-Flow2.gif)](https://en.wikipedia.org/wiki/File:Flow2.gif)  \n---|---|---  \nLinear interpolation  | Rectified Flow  |  Straightened Rectified Flow [[1]](https://www.cs.utexas.edu/~lqiang/rectflow/html/intro.html)  \nThe general idea is to start with two distributions  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b), then construct a flow field  ϕ 0 = { ϕ t : t ∈ [ 0 , 1 ] } {\\displaystyle \\phi ^{0}=\\\\{\\phi _{t}:t\\in [0,1]\\\\}} ![{\\\\displaystyle \\\\phi ^{0}=\\\\{\\\\phi _{t}:t\\\\in \\[0,1\\]\\\\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6b4fb1d3d1c4633a6248cbd80e8a1c58a5a70a3) from it, then repeatedly apply a \"reflow\" operation to obtain successive flow fields  ϕ 1 , ϕ 2 , … {\\displaystyle \\phi ^{1},\\phi ^{2},\\dots } ![{\\\\displaystyle \\\\phi ^{1},\\\\phi ^{2},\\\\dots }](https://wikimedia.org/api/rest_v1/media/math/render/svg/90386728f8b1258c18976ee1b0ca7ae96f66e4e5), each straighter than the previous one. When the flow field is straight enough for the application, we stop. \nGenerally, for any time-differentiable process  ϕ t {\\displaystyle \\phi _{t}} ![{\\\\displaystyle \\\\phi _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e1775c8a44fcf88e28ff6a5ec758f22bec15b84e),  v t {\\displaystyle v_{t}} ![{\\\\displaystyle v_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7be17a7e5bec78adf7afc13d266bdd9514963783) can be estimated by solving:  min θ ∫ 0 1 E x ∼ p t [ ‖ v t ( x , θ ) − v t ( x ) ‖ 2 ] d t . {\\displaystyle \\min _{\\theta }\\int _{0}^{1}\\mathbb {E} _{x\\sim p_{t}}\\left[\\lVert {v_{t}(x,\\theta )-v_{t}(x)}\\rVert ^{2}\\right]\\,\\mathrm {d} t.} ![{\\\\displaystyle \\\\min _{\\\\theta }\\\\int _{0}^{1}\\\\mathbb {E} _{x\\\\sim p_{t}}\\\\left\\[\\\\lVert {v_{t}\\(x,\\\\theta \\)-v_{t}\\(x\\)}\\\\rVert ^{2}\\\\right\\]\\\\,\\\\mathrm {d} t.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c22464149a08a692b55bb231b6858d8ae24f3233)\nIn rectified flow, by injecting strong priors that intermediate trajectories are straight, it can achieve both theoretical relevance for optimal transport and computational efficiency, as ODEs with straight paths can be simulated precisely without time discretization. \n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Rectified_Flow.png/250px-Rectified_Flow.png)](https://en.wikipedia.org/wiki/File:Rectified_Flow.png)Transport by rectified flow[[44]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:0-44)\nSpecifically, rectified flow seeks to match an ODE with the marginal distributions of the **linear interpolation** between points from distributions  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b). Given observations  x 0 ∼ π 0 {\\displaystyle x_{0}\\sim \\pi _{0}} ![{\\\\displaystyle x_{0}\\\\sim \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f739b447941c4cd6a560ca34b6126ae934cac9ca) and  x 1 ∼ π 1 {\\displaystyle x_{1}\\sim \\pi _{1}} ![{\\\\displaystyle x_{1}\\\\sim \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d7494d4eac89f53319b0743db67cc0ff22bc2222), the canonical linear interpolation  x t = t x 1 + ( 1 − t ) x 0 , t ∈ [ 0 , 1 ] {\\displaystyle x_{t}=tx_{1}+(1-t)x_{0},t\\in [0,1]} ![{\\\\displaystyle x_{t}=tx_{1}+\\(1-t\\)x_{0},t\\\\in \\[0,1\\]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3f1f37663ec351b027f0231aedc152e0e9ffa1c4) yields a trivial case  x ˙ t = x 1 − x 0 {\\displaystyle {\\dot {x}}_{t}=x_{1}-x_{0}} ![{\\\\displaystyle {\\\\dot {x}}_{t}=x_{1}-x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/56bfa593829a604e1fcf1b22be2679bcd5bb36be), which cannot be causally simulated without  x 1 {\\displaystyle x_{1}} ![{\\\\displaystyle x_{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8788bf85d532fa88d1fb25eff6ae382a601c308). To address this,  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) is \"projected\" into a space of causally simulatable ODEs, by minimizing the least squares loss with respect to the direction  x 1 − x 0 {\\displaystyle x_{1}-x_{0}} ![{\\\\displaystyle x_{1}-x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c2be377fc132914a5a9e9a747065b89768311e0b):  min θ ∫ 0 1 E π 0 , π 1 , p t [ ‖ ( x 1 − x 0 ) − v t ( x t ) ‖ 2 ] d t . {\\displaystyle \\min _{\\theta }\\int _{0}^{1}\\mathbb {E} _{\\pi _{0},\\pi _{1},p_{t}}\\left[\\lVert {(x_{1}-x_{0})-v_{t}(x_{t})}\\rVert ^{2}\\right]\\,\\mathrm {d} t.} ![{\\\\displaystyle \\\\min _{\\\\theta }\\\\int _{0}^{1}\\\\mathbb {E} _{\\\\pi _{0},\\\\pi _{1},p_{t}}\\\\left\\[\\\\lVert {\\(x_{1}-x_{0}\\)-v_{t}\\(x_{t}\\)}\\\\rVert ^{2}\\\\right\\]\\\\,\\\\mathrm {d} t.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ce12fef7ad8834f2a89cb7ec8d31bb17c0cd7391)\nThe data pair  ( x 0 , x 1 ) {\\displaystyle (x_{0},x_{1})} ![{\\\\displaystyle \\(x_{0},x_{1}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f900f90385eda503cb4ba0f61c583c03a61d007d) can be any coupling of  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b), typically independent (i.e.,  ( x 0 , x 1 ) ∼ π 0 × π 1 {\\displaystyle (x_{0},x_{1})\\sim \\pi _{0}\\times \\pi _{1}} ![{\\\\displaystyle \\(x_{0},x_{1}\\)\\\\sim \\\\pi _{0}\\\\times \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/262f9e6785d831a845af10af601b370b3fed8545)) obtained by randomly combining observations from  π 0 {\\displaystyle \\pi _{0}} ![{\\\\displaystyle \\\\pi _{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c00f5854464f99e26d9264b35295922f2c881177) and  π 1 {\\displaystyle \\pi _{1}} ![{\\\\displaystyle \\\\pi _{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/542cbd3dacd0a061d666ed7fc4ed7ad15b47444b). This process ensures that the trajectories closely mirror the density map of  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) trajectories but _reroute_ at intersections to ensure causality. \n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Reflow_Illustration.png/500px-Reflow_Illustration.png)](https://en.wikipedia.org/wiki/File:Reflow_Illustration.png)The reflow process[[44]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:0-44)\nA distinctive aspect of rectified flow is its capability for \"**reflow** \", which straightens the trajectory of ODE paths. Denote the rectified flow  ϕ 0 = { ϕ t : t ∈ [ 0 , 1 ] } {\\displaystyle \\phi ^{0}=\\\\{\\phi _{t}:t\\in [0,1]\\\\}} ![{\\\\displaystyle \\\\phi ^{0}=\\\\{\\\\phi _{t}:t\\\\in \\[0,1\\]\\\\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6b4fb1d3d1c4633a6248cbd80e8a1c58a5a70a3) induced from  ( x 0 , x 1 ) {\\displaystyle (x_{0},x_{1})} ![{\\\\displaystyle \\(x_{0},x_{1}\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f900f90385eda503cb4ba0f61c583c03a61d007d) as  ϕ 0 = R e c t f l o w ( ( x 0 , x 1 ) ) {\\displaystyle \\phi ^{0}={\\mathsf {Rectflow}}((x_{0},x_{1}))} ![{\\\\displaystyle \\\\phi ^{0}={\\\\mathsf {Rectflow}}\\(\\(x_{0},x_{1}\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/41646d7e8abd4a3cb01ade093d2d28e810e74d90). Recursively applying this  R e c t f l o w ( ⋅ ) {\\displaystyle {\\mathsf {Rectflow}}(\\cdot )} ![{\\\\displaystyle {\\\\mathsf {Rectflow}}\\(\\\\cdot \\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/adb6a8401fc3ab9b268c9d43f9835031155a75dd) operator generates a series of rectified flows  ϕ k + 1 = R e c t f l o w ( ( ϕ 0 k ( x 0 ) , ϕ 1 k ( x 1 ) ) ) {\\displaystyle \\phi ^{k+1}={\\mathsf {Rectflow}}((\\phi _{0}^{k}(x_{0}),\\phi _{1}^{k}(x_{1})))} ![{\\\\displaystyle \\\\phi ^{k+1}={\\\\mathsf {Rectflow}}\\(\\(\\\\phi _{0}^{k}\\(x_{0}\\),\\\\phi _{1}^{k}\\(x_{1}\\)\\)\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d36f81c087cf34b3bc6a038be74872d089d03d42). This \"reflow\" process not only reduces transport costs but also straightens the paths of rectified flows, making  ϕ k {\\displaystyle \\phi ^{k}} ![{\\\\displaystyle \\\\phi ^{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2d6561d8af43e0ca69c817dd06ab830ebb439a74) paths straighter with increasing  k {\\displaystyle k} ![{\\\\displaystyle k}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40). \nRectified flow includes a nonlinear extension where linear interpolation  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) is replaced with any time-differentiable curve that connects  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf) and  x 1 {\\displaystyle x_{1}} ![{\\\\displaystyle x_{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8788bf85d532fa88d1fb25eff6ae382a601c308), given by  x t = α t x 1 + β t x 0 {\\displaystyle x_{t}=\\alpha _{t}x_{1}+\\beta _{t}x_{0}} ![{\\\\displaystyle x_{t}=\\\\alpha _{t}x_{1}+\\\\beta _{t}x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a2631b68c6e8638ead6b7bb2b58937385eb9ea5). This framework encompasses DDIM and probability flow ODEs as special cases, with particular choices of  α t {\\displaystyle \\alpha _{t}} ![{\\\\displaystyle \\\\alpha _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/21f5c448878b19e535a54c80e546a39430e620cb) and  β t {\\displaystyle \\beta _{t}} ![{\\\\displaystyle \\\\beta _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b801e8682d2f1345dbeaca1657eef676bd12ab4a). However, in the case where the path of  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) is not straight, the reflow process no longer ensures a reduction in convex transport costs, and also no longer straighten the paths of  ϕ t {\\displaystyle \\phi _{t}} ![{\\\\displaystyle \\\\phi _{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e1775c8a44fcf88e28ff6a5ec758f22bec15b84e).[[44]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:0-44)\n## Choice of architecture\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=32 \"Edit section: Choice of architecture\")]\n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Diffusion_Architecture.png/330px-Diffusion_Architecture.png)](https://en.wikipedia.org/wiki/File:Diffusion_Architecture.png)Architecture of Stable Diffusion [![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/X-Y_plot_of_algorithmically-generated_AI_art_of_European-style_castle_in_Japan_demonstrating_DDIM_diffusion_steps.png/330px-X-Y_plot_of_algorithmically-generated_AI_art_of_European-style_castle_in_Japan_demonstrating_DDIM_diffusion_steps.png)](https://en.wikipedia.org/wiki/File:X-Y_plot_of_algorithmically-generated_AI_art_of_European-style_castle_in_Japan_demonstrating_DDIM_diffusion_steps.png)The denoising process used by Stable Diffusion\n### Diffusion model\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=33 \"Edit section: Diffusion model\")]\nFor generating images by DDPM, we need a neural network that takes a time  t {\\displaystyle t} ![{\\\\displaystyle t}](https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560) and a noisy image  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db), and predicts a noise  ϵ θ ( x t , t ) {\\displaystyle \\epsilon _{\\theta }(x_{t},t)} ![{\\\\displaystyle \\\\epsilon _{\\\\theta }\\(x_{t},t\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac1d100b70d76dbb0e1429000edc61529a2c1724) from it. Since predicting the noise is the same as predicting the denoised image, then subtracting it from  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db), denoising architectures tend to work well. For example, the [U-Net](https://en.wikipedia.org/wiki/U-Net \"U-Net\"), which was found to be good for denoising images, is often used for denoising diffusion models that generate images.[[46]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:3-46)\n[Transformer](https://en.wikipedia.org/wiki/Transformer_\\(deep_learning_architecture\\) \"Transformer \\(deep learning architecture\\)\") to predict the mean and diagonal covariance of the noise, given the textual conditioning and the partially denoised image. It is the same as standard U-Net-based denoising diffusion model, with a Transformer replacing the U-Net.[[47]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-47) [Mixture of experts](https://en.wikipedia.org/wiki/Mixture_of_experts \"Mixture of experts\")-Transformer can also be applied.[[48]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-48)\nDDPM can be used to model general data distributions, not just natural-looking images. For example, Human Motion Diffusion[[49]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:4-49) models human motion trajectory by DDPM. Each human motion trajectory is a sequence of poses, represented by either joint rotations or positions. It uses a [Transformer](https://en.wikipedia.org/wiki/Transformer_\\(deep_learning_architecture\\) \"Transformer \\(deep learning architecture\\)\") network to generate a less noisy trajectory out of a noisy one. \n### Conditioning\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=34 \"Edit section: Conditioning\")]\nThe base diffusion model can only generate unconditionally from the whole distribution. For example, a diffusion model learned on [ImageNet](https://en.wikipedia.org/wiki/ImageNet \"ImageNet\") would generate images that look like a random image from ImageNet. To generate images from just one category, one would need to impose the condition, and then sample from the conditional distribution. Whatever condition one wants to impose, one needs to first convert the conditioning into a vector of floating point numbers, then feed it into the underlying diffusion model neural network. However, one has freedom in choosing how to convert the conditioning into a vector. \nStable Diffusion, for example, imposes conditioning in the form of [cross-attention mechanism](https://en.wikipedia.org/wiki/Attention_\\(machine_learning\\) \"Attention \\(machine learning\\)\"), where the query is an intermediate representation of the image in the U-Net, and both key and value are the conditioning vectors. The conditioning can be selectively applied to only parts of an image, and new kinds of conditionings can be finetuned upon the base model, as used in ControlNet.[[50]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-50)\nAs a particularly simple example, consider [image inpainting](https://en.wikipedia.org/wiki/Inpainting \"Inpainting\"). The conditions are  x ~ {\\displaystyle {\\tilde {x}}} ![{\\\\displaystyle {\\\\tilde {x}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4f5c5435030c952a58a756e691ea64f60c1bd240), the reference image, and  m {\\displaystyle m} ![{\\\\displaystyle m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc), the inpainting [mask](https://en.wikipedia.org/wiki/Mask_\\(computing\\)#Image_masks \"Mask \\(computing\\)\"). The conditioning is imposed at each step of the backward diffusion process, by first sampling  x ~ t ∼ N ( α ¯ t x ~ , σ t 2 I ) {\\displaystyle {\\tilde {x}}_{t}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}{\\tilde {x}},\\sigma _{t}^{2}I\\right)} ![{\\\\displaystyle {\\\\tilde {x}}_{t}\\\\sim N\\\\left\\({\\\\sqrt {{\\\\bar {\\\\alpha }}_{t}}}{\\\\tilde {x}},\\\\sigma _{t}^{2}I\\\\right\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3126b84dfe0b37ed0f66cc575e89e0aaa6f6aa35), a noisy version of  x ~ {\\displaystyle {\\tilde {x}}} ![{\\\\displaystyle {\\\\tilde {x}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4f5c5435030c952a58a756e691ea64f60c1bd240), then replacing  x t {\\displaystyle x_{t}} ![{\\\\displaystyle x_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f279a30bc8eabc788f3fe81c9cfb674e72e858db) with  ( 1 − m ) ⊙ x t + m ⊙ x ~ t {\\displaystyle (1-m)\\odot x_{t}+m\\odot {\\tilde {x}}_{t}} ![{\\\\displaystyle \\(1-m\\)\\\\odot x_{t}+m\\\\odot {\\\\tilde {x}}_{t}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a17035f75725ed4e664f673ae052fe0b631304e3), where  ⊙ {\\displaystyle \\odot } ![{\\\\displaystyle \\\\odot }](https://wikimedia.org/api/rest_v1/media/math/render/svg/e89e009eb8a8839c82aa5c76c15e9f2d67006276) means [elementwise multiplication](https://en.wikipedia.org/wiki/Hadamard_product_\\(matrices\\) \"Hadamard product \\(matrices\\)\").[[51]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-51) Another application of cross-attention mechanism is prompt-to-prompt image editing.[[52]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-52)\nConditioning is not limited to just generating images from a specific category, or according to a specific caption (as in text-to-image). For example,[[49]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:4-49) demonstrated generating human motion, conditioned on an audio clip of human walking (allowing syncing motion to a soundtrack), or video of human running, or a text description of human motion, etc. For how conditional diffusion models are mathematically formulated, see a methodological summary in.[[53]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-53)\n### Upscaling\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=35 \"Edit section: Upscaling\")]\nAs generating an image takes a long time, one can try to generate a small image by a base diffusion model, then upscale it by other models. Upscaling can be done by [GAN](https://en.wikipedia.org/wiki/Generative_adversarial_network \"Generative adversarial network\"),[[54]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-54) [Transformer](https://en.wikipedia.org/wiki/Transformer_\\(machine_learning_model\\) \"Transformer \\(machine learning model\\)\"),[[55]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-55) or signal processing methods like [Lanczos resampling](https://en.wikipedia.org/wiki/Lanczos_resampling \"Lanczos resampling\"). \nDiffusion models themselves can be used to perform upscaling. Cascading diffusion model stacks multiple diffusion models one after another, in the style of [Progressive GAN](https://en.wikipedia.org/wiki/StyleGAN#Progressive_GAN \"StyleGAN\"). The lowest level is a standard diffusion model that generate 32x32 image, then the image would be upscaled by a diffusion model specifically trained for upscaling, and the process repeats.[[46]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:3-46)\nIn more detail, the diffusion upscaler is trained as follows:[[46]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:3-46)\n  * Sample  ( x 0 , z 0 , c ) {\\displaystyle (x_{0},z_{0},c)} ![{\\\\displaystyle \\(x_{0},z_{0},c\\)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7f376bb518a818d0c9dd8f64f1178637ff3a3fc0), where  x 0 {\\displaystyle x_{0}} ![{\\\\displaystyle x_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f21d0e31751534cd6584264ecf864a6aa792cf) is the high-resolution image,  z 0 {\\displaystyle z_{0}} ![{\\\\displaystyle z_{0}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e72d1d86e86355892b39b8eb32b964834e113bf) is the same image but scaled down to a low-resolution, and  c {\\displaystyle c} ![{\\\\displaystyle c}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455) is the conditioning, which can be the caption of the image, the class of the image, etc.\n  * Sample two white noises  ϵ x , ϵ z {\\displaystyle \\epsilon _{x},\\epsilon _{z}} ![{\\\\displaystyle \\\\epsilon _{x},\\\\epsilon _{z}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c1d35063cb7e4fa9dfe889e89e83d1d245217ef2), two time-steps  t x , t z {\\displaystyle t_{x},t_{z}} ![{\\\\displaystyle t_{x},t_{z}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2831b1f81c27023b4d3d4af480e88b0e35ae8368). Compute the noisy versions of the high-resolution and low-resolution images:  { x t x = α ¯ t x x 0 + σ t x ϵ x z t z = α ¯ t z z 0 + σ t z ϵ z {\\displaystyle {\\begin{cases}x_{t_{x}}&={\\sqrt {{\\bar {\\alpha }}_{t_{x}}}}x_{0}+\\sigma _{t_{x}}\\epsilon _{x}\\\\\\z_{t_{z}}&={\\sqrt {{\\bar {\\alpha }}_{t_{z}}}}z_{0}+\\sigma _{t_{z}}\\epsilon _{z}\\end{cases}}} ![{\\\\displaystyle {\\\\begin{cases}x_{t_{x}}&={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t_{x}}}}x_{0}+\\\\sigma _{t_{x}}\\\\epsilon _{x}\\\\\\\\z_{t_{z}}&={\\\\sqrt {{\\\\bar {\\\\alpha }}_{t_{z}}}}z_{0}+\\\\sigma _{t_{z}}\\\\epsilon _{z}\\\\end{cases}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3188c91ee8a2cea17c6bac011639e8c662b5ffba).\n  * Train the denoising network to predict  ϵ x {\\displaystyle \\epsilon _{x}} ![{\\\\displaystyle \\\\epsilon _{x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/41af29de2b1d4b9ac93f30b80ff3d21e3a10e32f) given  x t x , z t z , t x , t z , c {\\displaystyle x_{t_{x}},z_{t_{z}},t_{x},t_{z},c} ![{\\\\displaystyle x_{t_{x}},z_{t_{z}},t_{x},t_{z},c}](https://wikimedia.org/api/rest_v1/media/math/render/svg/378c504ecda7c62d9d36d1393ce7eb80bc302338). That is, apply gradient descent on  θ {\\displaystyle \\theta } ![{\\\\displaystyle \\\\theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af) on the L2 loss  ‖ ϵ θ ( x t x , z t z , t x , t z , c ) − ϵ x ‖ 2 2 {\\displaystyle \\|\\epsilon _{\\theta }(x_{t_{x}},z_{t_{z}},t_{x},t_{z},c)-\\epsilon _{x}\\|_{2}^{2}} ![{\\\\displaystyle \\\\|\\\\epsilon _{\\\\theta }\\(x_{t_{x}},z_{t_{z}},t_{x},t_{z},c\\)-\\\\epsilon _{x}\\\\|_{2}^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fe24a761f2ef9e6fc11e1de1e63c31c990c575d7).\n\n\n## Examples\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=36 \"Edit section: Examples\")]\nThis section collects some notable diffusion models, and briefly describes their architecture. \n### OpenAI\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=37 \"Edit section: OpenAI\")]\nMain articles: [DALL-E](https://en.wikipedia.org/wiki/DALL-E \"DALL-E\") and [Sora (text-to-video model)](https://en.wikipedia.org/wiki/Sora_\\(text-to-video_model\\) \"Sora \\(text-to-video model\\)\")\nThe DALL-E series by OpenAI are text-conditional diffusion models of images. \nThe first version of DALL-E (2021) is not actually a diffusion model. Instead, it uses a Transformer architecture that autoregressively generates a sequence of tokens, which is then converted to an image by the decoder of a discrete VAE. Released with DALL-E was the CLIP classifier, which was used by DALL-E to rank generated images according to how close the image fits the text. \nGLIDE (2022-03)[[56]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-56) is a 3.5-billion diffusion model, and a small version was released publicly.[[5]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-5) Soon after, DALL-E 2 was released (2022-04).[[57]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-57) DALL-E 2 is a 3.5-billion cascaded diffusion model that generates images from text by \"inverting the CLIP image encoder\", the technique which they termed \"unCLIP\". \nThe unCLIP method contains 4 models: a CLIP image encoder, a CLIP text encoder, an image decoder, and a \"prior\" model (which can be a diffusion model, or an autoregressive model). During training, the prior model is trained to convert CLIP image encodings to CLIP text encodings. The image decoder is trained to convert CLIP image encodings back to images. During inference, a text is converted by the CLIP text encoder to a vector, then it is converted by the prior model to an image encoding, then it is converted by the image decoder to an image. \n[Sora](https://en.wikipedia.org/wiki/Sora_\\(text-to-video_model\\) \"Sora \\(text-to-video model\\)\") (2024-02) is a diffusion Transformer model (DiT). \n### Stability AI\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=38 \"Edit section: Stability AI\")]\nMain article: [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion \"Stable Diffusion\")\n[Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion \"Stable Diffusion\") (2022-08), released by Stability AI, consists of a denoising latent diffusion model (860 million parameters), a VAE, and a text encoder. The denoising network is a U-Net, with cross-attention blocks to allow for conditional image generation.[[58]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:02-58)[[23]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:2-23)\nStable Diffusion 3 (2024-03)[[59]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-:6-59) changed the latent diffusion model from the UNet to a Transformer model, and so it is a DiT. It uses rectified flow. \nStable Video 4D (2024-07)[[60]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-60) is a latent diffusion model for videos of 3D objects. \n### Google\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=39 \"Edit section: Google\")]\nImagen (2022)[[61]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-61)[[62]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-62) uses a [T5-XXL language model](https://en.wikipedia.org/wiki/T5_\\(language_model\\) \"T5 \\(language model\\)\") to encode the input text into an embedding vector. It is a cascaded diffusion model with three sub-models. The first step denoises a white noise to a 64×64 image, conditional on the embedding vector of the text. This model has 2B parameters. The second step upscales the image by 64×64→256×256, conditional on embedding. This model has 650M parameters. The third step is similar, upscaling by 256×256→1024×1024. This model has 400M parameters. The three denoising networks are all U-Nets. \nMuse (2023-01)[[63]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-63) is not a diffusion model, but an encoder-only Transformer that is trained to predict masked image tokens from unmasked image tokens. \nImagen 2 (2023-12) is also diffusion-based. It can generate images based on a prompt that mixes images and text. No further information available.[[64]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-64) Imagen 3 (2024-05) is too. No further information available.[[65]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-65)\nVeo (2024) generates videos by latent diffusion. The diffusion is conditioned on a vector that encodes both a text prompt and an image prompt.[[66]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-66)\n### Meta\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=40 \"Edit section: Meta\")]\nMake-A-Video (2022) is a text-to-video diffusion model.[[67]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-67)[[68]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-68)\nCM3leon (2023) is not a diffusion model, but an autoregressive causally masked Transformer, with mostly the same architecture as [LLaMa](https://en.wikipedia.org/wiki/Llama_\\(language_model\\) \"Llama \\(language model\\)\")-2.[[69]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-69)[[70]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-70)\n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Transfusion_%282024%29_Fig_1%2C_architectural_diagram.png/330px-Transfusion_%282024%29_Fig_1%2C_architectural_diagram.png)](https://en.wikipedia.org/wiki/File:Transfusion_\\(2024\\)_Fig_1,_architectural_diagram.png)Transfusion architectural diagram\nTransfusion (2024) is a Transformer that combines autoregressive text generation and denoising diffusion. Specifically, it generates text autoregressively (with causal masking), and generates images by denoising multiple times over image tokens (with all-to-all attention).[[71]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-71)\nMovie Gen (2024) is a series of Diffusion Transformers operating on latent space and by flow matching.[[72]](https://en.wikipedia.org/wiki/Diffusion_model#cite_note-72)\n## See also\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=41 \"Edit section: See also\")]\n  * [Diffusion process](https://en.wikipedia.org/wiki/Diffusion_process \"Diffusion process\")\n  * [Markov chain](https://en.wikipedia.org/wiki/Markov_chain \"Markov chain\")\n  * [Variational inference](https://en.wikipedia.org/wiki/Variational_inference \"Variational inference\")\n  * [Variational autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder \"Variational autoencoder\")\n\n\n## Further reading\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=42 \"Edit section: Further reading\")]\n  * Review papers \n    * Yang, Ling (2024-09-06), [_YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy_](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy) , retrieved 2024-09-06\n    * Yang, Ling; Zhang, Zhilong; Song, Yang; Hong, Shenda; Xu, Runsheng; Zhao, Yue; Zhang, Wentao; Cui, Bin; Yang, Ming-Hsuan (2023-11-09). [\"Diffusion Models: A Comprehensive Survey of Methods and Applications\"](https://dl.acm.org/doi/abs/10.1145/3626235). _ACM Comput. Surv_. **56** (4): 105:1–105:39. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.00796](https://arxiv.org/abs/2209.00796). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1145/3626235](https://doi.org/10.1145%2F3626235). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [0360-0300](https://search.worldcat.org/issn/0360-0300).\n    * Austin, Jacob; Johnson, Daniel D.; Ho, Jonathan; Tarlow, Daniel; Rianne van den Berg (2021). \"Structured Denoising Diffusion Models in Discrete State-Spaces\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2107.03006](https://arxiv.org/abs/2107.03006) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n    * Croitoru, Florinel-Alin; Hondru, Vlad; Ionescu, Radu Tudor; Shah, Mubarak (2023-09-01). \"Diffusion Models in Vision: A Survey\". _IEEE Transactions on Pattern Analysis and Machine Intelligence_. **45** (9): 10850–10869. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.04747](https://arxiv.org/abs/2209.04747). [Bibcode](https://en.wikipedia.org/wiki/Bibcode_\\(identifier\\) \"Bibcode \\(identifier\\)\"):[2023ITPAM..4510850C](https://ui.adsabs.harvard.edu/abs/2023ITPAM..4510850C). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1109/TPAMI.2023.3261988](https://doi.org/10.1109%2FTPAMI.2023.3261988). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [0162-8828](https://search.worldcat.org/issn/0162-8828). [PMID](https://en.wikipedia.org/wiki/PMID_\\(identifier\\) \"PMID \\(identifier\\)\") [37030794](https://pubmed.ncbi.nlm.nih.gov/37030794).\n  * Mathematical details omitted in the article. \n    * [\"Power of Diffusion Models\"](https://astralord.github.io/posts/power-of-diffusion-models/). _AstraBlog_. 2022-09-25. Retrieved 2023-09-25.\n    * Luo, Calvin (2022-08-25). \"Understanding Diffusion Models: A Unified Perspective\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2208.11970](https://arxiv.org/abs/2208.11970) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n    * Weng, Lilian (2021-07-11). [\"What are Diffusion Models?\"](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/). _lilianweng.github.io_. Retrieved 2023-09-25.\n  * Tutorials \n    * Nakkiran, Preetum; Bradley, Arwen; Zhou, Hattie; Advani, Madhu (2024). \"Step-by-Step Diffusion: An Elementary Tutorial\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2406.08929](https://arxiv.org/abs/2406.08929) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n    * [\"Guidance: a cheat code for diffusion models\"](https://benanne.github.io/2022/05/26/guidance.html). 26 May 2022.\n\n\n## References\n[[edit](https://en.wikipedia.org/w/index.php?title=Diffusion_model&action=edit&section=43 \"Edit section: References\")]\n  1. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-song_1-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-song_1-1) [_**c**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-song_1-2) [_**d**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-song_1-3) Song, Yang; Sohl-Dickstein, Jascha; Kingma, Diederik P.; Kumar, Abhishek; Ermon, Stefano; Poole, Ben (2021-02-10). \"Score-Based Generative Modeling through Stochastic Differential Equations\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2011.13456](https://arxiv.org/abs/2011.13456) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  2. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-2)** Croitoru, Florinel-Alin; Hondru, Vlad; Ionescu, Radu Tudor; Shah, Mubarak (2023). \"Diffusion Models in Vision: A Survey\". _IEEE Transactions on Pattern Analysis and Machine Intelligence_. **45** (9): 10850–10869. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.04747](https://arxiv.org/abs/2209.04747). [Bibcode](https://en.wikipedia.org/wiki/Bibcode_\\(identifier\\) \"Bibcode \\(identifier\\)\"):[2023ITPAM..4510850C](https://ui.adsabs.harvard.edu/abs/2023ITPAM..4510850C). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1109/TPAMI.2023.3261988](https://doi.org/10.1109%2FTPAMI.2023.3261988). [PMID](https://en.wikipedia.org/wiki/PMID_\\(identifier\\) \"PMID \\(identifier\\)\") [37030794](https://pubmed.ncbi.nlm.nih.gov/37030794). [S2CID](https://en.wikipedia.org/wiki/S2CID_\\(identifier\\) \"S2CID \\(identifier\\)\") [252199918](https://api.semanticscholar.org/CorpusID:252199918).\n  3. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-ho_3-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-ho_3-1) Ho, Jonathan; Jain, Ajay; Abbeel, Pieter (2020). [\"Denoising Diffusion Probabilistic Models\"](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html). _Advances in Neural Information Processing Systems_. **33**. Curran Associates, Inc.: 6840–6851.\n  4. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-gu_4-0)** Gu, Shuyang; Chen, Dong; Bao, Jianmin; Wen, Fang; Zhang, Bo; Chen, Dongdong; Yuan, Lu; Guo, Baining (2021). \"Vector Quantized Diffusion Model for Text-to-Image Synthesis\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2111.14822](https://arxiv.org/abs/2111.14822) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  5. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-dalle2_5-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-dalle2_5-1) [_GLIDE_](https://github.com/openai/glide-text2im), OpenAI, 2023-09-22, retrieved 2023-09-24\n  6. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-6)** Li, Yifan; Zhou, Kun; Zhao, Wayne Xin; Wen, Ji-Rong (August 2023). [\"Diffusion Models for Non-autoregressive Text Generation: A Survey\"](https://dx.doi.org/10.24963/ijcai.2023/750). _Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence_. California: International Joint Conferences on Artificial Intelligence Organization. pp. 6692–6701. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2303.06574](https://arxiv.org/abs/2303.06574). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.24963/ijcai.2023/750](https://doi.org/10.24963%2Fijcai.2023%2F750). [ISBN](https://en.wikipedia.org/wiki/ISBN_\\(identifier\\) \"ISBN \\(identifier\\)\") [978-1-956792-03-4](https://en.wikipedia.org/wiki/Special:BookSources/978-1-956792-03-4 \"Special:BookSources/978-1-956792-03-4\").\n  7. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-7)** Xu, Weijie; Hu, Wenxiang; Wu, Fanyou; Sengamedu, Srinivasan (2023). [\"DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM\"](https://dx.doi.org/10.18653/v1/2023.findings-emnlp.606). _Findings of the Association for Computational Linguistics: EMNLP 2023_. Stroudsburg, PA, USA: Association for Computational Linguistics: 9040–9057. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2310.15296](https://arxiv.org/abs/2310.15296). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.18653/v1/2023.findings-emnlp.606](https://doi.org/10.18653%2Fv1%2F2023.findings-emnlp.606).\n  8. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-8)** Zhang, Haopeng; Liu, Xiao; Zhang, Jiawei (2023). [\"DiffuSum: Generation Enhanced Extractive Summarization with Diffusion\"](https://dx.doi.org/10.18653/v1/2023.findings-acl.828). _Findings of the Association for Computational Linguistics: ACL 2023_. Stroudsburg, PA, USA: Association for Computational Linguistics: 13089–13100. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2305.01735](https://arxiv.org/abs/2305.01735). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.18653/v1/2023.findings-acl.828](https://doi.org/10.18653%2Fv1%2F2023.findings-acl.828).\n  9. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-9)** Yang, Dongchao; Yu, Jianwei; Wang, Helin; Wang, Wen; Weng, Chao; Zou, Yuexian; Yu, Dong (2023). [\"Diffsound: Discrete Diffusion Model for Text-to-Sound Generation\"](https://dx.doi.org/10.1109/taslp.2023.3268730). _IEEE/ACM Transactions on Audio, Speech, and Language Processing_. **31** : 1720–1733. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2207.09983](https://arxiv.org/abs/2207.09983). [Bibcode](https://en.wikipedia.org/wiki/Bibcode_\\(identifier\\) \"Bibcode \\(identifier\\)\"):[2023ITASL..31.1720Y](https://ui.adsabs.harvard.edu/abs/2023ITASL..31.1720Y). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1109/taslp.2023.3268730](https://doi.org/10.1109%2Ftaslp.2023.3268730). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [2329-9290](https://search.worldcat.org/issn/2329-9290).\n  10. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-10)** Janner, Michael; Du, Yilun; Tenenbaum, Joshua B.; Levine, Sergey (2022-12-20). \"Planning with Diffusion for Flexible Behavior Synthesis\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2205.09991](https://arxiv.org/abs/2205.09991) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  11. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-11)** Chi, Cheng; Xu, Zhenjia; Feng, Siyuan; Cousineau, Eric; Du, Yilun; Burchfiel, Benjamin; Tedrake, Russ; Song, Shuran (2024-03-14). \"Diffusion Policy: Visuomotor Policy Learning via Action Diffusion\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2303.04137](https://arxiv.org/abs/2303.04137) [[cs.RO](https://arxiv.org/archive/cs.RO)].\n  12. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-12)** Sohl-Dickstein, Jascha; Weiss, Eric; Maheswaranathan, Niru; Ganguli, Surya (2015-06-01). [\"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\"](http://proceedings.mlr.press/v37/sohl-dickstein15.pdf) (PDF). _Proceedings of the 32nd International Conference on Machine Learning_. **37**. PMLR: 2256–2265. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[1503.03585](https://arxiv.org/abs/1503.03585).\n  13. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-13)** Ho, Jonathan (Jun 20, 2020), [_hojonathanho/diffusion_](https://github.com/hojonathanho/diffusion) , retrieved 2024-09-07\n  14. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:7_14-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:7_14-1) Weng, Lilian (2021-07-11). [\"What are Diffusion Models?\"](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/). _lilianweng.github.io_. Retrieved 2023-09-24.\n  15. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-15)** [\"Generative Modeling by Estimating Gradients of the Data Distribution | Yang Song\"](https://yang-song.net/blog/2021/score/). _yang-song.net_. Retrieved 2023-09-24.\n  16. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:9_16-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:9_16-1) Song, Yang; Ermon, Stefano (2019). [\"Generative Modeling by Estimating Gradients of the Data Distribution\"](https://proceedings.neurips.cc/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html). _Advances in Neural Information Processing Systems_. **32**. Curran Associates, Inc. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[1907.05600](https://arxiv.org/abs/1907.05600).\n  17. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:1_17-0)** Song, Yang; Sohl-Dickstein, Jascha; Kingma, Diederik P.; Kumar, Abhishek; Ermon, Stefano; Poole, Ben (2021-02-10). \"Score-Based Generative Modeling through Stochastic Differential Equations\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2011.13456](https://arxiv.org/abs/2011.13456) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  18. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-18)** [_ermongroup/ncsn_](https://github.com/ermongroup/ncsn), ermongroup, 2019, retrieved 2024-09-07\n  19. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-19)** [\"Sliced Score Matching: A Scalable Approach to Density and Score Estimation | Yang Song\"](https://yang-song.net/blog/2019/ssm/). _yang-song.net_. Retrieved 2023-09-24.\n  20. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-20)** Anderson, Brian D.O. (May 1982). [\"Reverse-time diffusion equation models\"](https://dx.doi.org/10.1016/0304-4149\\(82\\)90051-5). _Stochastic Processes and Their Applications_. **12** (3): 313–326. [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1016/0304-4149(82)90051-5](https://doi.org/10.1016%2F0304-4149%2882%2990051-5). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [0304-4149](https://search.worldcat.org/issn/0304-4149).\n  21. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-21)** Luo, Calvin (2022). \"Understanding Diffusion Models: A Unified Perspective\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2208.11970v1](https://arxiv.org/abs/2208.11970v1) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  22. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-22)** Song, Jiaming; Meng, Chenlin; Ermon, Stefano (3 Oct 2023). \"Denoising Diffusion Implicit Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2010.02502](https://arxiv.org/abs/2010.02502) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  23. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:2_23-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:2_23-1) Rombach, Robin; Blattmann, Andreas; Lorenz, Dominik; Esser, Patrick; Ommer, Björn (13 April 2022). \"High-Resolution Image Synthesis With Latent Diffusion Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2112.10752](https://arxiv.org/abs/2112.10752) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  24. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-24)** Nichol, Alexander Quinn; Dhariwal, Prafulla (2021-07-01). [\"Improved Denoising Diffusion Probabilistic Models\"](https://proceedings.mlr.press/v139/nichol21a.html). _Proceedings of the 38th International Conference on Machine Learning_. PMLR: 8162–8171.\n  25. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-25)** Salimans, Tim; Ho, Jonathan (2021-10-06). [_Progressive Distillation for Fast Sampling of Diffusion Models_](https://openreview.net/forum?id=TIdIXIpzhoI). The Tenth International Conference on Learning Representations (ICLR 2022).\n  26. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-26)** Lin, Shanchuan; Liu, Bingchen; Li, Jiashi; Yang, Xiao (2024). [_Common Diffusion Noise Schedules and Sample Steps Are Flawed_](https://openaccess.thecvf.com/content/WACV2024/html/Lin_Common_Diffusion_Noise_Schedules_and_Sample_Steps_Are_Flawed_WACV_2024_paper.html). IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). pp. 5404–5411.\n  27. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:8_27-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:8_27-1) [_**c**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:8_27-2) Dhariwal, Prafulla; Nichol, Alex (2021-06-01). \"Diffusion Models Beat GANs on Image Synthesis\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2105.05233](https://arxiv.org/abs/2105.05233) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  28. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:5_28-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:5_28-1) Ho, Jonathan; Salimans, Tim (2022-07-25). \"Classifier-Free Diffusion Guidance\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2207.12598](https://arxiv.org/abs/2207.12598) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  29. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-29)** Chung, Hyungjin; Kim, Jeongsol; Park, Geon Yeong; Nam, Hyelin; Ye, Jong Chul (2024-06-12). \"CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2406.08070](https://arxiv.org/abs/2406.08070) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  30. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-30)** Sanchez, Guillaume; Fan, Honglu; Spangher, Alexander; Levi, Elad; Ammanamanchi, Pawan Sasanka; Biderman, Stella (2023-06-30). \"Stay on topic with Classifier-Free Guidance\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2306.17806](https://arxiv.org/abs/2306.17806) [[cs.CL](https://arxiv.org/archive/cs.CL)].\n  31. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-31)** Armandpour, Mohammadreza; Sadeghian, Ali; Zheng, Huangjie; Sadeghian, Amir; Zhou, Mingyuan (2023-04-26). \"Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2304.04968](https://arxiv.org/abs/2304.04968) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  32. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-32)** Yang, Ling; Zhang, Zhilong; Song, Yang; Hong, Shenda; Xu, Runsheng; Zhao, Yue; Zhang, Wentao; Cui, Bin; Yang, Ming-Hsuan (2022). \"Diffusion Models: A Comprehensive Survey of Methods and Applications\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2206.00364](https://arxiv.org/abs/2206.00364) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  33. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-33)** Shi, Jiaxin; Han, Kehang; Wang, Zhe; Doucet, Arnaud; Titsias, Michalis K. (2024). \"Simplified and Generalized Masked Diffusion for Discrete Data\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2406.04329](https://arxiv.org/abs/2406.04329) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  34. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-34)** Karras, Tero; Aittala, Miika; Aila, Timo; Laine, Samuli (2022). \"Elucidating the Design Space of Diffusion-Based Generative Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2206.00364v2](https://arxiv.org/abs/2206.00364v2) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  35. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-35)** Cao, Hanqun; Tan, Cheng; Gao, Zhangyang; Xu, Yilun; Chen, Guangyong; Heng, Pheng-Ann; Li, Stan Z. (July 2024). \"A Survey on Generative Diffusion Models\". _IEEE Transactions on Knowledge and Data Engineering_. **36** (7): 2814–2830. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_\\(identifier\\) \"Bibcode \\(identifier\\)\"):[2024ITKDE..36.2814C](https://ui.adsabs.harvard.edu/abs/2024ITKDE..36.2814C). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi \\(identifier\\)\"):[10.1109/TKDE.2024.3361474](https://doi.org/10.1109%2FTKDE.2024.3361474). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [1041-4347](https://search.worldcat.org/issn/1041-4347).\n  36. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-36)** Xu, Yilun; Liu, Ziming; Tian, Yonglong; Tong, Shangyuan; Tegmark, Max; Jaakkola, Tommi (2023-07-03). [\"PFGM++: Unlocking the Potential of Physics-Inspired Generative Models\"](https://proceedings.mlr.press/v202/xu23m.html). _Proceedings of the 40th International Conference on Machine Learning_. PMLR: 38566–38591. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2302.04265](https://arxiv.org/abs/2302.04265).\n  37. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-37)** Song, Yang; Dhariwal, Prafulla; Chen, Mark; Sutskever, Ilya (2023-07-03). [\"Consistency Models\"](https://proceedings.mlr.press/v202/song23a). _Proceedings of the 40th International Conference on Machine Learning_. PMLR: 32211–32252.\n  38. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-38)** Dockhorn, Tim; Vahdat, Arash; Kreis, Karsten (2021-10-06). \"Score-Based Generative Modeling with Critically-Damped Langevin Diffusion\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2112.07068](https://arxiv.org/abs/2112.07068) [[stat.ML](https://arxiv.org/archive/stat.ML)].\n  39. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-39)** Liu, Ziming; Luo, Di; Xu, Yilun; Jaakkola, Tommi; Tegmark, Max (2023-04-05). \"GenPhys: From Physical Processes to Generative Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2304.02637](https://arxiv.org/abs/2304.02637) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  40. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-40)** Bansal, Arpit; Borgnia, Eitan; Chu, Hong-Min; Li, Jie; Kazemi, Hamid; Huang, Furong; Goldblum, Micah; Geiping, Jonas; Goldstein, Tom (2023-12-15). [\"Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise\"](https://proceedings.neurips.cc/paper_files/paper/2023/hash/80fe51a7d8d0c73ff7439c2a2554ed53-Abstract-Conference.html). _Advances in Neural Information Processing Systems_. **36** : 41259–41282. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2208.09392](https://arxiv.org/abs/2208.09392).\n  41. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-41)** Gulrajani, Ishaan; Hashimoto, Tatsunori B. (2023-12-15). [\"Likelihood-Based Diffusion Language Models\"](https://proceedings.neurips.cc/paper_files/paper/2023/hash/35b5c175e139bff5f22a5361270fce87-Abstract-Conference.html). _Advances in Neural Information Processing Systems_. **36** : 16693–16715. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2305.18619](https://arxiv.org/abs/2305.18619).\n  42. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-42)** Lou, Aaron; Meng, Chenlin; Ermon, Stefano (2024-06-06). \"Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2310.16834](https://arxiv.org/abs/2310.16834) [[stat.ML](https://arxiv.org/archive/stat.ML)].\n  43. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-43)** Tong, Alexander; Fatras, Kilian; Malkin, Nikolay; Huguet, Guillaume; Zhang, Yanlei; Rector-Brooks, Jarrid; Wolf, Guy; Bengio, Yoshua (2023-11-08). [\"Improving and generalizing flow-based generative models with minibatch optimal transport\"](https://openreview.net/forum?id=CD9Snc73AW). _Transactions on Machine Learning Research_. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2302.00482](https://arxiv.org/abs/2302.00482). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [2835-8856](https://search.worldcat.org/issn/2835-8856).\n  44. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:0_44-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:0_44-1) [_**c**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:0_44-2) [_**d**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:0_44-3) Liu, Xingchao; Gong, Chengyue; Liu, Qiang (2022-09-07). \"Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.03003](https://arxiv.org/abs/2209.03003) [[cs.LG](https://arxiv.org/archive/cs.LG)].\n  45. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-45)** Liu, Qiang (2022-09-29). \"Rectified Flow: A Marginal Preserving Approach to Optimal Transport\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.14577](https://arxiv.org/abs/2209.14577) [[stat.ML](https://arxiv.org/archive/stat.ML)].\n  46. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:3_46-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:3_46-1) [_**c**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:3_46-2) Ho, Jonathan; Saharia, Chitwan; Chan, William; Fleet, David J.; Norouzi, Mohammad; Salimans, Tim (2022-01-01). [\"Cascaded diffusion models for high fidelity image generation\"](https://dl.acm.org/doi/abs/10.5555/3586589.3586636). _The Journal of Machine Learning Research_. **23** (1): 47:2249–47:2281. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2106.15282](https://arxiv.org/abs/2106.15282). [ISSN](https://en.wikipedia.org/wiki/ISSN_\\(identifier\\) \"ISSN \\(identifier\\)\") [1532-4435](https://search.worldcat.org/issn/1532-4435).\n  47. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-47)** Peebles, William; Xie, Saining (March 2023). \"Scalable Diffusion Models with Transformers\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2212.09748v2](https://arxiv.org/abs/2212.09748v2) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  48. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-48)** Fei, Zhengcong; Fan, Mingyuan; Yu, Changqian; Li, Debang; Huang, Junshi (2024-07-16). \"Scaling Diffusion Transformers to 16 Billion Parameters\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2407.11633](https://arxiv.org/abs/2407.11633) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  49. ^ [_**a**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:4_49-0) [_**b**_](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:4_49-1) Tevet, Guy; Raab, Sigal; Gordon, Brian; Shafir, Yonatan; Cohen-Or, Daniel; Bermano, Amit H. (2022). \"Human Motion Diffusion Model\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.14916](https://arxiv.org/abs/2209.14916) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  50. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-50)** Zhang, Lvmin; Rao, Anyi; Agrawala, Maneesh (2023). \"Adding Conditional Control to Text-to-Image Diffusion Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2302.05543](https://arxiv.org/abs/2302.05543) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  51. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-51)** Lugmayr, Andreas; Danelljan, Martin; Romero, Andres; Yu, Fisher; Timofte, Radu; Van Gool, Luc (2022). \"RePaint: Inpainting Using Denoising Diffusion Probabilistic Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2201.09865v4](https://arxiv.org/abs/2201.09865v4) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  52. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-52)** Hertz, Amir; Mokady, Ron; Tenenbaum, Jay; Aberman, Kfir; Pritch, Yael; Cohen-Or, Daniel (2022-08-02). \"Prompt-to-Prompt Image Editing with Cross Attention Control\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2208.01626](https://arxiv.org/abs/2208.01626) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  53. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-53)** Zhao, Zheng; Luo, Ziwei; Sjölund, Jens; Schön, Thomas B. (2024). \"Conditional sampling within generative diffusion models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2409.09650](https://arxiv.org/abs/2409.09650) [[stat.ML](https://arxiv.org/archive/stat.ML)].\n  54. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-54)** Wang, Xintao; Xie, Liangbin; Dong, Chao; Shan, Ying (2021). [\"Real-ESRGAN: Training Real-World Blind Super-Resolution With Pure Synthetic Data\"](https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.pdf) (PDF). _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2021_. International Conference on Computer Vision. pp. 1905–1914. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2107.10833](https://arxiv.org/abs/2107.10833).\n  55. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-55)** Liang, Jingyun; Cao, Jiezhang; Sun, Guolei; Zhang, Kai; Van Gool, Luc; Timofte, Radu (2021). [\"SwinIR: Image Restoration Using Swin Transformer\"](https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.pdf) (PDF). _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops_. International Conference on Computer Vision, 2021. pp. 1833–1844. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2108.10257v1](https://arxiv.org/abs/2108.10257v1).\n  56. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-56)** Nichol, Alex; Dhariwal, Prafulla; Ramesh, Aditya; Shyam, Pranav; Mishkin, Pamela; McGrew, Bob; Sutskever, Ilya; Chen, Mark (2022-03-08). \"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2112.10741](https://arxiv.org/abs/2112.10741) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  57. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-57)** Ramesh, Aditya; Dhariwal, Prafulla; Nichol, Alex; Chu, Casey; Chen, Mark (2022-04-12). \"Hierarchical Text-Conditional Image Generation with CLIP Latents\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2204.06125](https://arxiv.org/abs/2204.06125) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  58. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:02_58-0)** Alammar, Jay. [\"The Illustrated Stable Diffusion\"](https://jalammar.github.io/illustrated-stable-diffusion/). _jalammar.github.io_. Retrieved 2022-10-31.\n  59. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-:6_59-0)** Esser, Patrick; Kulal, Sumith; Blattmann, Andreas; Entezari, Rahim; Müller, Jonas; Saini, Harry; Levi, Yam; Lorenz, Dominik; Sauer, Axel (2024-03-05). \"Scaling Rectified Flow Transformers for High-Resolution Image Synthesis\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2403.03206](https://arxiv.org/abs/2403.03206) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  60. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-60)** Xie, Yiming; Yao, Chun-Han; Voleti, Vikram; Jiang, Huaizu; Jampani, Varun (2024-07-24). \"SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2407.17470](https://arxiv.org/abs/2407.17470) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  61. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-61)** [\"Imagen: Text-to-Image Diffusion Models\"](https://imagen.research.google/). _imagen.research.google_. Retrieved 2024-04-04.\n  62. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-62)** Saharia, Chitwan; Chan, William; Saxena, Saurabh; Li, Lala; Whang, Jay; Denton, Emily L.; Ghasemipour, Kamyar; Gontijo Lopes, Raphael; Karagol Ayan, Burcu; Salimans, Tim; Ho, Jonathan; Fleet, David J.; Norouzi, Mohammad (2022-12-06). [\"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding\"](https://proceedings.neurips.cc/paper_files/paper/2022/hash/ec795aeadae0b7d230fa35cbaf04c041-Abstract-Conference.html). _Advances in Neural Information Processing Systems_. **35** : 36479–36494. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2205.11487](https://arxiv.org/abs/2205.11487).\n  63. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-63)** Chang, Huiwen; Zhang, Han; Barber, Jarred; Maschinot, A. J.; Lezama, Jose; Jiang, Lu; Yang, Ming-Hsuan; Murphy, Kevin; Freeman, William T. (2023-01-02). \"Muse: Text-To-Image Generation via Masked Generative Transformers\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2301.00704](https://arxiv.org/abs/2301.00704) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  64. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-64)** [\"Imagen 2 - our most advanced text-to-image technology\"](https://deepmind.google/technologies/imagen-2/). _Google DeepMind_. Retrieved 2024-04-04.\n  65. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-65)** Imagen-Team-Google; Baldridge, Jason; Bauer, Jakob; Bhutani, Mukul; Brichtova, Nicole; Bunner, Andrew; Castrejon, Lluis; Chan, Kelvin; Chen, Yichang (2024-12-13), _Imagen 3_ , [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2408.07009](https://arxiv.org/abs/2408.07009)`{{citation[](https://en.wikipedia.org/wiki/Template:Citation \"Template:Citation\")}}`: `|last1=` has generic name ([help](https://en.wikipedia.org/wiki/Help:CS1_errors#generic_name \"Help:CS1 errors\"))\n  66. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-66)** [\"Veo\"](https://deepmind.google/technologies/veo/). _Google DeepMind_. 2024-05-14. Retrieved 2024-05-17.\n  67. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-67)** [\"Introducing Make-A-Video: An AI system that generates videos from text\"](https://ai.meta.com/blog/generative-ai-text-to-video/). _ai.meta.com_. Retrieved 2024-09-20.\n  68. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-68)** Singer, Uriel; Polyak, Adam; Hayes, Thomas; Yin, Xi; An, Jie; Zhang, Songyang; Hu, Qiyuan; Yang, Harry; Ashual, Oron (2022-09-29). \"Make-A-Video: Text-to-Video Generation without Text-Video Data\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2209.14792](https://arxiv.org/abs/2209.14792) [[cs.CV](https://arxiv.org/archive/cs.CV)].\n  69. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-69)** [\"Introducing CM3leon, a more efficient, state-of-the-art generative model for text and images\"](https://ai.meta.com/blog/generative-ai-text-images-cm3leon/). _ai.meta.com_. Retrieved 2024-09-20.\n  70. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-70)** Chameleon Team (2024-05-16). \"Chameleon: Mixed-Modal Early-Fusion Foundation Models\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2405.09818](https://arxiv.org/abs/2405.09818) [[cs.CL](https://arxiv.org/archive/cs.CL)].\n  71. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-71)** Zhou, Chunting; Yu, Lili; Babu, Arun; Tirumala, Kushal; Yasunaga, Michihiro; Shamis, Leonid; Kahn, Jacob; Ma, Xuezhe; Zettlemoyer, Luke (2024-08-20). \"Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv \\(identifier\\)\"):[2408.11039](https://arxiv.org/abs/2408.11039) [[cs.AI](https://arxiv.org/archive/cs.AI)].\n  72. **[^](https://en.wikipedia.org/wiki/Diffusion_model#cite_ref-72)** _[Movie Gen: A Cast of Media Foundation Models](https://ai.meta.com/static-resource/movie-gen-research-paper)_ , The Movie Gen team @ Meta, October 4, 2024.\n\n\nRetrieved from \"[https://en.wikipedia.org/w/index.php?title=Diffusion_model&oldid=1314773671](https://en.wikipedia.org/w/index.php?title=Diffusion_model&oldid=1314773671)\"\n[Categories](https://en.wikipedia.org/wiki/Help:Category \"Help:Category\"): \n  * [Markov models](https://en.wikipedia.org/wiki/Category:Markov_models \"Category:Markov models\")\n  * [Machine learning algorithms](https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms \"Category:Machine learning algorithms\")\n\n\nHidden categories: \n  * [CS1 errors: generic name](https://en.wikipedia.org/wiki/Category:CS1_errors:_generic_name \"Category:CS1 errors: generic name\")\n  * [Articles with short description](https://en.wikipedia.org/wiki/Category:Articles_with_short_description \"Category:Articles with short description\")\n  * [Short description matches Wikidata](https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata \"Category:Short description matches Wikidata\")\n  * [Articles containing potentially dated statements from 2024](https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_2024 \"Category:Articles containing potentially dated statements from 2024\")\n  * [All articles containing potentially dated statements](https://en.wikipedia.org/wiki/Category:All_articles_containing_potentially_dated_statements \"Category:All articles containing potentially dated statements\")\n\n\n  * This page was last edited on 3 October 2025, at 04:33 (UTC).\n  * Text is available under the [Creative Commons Attribution-ShareAlike 4.0 License](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License \"Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License\"); additional terms may apply. By using this site, you agree to the [Terms of Use](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use \"foundation:Special:MyLanguage/Policy:Terms of Use\") and [Privacy Policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy \"foundation:Special:MyLanguage/Policy:Privacy policy\"). Wikipedia® is a registered trademark of the [Wikimedia Foundation, Inc.](https://wikimediafoundation.org/), a non-profit organization.\n\n\n  * [Privacy policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)\n  * [About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)\n  * [Disclaimers](https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer)\n  * [Contact Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)\n  * [Code of Conduct](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)\n  * [Developers](https://developer.wikimedia.org)\n  * [Statistics](https://stats.wikimedia.org/#/en.wikipedia.org)\n  * [Cookie statement](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)\n  * [Mobile view](https://en.wikipedia.org/w/index.php?title=Diffusion_model&mobileaction=toggle_view_mobile)\n\n\n  * [![Wikimedia Foundation](https://en.wikipedia.org/static/images/footer/wikimedia.svg)](https://www.wikimedia.org/)\n  * [![Powered by MediaWiki](https://en.wikipedia.org/w/resources/assets/mediawiki_compact.svg)](https://www.mediawiki.org/)\n\n\nSearch\nSearch\nToggle the table of contents\nDiffusion model\n[](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model) [](https://en.wikipedia.org/wiki/Diffusion_model)\n13 languages [Add topic ](https://en.wikipedia.org/wiki/Diffusion_model)\n  *[v]: View this template\n  *[t]: Discuss this template\n  *[e]: Edit this template"
              }
            ],
            "extraInfo": {
              "created": 1761224342645,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 2421,
                "completion_tokens": 24,
                "total_tokens": 2445,
                "prompt_tokens_details": {
                  "cached_tokens": 2240
                },
                "prompt_cache_hit_tokens": 2240,
                "prompt_cache_miss_tokens": 181
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_cAr4p8eAltWRMpMUVLGEuMz0",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "qq_send_message",
                  "arguments": "{\"groupId\": 782833642, \"message\": [{\"type\": \"text\", \"data\": {\"text\": \"Diffusion模型的发展历史概述如下：\"}}, {\"type\": \"text\", \"data\": {\"text\": \"2015年：Sohl-Dickstein等人首次提出基于非平衡热力学的扩散模型概念，使用扩散过程训练复杂概率分布模型\"}}, {\"type\": \"text\", \"data\": {\"text\": \"2019年：Song和Ermon提出基于分数的生成模型（Score-Based Generative Models），也称为噪声条件分数网络（NCSN）\"}}, {\"type\": \"text\", \"data\": {\"text\": \"2020年：Ho等人提出去噪扩散概率模型（DDPM），通过变分推断改进训练方法，成为现代扩散模型的基础\"}}, {\"type\": \"text\", \"data\": {\"text\": \"2021年：Song等人证明DDPM和分数模型在数学上的等价性，提出通过随机微分方程的统一框架\"}}, {\"type\": \"text\", \"data\": {\"text\": \"2022年：Song等人提出DDIM（去噪扩散隐式模型），显著加速采样过程；Rombach等人提出潜在扩散模型（LDM），在潜在空间进行扩散以降低计算成本\"}}, {\"type\": \"text\", \"data\": {\"text\": \"关键技术发展包括：分类器引导、无分类器引导、流匹配、一致性模型等，推动模型在图像生成、视频生成、文本生成等领域的广泛应用\"}}]}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761224384530,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_cAr4p8eAltWRMpMUVLGEuMz0",
            "content": [
              {
                "type": "text",
                "text": "{\n  \"message_id\": 787363224\n}"
              }
            ],
            "extraInfo": {
              "created": 1761224384965,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 77199,
                "completion_tokens": 325,
                "total_tokens": 77524,
                "prompt_tokens_details": {
                  "cached_tokens": 77184
                },
                "prompt_cache_hit_tokens": 77184,
                "prompt_cache_miss_tokens": 15
              },
              "enableXmlWrapper": false
            }
          },
          {
            "role": "assistant",
            "content": "",
            "tool_calls": [
              {
                "id": "call_00_rZgcOyEAkH727t4as6WxJ72x",
                "index": 0,
                "type": "function",
                "function": {
                  "name": "util_add_memory",
                  "arguments": "{\"groupId\": \"default\", \"content\": [\"Diffusion扩散模型发展历史：2015年首次提出基于非平衡热力学的扩散模型概念，2019年提出基于分数的生成模型，2020年提出DDPM成为现代扩散模型基础，2021年证明DDPM和分数模型等价性，2022年提出DDIM加速采样和潜在扩散模型降低计算成本\"]}"
                }
              }
            ],
            "extraInfo": {
              "created": 1761224391116,
              "state": "success",
              "serverName": "deepseek",
              "enableXmlWrapper": false
            }
          },
          {
            "role": "tool",
            "index": 0,
            "tool_call_id": "call_00_rZgcOyEAkH727t4as6WxJ72x",
            "content": [
              {
                "type": "text",
                "text": "记忆添加成功"
              }
            ],
            "extraInfo": {
              "created": 1761224391201,
              "state": "success",
              "serverName": "deepseek",
              "usage": {
                "prompt_tokens": 77549,
                "completion_tokens": 91,
                "total_tokens": 77640,
                "prompt_tokens_details": {
                  "cached_tokens": 77504
                },
                "prompt_cache_hit_tokens": 77504,
                "prompt_cache_miss_tokens": 45
              },
              "enableXmlWrapper": false
            }
          }
        ],
        "chatMode": "single-chat",
        "parallelChats": [],
        "selectedModels": [],
        "settings": {
          "modelIndex": 0,
          "enableTools": [
            {
              "name": "qq_send_message",
              "description": "发送群消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "message": {
                    "type": "array",
                    "items": {
                      "anyOf": [
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "text"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "text": {
                                  "type": "string"
                                }
                              },
                              "required": [
                                "text"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        },
                        {
                          "type": "object",
                          "properties": {
                            "type": {
                              "type": "string",
                              "const": "at"
                            },
                            "data": {
                              "type": "object",
                              "properties": {
                                "qq": {
                                  "type": [
                                    "string",
                                    "number"
                                  ]
                                }
                              },
                              "required": [
                                "qq"
                              ],
                              "additionalProperties": false
                            }
                          },
                          "required": [
                            "type",
                            "data"
                          ],
                          "additionalProperties": false
                        }
                      ]
                    },
                    "description": "要发送的内容"
                  }
                },
                "required": [
                  "groupId",
                  "message"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_image",
              "description": "发送图片",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "url": {
                    "type": "string",
                    "description": "图片的 url"
                  }
                },
                "required": [
                  "groupId",
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_info",
              "description": "获取群信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_list",
              "description": "获取群成员列表",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  }
                },
                "required": [
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_group_member_info",
              "description": "获取群成员信息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "user_id": {
                    "type": "number",
                    "description": "用户 QQ 号"
                  }
                },
                "required": [
                  "groupId",
                  "user_id"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_upload_group_file",
              "description": "上传群文件",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "file": {
                    "type": "string",
                    "description": "文件绝对路径"
                  },
                  "name": {
                    "type": "string",
                    "description": "文件名称"
                  }
                },
                "required": [
                  "groupId",
                  "file",
                  "name"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_send_group_notice",
              "description": "发送群公告",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "content": {
                    "type": "string",
                    "description": "公告内容"
                  }
                },
                "required": [
                  "groupId",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "qq_get_latest_messages",
              "description": "获取最近的若干条群聊消息",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "number",
                    "description": "群号"
                  },
                  "messageCount": {
                    "type": "number",
                    "description": "获取最近几条消息"
                  }
                },
                "required": [
                  "groupId",
                  "messageCount"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_add_memory",
              "description": "将重要信息添加到长期记忆中。当用户分享关于自己、他人、事件的重要信息时(例如:姓名、喜好、经历、关系等),应该主动使用此工具记录,以便后续对话中查询使用。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容,每条信息应该是完整、清晰的描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识（可选）"
                  }
                },
                "required": [
                  "content",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_update_memory",
              "description": "更新记忆",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  },
                  "key": {
                    "type": "string",
                    "description": "记忆的唯一标识"
                  },
                  "content": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "需要记忆的内容"
                  }
                },
                "required": [
                  "groupId",
                  "key",
                  "content"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_search_memory",
              "description": "从长期记忆中查询信息。当用户询问关于特定人物、事件、或之前对话中提到的信息时,应该首先使用此工具搜索相关记忆。例如:用户问\"XXX是谁\"、\"XXX喜欢什么\"、\"上次说的那件事\"等问题时,必须先调用此工具查询。",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string",
                    "description": "搜索的关键字,可以是人名、事件名、或相关描述"
                  },
                  "groupId": {
                    "type": "string",
                    "description": "群号，如果你不知道群号是什么，使用default"
                  }
                },
                "required": [
                  "query",
                  "groupId"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            },
            {
              "name": "util_websearch",
              "description": "获取网页内容",
              "inputSchema": {
                "type": "object",
                "properties": {
                  "url": {
                    "type": "string",
                    "description": "url"
                  }
                },
                "required": [
                  "url"
                ],
                "additionalProperties": false,
                "$schema": "http://json-schema.org/draft-07/schema#"
              },
              "enabled": true
            }
          ],
          "enableWebSearch": false,
          "temperature": 0.6,
          "contextLength": 100,
          "systemPrompt": "",
          "enableXmlWrapper": false,
          "parallelToolCalls": true
        }
      }
    }
  ]
}